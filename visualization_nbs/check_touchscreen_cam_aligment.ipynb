{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotebook for checking alignment of cam and ts data,\\nacross multiple days and animals to find trend\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Notebook for checking alignment of cam and ts data,\n",
    "across multiple days and animals to find trend\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from neuralmonkey.classes.session import load_mult_session_helper\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuralmonkey.classes.snippets import Snippets, extraction_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Diego*/*230530*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Diego/230530/Diego-230530-150228\n",
      "session:  0\n",
      "Beh Sessions that exist on this date:  {230530: [(1, 'primpracticemix1j')]}\n",
      "------------------------------\n",
      "Loading this neural session: 0\n",
      "Loading these beh expts: ['primpracticemix1j']\n",
      "Loading these beh sessions: [1]\n",
      "Using this beh_trial_map_list: [(1, 0)]\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Diego*/*230530*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Diego/230530/Diego-230530-150228\n",
      "{'filename_components_hyphened': ['Diego', '230530', '150228'], 'basedirs': ['/home/danhan/freiwaldDrive/ltian/recordings/Diego', '/home/danhan/freiwaldDrive/ltian/recordings/Diego/230530'], 'basedirs_filenames': ['230530', 'Diego-230530-150228'], 'filename_final_ext': 'Diego-230530-150228', 'filename_final_noext': 'Diego-230530-150228'}\n",
      "FOund this path for spikes:  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230530/Diego-230530-150228/spikes_tdt_quick-4\n",
      "== PATHS for this expt: \n",
      "raws  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230530/Diego-230530-150228\n",
      "tank  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230530/Diego-230530-150228/Diego-230530-150228\n",
      "spikes  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230530/Diego-230530-150228/spikes_tdt_quick-4\n",
      "final_dir_name  --  Diego-230530-150228\n",
      "time  --  150228\n",
      "pathbase_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228\n",
      "tank_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/data_tank.pkl\n",
      "spikes_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/data_spikes.pkl\n",
      "datall_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/data_datall.pkl\n",
      "events_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/events_photodiode.pkl\n",
      "mapper_st2dat_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/mapper_st2dat.pkl\n",
      "figs_local  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/figs\n",
      "metadata_units  --  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units_Diego\n",
      "cached_dir  --  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/cached\n",
      "Sites metada path doesnt exist:  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units/230530.yaml\n",
      "updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_garbage\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_error_spikes\n",
      "Printing whether spikes gotten (o) or not (-) because of spike peak to trough\n",
      "== Loading TDT tank\n",
      "** Loading tank data from local (previusly cached)\n",
      "== Done\n",
      "** MINIMAL_LOADING, therefore loading previuosly cached data\n",
      "== Trying to load events data\n",
      "Loading this events (pd) locally to:  /data4/dan/neural_preprocess/recordings/Diego/230530/Diego-230530-150228/events_photodiode.pkl\n",
      "== Done\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat/*230530-*Diego.**\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/*230530-*Diego.**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/primpracticemix1j-230530-Diego.yaml\n",
      "Loading this dataset Diego primpracticemix1j 230530\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/*Diego-*primpracticemix1j-*230530-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/BEH/*Diego-*primpracticemix1j-*230530-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/*Diego-*primpracticemix1j-*230530-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/*Diego-*primpracticemix1j-*230530-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Diego-primpracticemix1j-230530-230531_044729\n",
      "----------------\n",
      "Currently loading dataset pkl: /home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Diego-primpracticemix1j-230530-230531_044729\n",
      ".. Done!\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': '230530', 'edate': '230530', 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'230530': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['primpracticemix1j'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'primpracticemix1j', 'animal': 'Diego', 'ssess': None, 'esess': None, 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Diego', 'basedir': '/home/kgg/mnt/Freiwald/kgupta/macaque_data', 'sample_rate': array([500.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 18: 'end', 19: 'FixationRaiseFailWTH', 20: 'go (draw)', 21: 'guide_on_GA', 30: 'DelayWhatIsThis', 40: 'GoWhatIsThis', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 64: 'DragAroundAbort', 65: 'DragAroundFirstAbortNow', 70: 'hotkey_x', 71: 'DAstimevent_firstpres', 72: 'DAstimoff_finibeforepause', 73: 'DAstimoff_fini', 74: 'DAsamp1_visible_change', 75: 'DAnewpnutthisframe', 76: 'DAsound_samp1touched', 78: 'DAsound_gotallink', 80: 'ttl_trialon', 81: 'ttl_trialoff', 91: 'GAstimevent_firstpres', 92: 'GAstimoff_fini', 101: 'fix_square_on', 102: 'fix_square_off', 103: 'fix_square_on_pd', 111: 'photodiode_force_off', 120: 'DAsound_chunk', 121: 'DAsound_strokedone', 122: 'DAsound_chunkupdate', 123: 'DAsound_chunkdone', 124: 'DAsound_firstraise', 131: 'fix_cue_colored_on', 132: 'fix_cue_colored_on_v2', 133: 'fix_cue_colored_off', 134: 'fix_cue_colored_off_v2', 135: 'new_color_cue_off', 200: 'skipped_movie_frame'}, 'screen_hz': 59, 'screen_period': 0.01694915254237288}}\n",
      "Loading BlockParamsByDateSessBlock!\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n",
      "* UDPATEING onset of first stroke [too close to fixation] (trial, new onset index):\n",
      "-- CHECKING  origin\n",
      "--- idat, trialcode, strok inds to remove, len strokes beofre remofe, len strokes after:\n",
      "-- CHECKING  donepos\n",
      "--- idat, trialcode, strok inds to remove, len strokes beofre remofe, len strokes after:\n",
      "Updated columns: insummarydates, using Metadats\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/TASKS_GENERAL/Diego-primpracticemix1j-230530-all/*Tasks*pkl\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/TASKS_GENERAL/Diego-primpracticemix1j-230530-all/*Tasks*pkl\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/TASKS_GENERAL/Diego-primpracticemix1j-230530-all/Tasks.pkl\n",
      "--- Loading tasks pkl file:  /home/danhan/freiwaldDrive/kgupta/analyses/database/TASKS_GENERAL/Diego-primpracticemix1j-230530-all/Tasks.pkl\n",
      "added new column self.Dat[Task]\n",
      "=== CLEANING UP self.Dat (_cleanup_reloading_saved_state) ===== \n",
      "- starting/ending len (grouping params):\n",
      "552\n",
      "Extracting Behclass for each trial, may take a while...\n",
      "0 _behclass_alignsim_compute\n",
      "200 _behclass_alignsim_compute\n",
      "400 _behclass_alignsim_compute\n",
      "Running D._behclass_tokens_extract_datsegs\n",
      "TODO: Pancho -- combine circles with the tohers\n",
      "0 _behclass_tokens_extract_datsegs\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Pancho*/*230908*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908/Pancho-230908-152003\n",
      "session:  0\n",
      "Beh Sessions that exist on this date:  {230908: [(1, 'dirgrammarpancho6b')]}\n",
      "------------------------------\n",
      "Loading this neural session: 0\n",
      "Loading these beh expts: ['dirgrammarpancho6b']\n",
      "Loading these beh sessions: [1]\n",
      "Using this beh_trial_map_list: [(1, 0)]\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Pancho*/*230908*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908/Pancho-230908-152003\n",
      "{'filename_components_hyphened': ['Pancho', '230908', '152003'], 'basedirs': ['/home/danhan/freiwaldDrive/ltian/recordings/Pancho', '/home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908'], 'basedirs_filenames': ['230908', 'Pancho-230908-152003'], 'filename_final_ext': 'Pancho-230908-152003', 'filename_final_noext': 'Pancho-230908-152003'}\n",
      "FOund this path for spikes:  /home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908/Pancho-230908-152003/spikes_tdt_quick-4\n",
      "== PATHS for this expt: \n",
      "raws  --  /home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908/Pancho-230908-152003\n",
      "tank  --  /home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908/Pancho-230908-152003/Pancho-230908-152003\n",
      "spikes  --  /home/danhan/freiwaldDrive/ltian/recordings/Pancho/230908/Pancho-230908-152003/spikes_tdt_quick-4\n",
      "final_dir_name  --  Pancho-230908-152003\n",
      "time  --  152003\n",
      "pathbase_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003\n",
      "tank_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/data_tank.pkl\n",
      "spikes_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/data_spikes.pkl\n",
      "datall_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/data_datall.pkl\n",
      "events_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/events_photodiode.pkl\n",
      "mapper_st2dat_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/mapper_st2dat.pkl\n",
      "figs_local  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/figs\n",
      "metadata_units  --  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units\n",
      "cached_dir  --  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/cached\n",
      "Sites metada path doesnt exist:  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units/230908.yaml\n",
      "updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_garbage\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_error_spikes\n",
      "Printing whether spikes gotten (o) or not (-) because of spike peak to trough\n",
      "== Loading TDT tank\n",
      "** Loading tank data from local (previusly cached)\n",
      "== Done\n",
      "** MINIMAL_LOADING, therefore loading previuosly cached data\n",
      "== Trying to load events data\n",
      "Loading this events (pd) locally to:  /data4/dan/neural_preprocess/recordings/Pancho/230908/Pancho-230908-152003/events_photodiode.pkl\n",
      "== Done\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat/*230908-*Pancho.**\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/*230908-*Pancho.**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/dirgrammarpancho6b-230908-Pancho.yaml\n",
      "Loading this dataset Pancho dirgrammarpancho6b 230908\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/*Pancho-*dirgrammarpancho6b-*230908-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/BEH/*Pancho-*dirgrammarpancho6b-*230908-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/*Pancho-*dirgrammarpancho6b-*230908-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/*Pancho-*dirgrammarpancho6b-*230908-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Pancho-dirgrammarpancho6b-230908-230908_235923\n",
      "----------------\n",
      "Currently loading dataset pkl: /home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Pancho-dirgrammarpancho6b-230908-230908_235923\n",
      ".. Done!\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 230908, 'edate': 230908, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'230908': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['dirgrammarpancho6b'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'dirgrammarpancho6b', 'animal': 'Pancho', 'ssess': None, 'esess': None, 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/home/kgg/mnt/Freiwald/kgupta/macaque_data', 'sample_rate': array([500.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 18: 'end', 19: 'FixationRaiseFailWTH', 20: 'go (draw)', 21: 'guide_on_GA', 30: 'DelayWhatIsThis', 40: 'GoWhatIsThis', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 64: 'DragAroundAbort', 65: 'DragAroundFirstAbortNow', 70: 'hotkey_x', 71: 'DAstimevent_firstpres', 72: 'DAstimoff_finibeforepause', 73: 'DAstimoff_fini', 74: 'DAsamp1_visible_change', 75: 'DAnewpnutthisframe', 76: 'DAsound_samp1touched', 78: 'DAsound_gotallink', 80: 'ttl_trialon', 81: 'ttl_trialoff', 91: 'GAstimevent_firstpres', 92: 'GAstimoff_fini', 101: 'fix_square_on', 102: 'fix_square_off', 103: 'fix_square_on_pd', 111: 'photodiode_force_off', 120: 'DAsound_chunk', 121: 'DAsound_strokedone', 122: 'DAsound_chunkupdate', 123: 'DAsound_chunkdone', 124: 'DAsound_firstraise', 131: 'fix_cue_colored_on', 132: 'fix_cue_colored_on_v2', 133: 'fix_cue_colored_off', 134: 'fix_cue_colored_off_v2', 135: 'new_color_cue_off', 200: 'skipped_movie_frame'}, 'screen_hz': 59, 'screen_period': 0.01694915254237288}}\n",
      "Loading BlockParamsByDateSessBlock!\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n",
      "* UDPATEING onset of first stroke [too close to fixation] (trial, new onset index):\n",
      "-- CHECKING  origin\n",
      "--- idat, trialcode, strok inds to remove, len strokes beofre remofe, len strokes after:\n",
      "-- CHECKING  donepos\n",
      "--- idat, trialcode, strok inds to remove, len strokes beofre remofe, len strokes after:\n"
     ]
    }
   ],
   "source": [
    "diego_MS_dict = {}\n",
    "pancho_MS_dict = {}\n",
    "pancho_dates = [230908,230609,231211]\n",
    "diego_dates = [230530,230730,231201]\n",
    "error_listd = []\n",
    "error_listp = []\n",
    "for d,p in zip(diego_dates,pancho_dates):\n",
    "    try:\n",
    "        diego_MS_dict[d]= load_mult_session_helper(d,'Diego')\n",
    "    except:\n",
    "        error_listd.append(d)\n",
    "    try:\n",
    "        pancho_MS_dict[p] = load_mult_session_helper(p,'Pancho')\n",
    "    except:\n",
    "        error_listp.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Diego*/*231201*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Diego/231201/Diego-231201-155653\n",
      "session:  0\n",
      "Beh Sessions that exist on this date:  {231201: [(1, 'chardiego2c')]}\n",
      "------------------------------\n",
      "Loading this neural session: 0\n",
      "Loading these beh expts: ['chardiego2c']\n",
      "Loading these beh sessions: [1]\n",
      "Using this beh_trial_map_list: [(1, 0)]\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Diego*/*231201*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Diego/231201/Diego-231201-155653\n",
      "{'filename_components_hyphened': ['Diego', '231201', '155653'], 'basedirs': ['/home/danhan/freiwaldDrive/ltian/recordings/Diego', '/home/danhan/freiwaldDrive/ltian/recordings/Diego/231201'], 'basedirs_filenames': ['231201', 'Diego-231201-155653'], 'filename_final_ext': 'Diego-231201-155653', 'filename_final_noext': 'Diego-231201-155653'}\n",
      "FOund this path for spikes:  /home/danhan/freiwaldDrive/ltian/recordings/Diego/231201/Diego-231201-155653/spikes_tdt_quick-4\n",
      "== PATHS for this expt: \n",
      "raws  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/231201/Diego-231201-155653\n",
      "tank  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/231201/Diego-231201-155653/Diego-231201-155653\n",
      "spikes  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/231201/Diego-231201-155653/spikes_tdt_quick-4\n",
      "final_dir_name  --  Diego-231201-155653\n",
      "time  --  155653\n",
      "pathbase_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653\n",
      "tank_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/data_tank.pkl\n",
      "spikes_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/data_spikes.pkl\n",
      "datall_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/data_datall.pkl\n",
      "events_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/events_photodiode.pkl\n",
      "mapper_st2dat_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/mapper_st2dat.pkl\n",
      "figs_local  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/figs\n",
      "metadata_units  --  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units_Diego\n",
      "cached_dir  --  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/cached\n",
      "Sites metada path doesnt exist:  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units/231201.yaml\n",
      "updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_garbage\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_error_spikes\n",
      "Printing whether spikes gotten (o) or not (-) because of spike peak to trough\n",
      "== Loading TDT tank\n",
      "** Loading tank data from local (previusly cached)\n",
      "== Done\n",
      "** MINIMAL_LOADING, therefore loading previuosly cached data\n",
      "== Trying to load events data\n",
      "Loading this events (pd) locally to:  /data4/dan/neural_preprocess/recordings/Diego/231201/Diego-231201-155653/events_photodiode.pkl\n",
      "== Done\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat/*231201-*Diego.**\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/*231201-*Diego.**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/chardiego2c-231201-Diego.yaml\n",
      "Loading this dataset Diego chardiego2c 231201\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/*Diego-*chardiego2c-*231201-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/BEH/*Diego-*chardiego2c-*231201-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/*Diego-*chardiego2c-*231201-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/*Diego-*chardiego2c-*231201-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Diego-chardiego2c-231201-231201_225842\n",
      "----------------\n",
      "Currently loading dataset pkl: /home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Diego-chardiego2c-231201-231201_225842\n",
      ".. Done!\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 231201, 'edate': 231201, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'231201': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['chardiego2c'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'chardiego2c', 'animal': 'Diego', 'ssess': None, 'esess': None, 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Diego', 'basedir': '/home/kgg/mnt/Freiwald/kgupta/macaque_data', 'sample_rate': array([500.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 18: 'end', 19: 'FixationRaiseFailWTH', 20: 'go (draw)', 21: 'guide_on_GA', 22: 'guide_on_GA_delay', 30: 'DelayWhatIsThis', 40: 'GoWhatIsThis', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 52: 'WaitThenHold_LT_reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 64: 'DragAroundAbort', 65: 'DragAroundFirstAbortNow', 70: 'hotkey_x', 71: 'DAstimevent_firstpres', 72: 'DAstimoff_finibeforepause', 73: 'DAstimoff_fini', 74: 'DAsamp1_visible_change', 75: 'DAnewpnutthisframe', 76: 'DAsound_samp1touched', 78: 'DAsound_gotallink', 80: 'ttl_trialon', 81: 'ttl_trialoff', 91: 'GAstimevent_firstpres', 92: 'GAstimoff_fini', 93: 'GAstimeventDelay_firstpres', 94: 'GAstimoffDelay_fini', 101: 'fix_square_on', 102: 'fix_square_off', 103: 'fix_square_on_pd', 111: 'photodiode_force_off', 120: 'DAsound_chunk', 121: 'DAsound_strokedone', 122: 'DAsound_chunkupdate', 123: 'DAsound_chunkdone', 124: 'DAsound_firstraise', 131: 'fix_cue_colored_on', 132: 'fix_cue_colored_on_v2', 133: 'fix_cue_colored_off', 134: 'fix_cue_colored_off_v2', 135: 'new_color_cue_off', 141: 'estim_ttl_1_on', 142: 'estim_ttl_2_on', 151: 'estim_ttl_stroke_on', 152: 'estim_ttl_stroke_off', 200: 'skipped_movie_frame'}, 'screen_hz': 59, 'screen_period': 0.01694915254237288}}\n",
      "Loading BlockParamsByDateSessBlock!\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m diego_MS_dict\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m----> 2\u001b[0m diego_MS_dict[\u001b[38;5;241m231201\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mload_mult_session_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m231201\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDiego\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/session.py:152\u001b[0m, in \u001b[0;36mload_mult_session_helper\u001b[0;34m(DATE, animal, dataset_beh_expt, expt, MINIMAL_LOADING, units_metadat_fail_if_no_exist, spikes_version, fr_sm_std)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession: \u001b[39m\u001b[38;5;124m\"\u001b[39m, rec_session)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# ============= RUN\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# beh_session = rec_session+1 # 1-indexing.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# sessdict = mkl.getSessionsList(animal, datelist=[date])\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# print(\"ALL SESSIONS: \")\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# print(sessdict)\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m SN \u001b[38;5;241m=\u001b[39m \u001b[43mload_session_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_beh_expt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrec_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMINIMAL_LOADING\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMINIMAL_LOADING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43munits_metadat_fail_if_no_exist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits_metadat_fail_if_no_exist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspikes_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspikes_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_sm_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfr_sm_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m SNlist\u001b[38;5;241m.\u001b[39mappend(SN)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted successfully for session: \u001b[39m\u001b[38;5;124m\"\u001b[39m, rec_session)\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/session.py:258\u001b[0m, in \u001b[0;36mload_session_helper\u001b[0;34m(DATE, dataset_beh_expt, rec_session, animal, expt, do_all_copy_to_local, extract_spiketrain_elephant, DEBUG_TIMING, MINIMAL_LOADING, BAREBONES_LOADING, ACTUALLY_BAREBONES_LOADING, units_metadat_fail_if_no_exist, do_if_spikes_incomplete, spikes_version, fr_sm_std)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# # Hard code sessions where multiple sec sessions to a single beh session, this leads to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# # error where the rec sessions doesnt know which beh trial to start at.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# if animal==\"Pancho\" and int(DATE)==221024 and rec_session==1:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m#     print(sessdict[DATE])\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m#     assert False\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m     SN \u001b[38;5;241m=\u001b[39m \u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeh_expt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeh_sess_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeh_trial_map_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43manimal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrec_session\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrec_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_beh_expt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_beh_expt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextract_spiketrain_elephant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_spiketrain_elephant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_all_copy_to_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_all_copy_to_local\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEBUG_TIMING\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEBUG_TIMING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMINIMAL_LOADING\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMINIMAL_LOADING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBAREBONES_LOADING\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBAREBONES_LOADING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43munits_metadat_fail_if_no_exist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits_metadat_fail_if_no_exist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_if_spikes_incomplete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_if_spikes_incomplete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mACTUALLY_BAREBONES_LOADING\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACTUALLY_BAREBONES_LOADING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspikes_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspikes_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_sm_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfr_sm_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DataMisalignError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ALLOW_RETRY:\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/session.py:574\u001b[0m, in \u001b[0;36mSession.__init__\u001b[0;34m(self, datestr, beh_expt_list, beh_sess_list, beh_trial_map_list, sites_garbage, expt, animal, path_base, path_local, rec_session, do_all_copy_to_local, extract_spiketrain_elephant, do_sanity_checks, do_sanity_checks_rawdupl, dataset_beh_expt, DEBUG_TIMING, MINIMAL_LOADING, BAREBONES_LOADING, ACTUALLY_BAREBONES_LOADING, units_metadat_fail_if_no_exist, do_if_spikes_incomplete, spikes_version, fr_sm_std)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== Done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MINIMAL_LOADING:\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# Load dataset beh\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_savelocalcached_load_dataset_beh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# Hacky things to do, since cannot do in oeroginal extract of dataset.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDatasetbeh\u001b[38;5;241m.\u001b[39msupervision_epochs_extract_orig()\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/session.py:2042\u001b[0m, in \u001b[0;36mSession._savelocalcached_load_dataset_beh\u001b[0;34m(self, dataset_version)\u001b[0m\n\u001b[1;32m   2040\u001b[0m datasetbeh_exptname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# None was used orignally during extraction. This means use daily dataset.\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;66;03m# self.datasetbeh_load_helper(self.DatasetbehExptname, FORCE_AFTER_MINIMAL=True)\u001b[39;00m\n\u001b[0;32m-> 2042\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasetbeh_load_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasetbeh_exptname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;66;03m# Clear cached beh data that might now be innacurate.\u001b[39;00m\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CachedStrokesPeanutsOnly \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/session.py:5366\u001b[0m, in \u001b[0;36mSession.datasetbeh_load_helper\u001b[0;34m(self, dataset_beh_expt)\u001b[0m\n\u001b[1;32m   5361\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   5362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   5363\u001b[0m         \u001b[38;5;66;03m# If that doesnt work, then use the daily dataset, which \u001b[39;00m\n\u001b[1;32m   5364\u001b[0m         \u001b[38;5;66;03m# is generated autmatoiocalyl (after like sep 2022)\u001b[39;00m\n\u001b[1;32m   5365\u001b[0m         \u001b[38;5;66;03m# self.datasetbeh_load(version=\"daily\", FORCE_AFTER_MINIMAL=FORCE_AFTER_MINIMAL) # daily\u001b[39;00m\n\u001b[0;32m-> 5366\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasetbeh_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdaily\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# daily\u001b[39;00m\n\u001b[1;32m   5367\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**Loaded dataset! daily\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5368\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5369\u001b[0m         \u001b[38;5;66;03m# Try loading using \"null\" rule, which is common\u001b[39;00m\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/session.py:5416\u001b[0m, in \u001b[0;36mSession.datasetbeh_load\u001b[0;34m(self, dataset_beh_expt, version)\u001b[0m\n\u001b[1;32m   5411\u001b[0m \u001b[38;5;66;03m# if not FORCE_AFTER_MINIMAL:\u001b[39;00m\n\u001b[1;32m   5412\u001b[0m \u001b[38;5;66;03m#     assert self.DatAll is not None, \"need to load first, run SN.extract_raw_and_spikes_helper()\"\u001b[39;00m\n\u001b[1;32m   5413\u001b[0m \n\u001b[1;32m   5414\u001b[0m \u001b[38;5;66;03m# 1) Load Dataset\u001b[39;00m\n\u001b[1;32m   5415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 5416\u001b[0m     D \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_daily_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAnimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5417\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m version\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   5418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDatasetbehExptname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5419\u001b[0m         \u001b[38;5;66;03m# you must enter it\u001b[39;00m\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/dataset/dataset.py:68\u001b[0m, in \u001b[0;36mload_dataset_daily_helper\u001b[0;34m(animal, date, rename_shapes_if_cluster_labels_exist, label_as_novel_if_shape_semantic_fails_overwrite)\u001b[0m\n\u001b[1;32m     66\u001b[0m expt \u001b[38;5;241m=\u001b[39m list_metadat[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading this dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, animal, expt, date)\n\u001b[0;32m---> 68\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_notdaily_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrulelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mrename_shapes_if_cluster_labels_exist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrename_shapes_if_cluster_labels_exist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlabel_as_novel_if_shape_semantic_fails_overwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_as_novel_if_shape_semantic_fails_overwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(D, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokensStrokesBeh\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow is this possible? It should have run tokens_generate_replacement_quick_from_beh...\u001b[39m\u001b[38;5;124m\"\u001b[39m    \n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m D\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/dataset/dataset.py:103\u001b[0m, in \u001b[0;36mload_dataset_notdaily_helper\u001b[0;34m(animal, expt, rulelist, return_rulelist, rename_shapes_if_cluster_labels_exist, label_as_novel_if_shape_semantic_fails_overwrite)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rulelist, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    102\u001b[0m D \u001b[38;5;241m=\u001b[39m Dataset([])\n\u001b[0;32m--> 103\u001b[0m \u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmult\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrulelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mrename_shapes_if_cluster_labels_exist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrename_shapes_if_cluster_labels_exist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mlabel_as_novel_if_shape_semantic_fails_overwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_as_novel_if_shape_semantic_fails_overwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(D, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokensStrokesBeh\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow is this possible? It should have run tokens_generate_replacement_quick_from_beh...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_rulelist:\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/dataset/dataset.py:246\u001b[0m, in \u001b[0;36mDataset.load_dataset_helper\u001b[0;34m(self, animal, expt, ver, rule, rename_shapes_if_cluster_labels_exist, label_as_novel_if_shape_semantic_fails_overwrite)\u001b[0m\n\u001b[1;32m    244\u001b[0m                 pathlist\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_dataset(a, e, \u001b[38;5;28;01mTrue\u001b[39;00m, rule\u001b[38;5;241m=\u001b[39mr))\n\u001b[1;32m    245\u001b[0m                 aer_list\u001b[38;5;241m.\u001b[39mappend((a,e,r))\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manimal_expt_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maer_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/dataset/dataset.py:296\u001b[0m, in \u001b[0;36mDataset._main_loader\u001b[0;34m(self, inputs, append_list, animal_expt_rule)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataframes(inputs, append_list)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reloading_saved_state:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cleanup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_dot_strokes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParamsCleanup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mremove_dot_strokes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_online_abort\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParamsCleanup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mremove_online_abort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_bad_strokes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43msmooth_strokes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_consistency()\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/dataset/dataset.py:3649\u001b[0m, in \u001b[0;36mDataset._cleanup\u001b[0;34m(self, remove_dot_strokes, remove_online_abort, remove_bad_strokes, smooth_strokes)\u001b[0m\n\u001b[1;32m   3646\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved online aborts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;66;03m################ STROKES\u001b[39;00m\n\u001b[0;32m-> 3649\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_strokes_all_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_dot_strokes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_bad_strokes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3650\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msmooth_strokes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;66;03m################# OTHER STUFF\u001b[39;00m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDat\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/dataset/dataset.py:3998\u001b[0m, in \u001b[0;36mDataset.cleanup_strokes_all_wrapper\u001b[0;34m(self, remove_dot_strokes, remove_bad_strokes, smooth_strokes)\u001b[0m\n\u001b[1;32m   3996\u001b[0m \u001b[38;5;66;03m# Second, remove dist=0 strokes\u001b[39;00m\n\u001b[1;32m   3997\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpythonlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdrawmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strokeDistances\n\u001b[0;32m-> 3998\u001b[0m list_d \u001b[38;5;241m=\u001b[39m \u001b[43mstrokeDistances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrokes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3999\u001b[0m strokes \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s,d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(strokes, list_d) \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m>\u001b[39mdist_min]\n\u001b[1;32m   4001\u001b[0m strokeslist[i] \u001b[38;5;241m=\u001b[39m strokes\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/drawmodel/features.py:88\u001b[0m, in \u001b[0;36mstrokeDistances\u001b[0;34m(strokes)\u001b[0m\n\u001b[1;32m     86\u001b[0m     d \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(s1\u001b[38;5;241m-\u001b[39ms2) \u001b[38;5;28;01mfor\u001b[39;00m s1, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(s[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:\u001b[38;5;241m2\u001b[39m], s[\u001b[38;5;241m1\u001b[39m:,:\u001b[38;5;241m2\u001b[39m])]\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(d)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [D(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strokes]\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/drawmodel/features.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m     d \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(s1\u001b[38;5;241m-\u001b[39ms2) \u001b[38;5;28;01mfor\u001b[39;00m s1, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(s[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:\u001b[38;5;241m2\u001b[39m], s[\u001b[38;5;241m1\u001b[39m:,:\u001b[38;5;241m2\u001b[39m])]\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(d)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strokes]\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/drawmodel/features.py:86\u001b[0m, in \u001b[0;36mstrokeDistances.<locals>.D\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mD\u001b[39m(s):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# s is one np.array, N by 3, N = timepoints.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# adds up sum of distnace btween adjacent points\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     d \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(s1\u001b[38;5;241m-\u001b[39ms2) \u001b[38;5;28;01mfor\u001b[39;00m s1, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(s[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:\u001b[38;5;241m2\u001b[39m], s[\u001b[38;5;241m1\u001b[39m:,:\u001b[38;5;241m2\u001b[39m])]\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(d)\n",
      "File \u001b[0;32m~/code/pythonlib/pythonlib/drawmodel/features.py:86\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mD\u001b[39m(s):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# s is one np.array, N by 3, N = timepoints.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# adds up sum of distnace btween adjacent points\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     d \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s1, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(s[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:\u001b[38;5;241m2\u001b[39m], s[\u001b[38;5;241m1\u001b[39m:,:\u001b[38;5;241m2\u001b[39m])]\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(d)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "diego_MS_dict[231201] = load_mult_session_helper(231201,'Diego')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Diego*/*230918*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Diego/230918/Diego-230918-150357\n",
      "session:  0\n",
      "Beh Sessions that exist on this date:  {230918: [(1, 'dirgrammardiego8b')]}\n",
      "------------------------------\n",
      "Loading this neural session: 0\n",
      "Loading these beh expts: ['dirgrammardiego8b']\n",
      "Loading these beh sessions: [1]\n",
      "Using this beh_trial_map_list: [(1, 0)]\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/*Diego*/*230918*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/ltian/recordings/Diego/230918/Diego-230918-150357\n",
      "{'filename_components_hyphened': ['Diego', '230918', '150357'], 'basedirs': ['/home/danhan/freiwaldDrive/ltian/recordings/Diego', '/home/danhan/freiwaldDrive/ltian/recordings/Diego/230918'], 'basedirs_filenames': ['230918', 'Diego-230918-150357'], 'filename_final_ext': 'Diego-230918-150357', 'filename_final_noext': 'Diego-230918-150357'}\n",
      "FOund this path for spikes:  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230918/Diego-230918-150357/spikes_tdt_quick-4\n",
      "== PATHS for this expt: \n",
      "raws  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230918/Diego-230918-150357\n",
      "tank  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230918/Diego-230918-150357/Diego-230918-150357\n",
      "spikes  --  /home/danhan/freiwaldDrive/ltian/recordings/Diego/230918/Diego-230918-150357/spikes_tdt_quick-4\n",
      "final_dir_name  --  Diego-230918-150357\n",
      "time  --  150357\n",
      "pathbase_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357\n",
      "tank_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/data_tank.pkl\n",
      "spikes_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/data_spikes.pkl\n",
      "datall_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/data_datall.pkl\n",
      "events_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/events_photodiode.pkl\n",
      "mapper_st2dat_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/mapper_st2dat.pkl\n",
      "figs_local  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/figs\n",
      "metadata_units  --  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units_Diego\n",
      "cached_dir  --  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/cached\n",
      "Sites metada path doesnt exist:  /home/danhan/code/neuralmonkey/neuralmonkey/metadat/units/230918.yaml\n",
      "updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_garbage\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_error_spikes\n",
      "Printing whether spikes gotten (o) or not (-) because of spike peak to trough\n",
      "== Loading TDT tank\n",
      "** Loading tank data from local (previusly cached)\n",
      "== Done\n",
      "** MINIMAL_LOADING, therefore loading previuosly cached data\n",
      "== Trying to load events data\n",
      "Loading this events (pd) locally to:  /data4/dan/neural_preprocess/recordings/Diego/230918/Diego-230918-150357/events_photodiode.pkl\n",
      "== Done\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat/*230918-*Diego.**\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/*230918-*Diego.**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/code/drawmonkey/expt_metadat_daily/dirgrammardiego8b-230918-Diego.yaml\n",
      "Loading this dataset Diego dirgrammardiego8b 230918\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/*Diego-*dirgrammardiego8b-*230918-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/BEH/*Diego-*dirgrammardiego8b-*230918-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/*Diego-*dirgrammardiego8b-*230918-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/*Diego-*dirgrammardiego8b-*230918-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Diego-dirgrammardiego8b-230918-230918_224557\n",
      "----------------\n",
      "Currently loading dataset pkl: /home/danhan/freiwaldDrive/kgupta/analyses/database/BEH/Diego-dirgrammardiego8b-230918-230918_224557\n",
      ".. Done!\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 230918, 'edate': 230918, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'230918': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['dirgrammardiego8b'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'dirgrammardiego8b', 'animal': 'Diego', 'ssess': None, 'esess': None, 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Diego', 'basedir': '/home/kgg/mnt/Freiwald/kgupta/macaque_data', 'sample_rate': array([500.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 18: 'end', 19: 'FixationRaiseFailWTH', 20: 'go (draw)', 21: 'guide_on_GA', 30: 'DelayWhatIsThis', 40: 'GoWhatIsThis', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 52: 'WaitThenHold_LT_reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 64: 'DragAroundAbort', 65: 'DragAroundFirstAbortNow', 70: 'hotkey_x', 71: 'DAstimevent_firstpres', 72: 'DAstimoff_finibeforepause', 73: 'DAstimoff_fini', 74: 'DAsamp1_visible_change', 75: 'DAnewpnutthisframe', 76: 'DAsound_samp1touched', 78: 'DAsound_gotallink', 80: 'ttl_trialon', 81: 'ttl_trialoff', 91: 'GAstimevent_firstpres', 92: 'GAstimoff_fini', 101: 'fix_square_on', 102: 'fix_square_off', 103: 'fix_square_on_pd', 111: 'photodiode_force_off', 120: 'DAsound_chunk', 121: 'DAsound_strokedone', 122: 'DAsound_chunkupdate', 123: 'DAsound_chunkdone', 124: 'DAsound_firstraise', 131: 'fix_cue_colored_on', 132: 'fix_cue_colored_on_v2', 133: 'fix_cue_colored_off', 134: 'fix_cue_colored_off_v2', 135: 'new_color_cue_off', 200: 'skipped_movie_frame'}, 'screen_hz': 59, 'screen_period': 0.01694915254237288}}\n",
      "Loading BlockParamsByDateSessBlock!\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n",
      "* UDPATEING onset of first stroke [too close to fixation] (trial, new onset index):\n",
      "-- CHECKING  origin\n",
      "--- idat, trialcode, strok inds to remove, len strokes beofre remofe, len strokes after:\n",
      "-- CHECKING  donepos\n",
      "--- idat, trialcode, strok inds to remove, len strokes beofre remofe, len strokes after:\n",
      "Updated columns: insummarydates, using Metadats\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/dhanuska/analyses/database/TASKS_GENERAL/Diego-dirgrammardiego8b-230918-all/*Tasks*pkl\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/TASKS_GENERAL/Diego-dirgrammardiego8b-230918-all/*Tasks*pkl\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/danhan/freiwaldDrive/kgupta/analyses/database/TASKS_GENERAL/Diego-dirgrammardiego8b-230918-all/Tasks.pkl\n",
      "--- Loading tasks pkl file:  /home/danhan/freiwaldDrive/kgupta/analyses/database/TASKS_GENERAL/Diego-dirgrammardiego8b-230918-all/Tasks.pkl\n",
      "added new column self.Dat[Task]\n",
      "=== CLEANING UP self.Dat (_cleanup_reloading_saved_state) ===== \n",
      "- starting/ending len (grouping params):\n",
      "663\n",
      "Extracting Behclass for each trial, may take a while...\n",
      "0 _behclass_alignsim_compute\n",
      "200 _behclass_alignsim_compute\n",
      "400 _behclass_alignsim_compute\n",
      "600 _behclass_alignsim_compute\n",
      "Running D._behclass_tokens_extract_datsegs\n",
      "TODO: Pancho -- combine circles with the tohers\n",
      "0 _behclass_tokens_extract_datsegs\n",
      "200 _behclass_tokens_extract_datsegs\n",
      "400 _behclass_tokens_extract_datsegs\n",
      "600 _behclass_tokens_extract_datsegs\n",
      "stored in self.Dat[BehClass]\n",
      "Removing these trials: \n",
      "[]\n",
      "self.Dat starting legnth:  663\n",
      "Modified self.Dat, keeping only the inputted inds\n",
      "self.Dat final legnth:  663\n",
      " \n",
      "*** Rules/epochs reassigning using the following rules:\n",
      "{(None, None): 'base', ('direction', '3.14'): 'L', ('direction', '0.00'): 'R', ('directionv2', ('lr',)): 'R', ('directionv2', ('rl',)): 'L', ('directionv2', ('ud',)): 'D', ('directionv2', ('du',)): 'U', ('directionv2', ('right',)): 'R', ('directionv2', ('left',)): 'L', ('directionv2', ('down',)): 'D', ('directionv2', ('up',)): 'U', ('directionv2', ('topright',)): 'TR', ('directionv2', ('topleft',)): 'TL', ('directionv2', ('UL',)): 'UL', ('prot_prims_in_order', ('line-8-3', 'V-2-4', 'Lcentered-4-3')): 'lVL1', ('prot_prims_in_order', ('Lcentered-4-3', 'V-2-4', 'line-8-3')): 'LVl1', ('prot_prims_in_order', ('V-2-4', 'line-8-3', 'Lcentered-4-3')): 'VlL1', ('prot_prims_in_order', ('line-8-3', 'line-8-4', 'V-2-4')): 'llV1a', ('prot_prims_in_order', ('line-9-3', 'line-9-4', 'Lcentered-6-8')): 'llV1b', ('prot_prims_in_order', ('line-8-3', 'line-13-13', 'line-8-4', 'line-13-14', 'V-2-4', 'V2-2-4')): 'llV1c', ('prot_prims_in_order', ('line-8-3', 'line-13-13', 'line-8-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2')): 'llV1d', ('prot_prims_in_order', ('V2-2-2', 'V2-2-4', 'V-2-4', 'line-13-14', 'line-8-4', 'line-13-13', 'line-8-3')): 'llV1R', ('prot_prims_in_order', ('zigzagSq-1-1', 'line-8-1', 'arcdeep-4-3')): 'ZlA1', ('prot_prims_in_order', ('zigzagSq-1-1', 'line-8-1', 'line-9-1', 'arcdeep-4-3')): 'ZlA1', ('prot_prims_in_order', ('zigzagSq-1-1', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3')): 'ZlA1', ('prot_prims_in_order', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3')): 'ZlA1', ('prot_prims_in_order', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3')): 'ZlA1', ('prot_prims_in_order', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4')): 'ZlA1', ('prot_prims_chunks_in_order', ('line-8-4', 'line-8-3')): 'AnBm1a', ('prot_prims_chunks_in_order', ('line-8-1', 'line-8-2')): 'AnBm2', ('prot_prims_chunks_in_order', ('line-8-4', 'line-11-1', 'line-8-3', 'line-11-2')): 'AnBm1b', ('prot_prims_chunks_in_order', ('line-11-1', 'line-11-2')): 'AnBmHV', ('prot_prims_chunks_in_order', ('squiggle3-3-1', 'V-2-4')): 'AnBm0', ('hack_220829', ('hack_220829',)): '(AB)n', ('prot_prims_in_order_AND_directionv2', ('line-8-4', 'line-11-1', 'line-8-3', 'line-11-2', 'topright')): 'AnBmTR', ('prot_prims_in_order_AND_directionv2', ('line', 'circle', 'right')): 'LCr1', ('prot_prims_in_order_AND_directionv2', ('circle', 'line', 'right')): 'CLr1', ('prot_prims_in_order_AND_directionv2', ('line', 'arcdeep', 'circle', 'right')): 'LCr2', ('prot_prims_in_order_AND_directionv2', ('circle', 'arcdeep', 'line', 'right')): 'CLr2', ('prot_prims_in_order_AND_directionv2', ('line', 'arcdeep', 'circle', 'downright')): 'LCr3', ('prot_prims_in_order_AND_directionv2', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'topleft')): 'llCV1', ('prot_prims_in_order_AND_directionv2', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'left')): 'llCV2', ('prot_prims_in_order_AND_directionv2_FIRSTSTROKEONLY', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'left')): 'llCV2FstStk', ('prot_prims_in_order_AND_directionv2', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'UL')): 'llCV3', ('prot_prims_in_order_AND_directionv2', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-14-2', 'line-8-1', 'line-9-1', 'line-6-1', 'line-14-1', 'arcdeep-4-3', 'V-2-4', 'UL')): 'llCV3b', ('prot_prims_in_order_AND_directionv2_FIRSTSTROKEONLY', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'UL')): 'llCV3FstStk', ('prot_prims_in_order_AND_directionv2', ('line-8-3', 'line-13-13', 'line-8-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'left')): 'AnBmCk1a', ('prot_prims_in_order_AND_directionv2', ('line-8-3', 'line-13-13', 'line-8-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'left')): 'AnBmCk1b', ('prot_prims_in_order_AND_directionv2', ('line-8-3', 'line-13-13', 'line-8-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'left')): 'AnBmCk1c', ('prot_prims_in_order_AND_directionv2', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2', 'left')): 'AnBmCk2', ('prot_prims_in_order_AND_directionv2', ('Lcentered-4-2', 'V-2-4', 'line-8-2', 'arcdeep-4-2', 'usquare-1-3', 'UR')): 'SSD1b', ('prot_prims_in_order_AND_directionv2', ('Lcentered-4-2', 'V-2-4', 'line-8-2', 'arcdeep-4-2', 'arcdeep-4-2', 'usquare-1-3', 'UR')): 'SSD1', ('prot_prims_in_order_AND_directionv2', ('Lcentered-4-2', 'V-2-4', 'line-8-2', 'arcdeep-4-2', 'Lcentered-4-1', 'usquare-1-3', 'UR')): 'SSD2', ('prot_prims_in_order_AND_directionv2', ('Lcentered-4-2', 'V-2-4', 'line-8-2', 'arcdeep-4-2', 'Lcentered-4-1', 'circle-6-1', 'usquare-1-3', 'UR')): 'SSD3', ('prot_prims_in_order_AND_directionv2', ('arcdeep-4-2', 'Lcentered-4-1', 'line-8-2', 'circle-6-1', 'V-2-4', 'usquare-1-3', 'Lcentered-4-2', 'UR')): 'SSD4', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('arcdeep-4-2', 'Lcentered-4-1', 'line-8-2', 'circle-6-1', 'V-2-4', 'usquare-1-3', 'Lcentered-4-2', 'UR', (), ())): 'SSD4Rnd', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('arcdeep-4-2', 'Lcentered-4-1', 'line-8-2', 'circle-6-1', 'V-2-4', 'usquare-1-3', 'Lcentered-4-2', 'UR', (1,), (2, 3))): 'SSD4RndFlx1', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('arcdeep-4-2', 'Lcentered-4-1', 'line-8-2', 'circle-6-1', 'V-2-4', 'usquare-1-3', 'Lcentered-4-2', 'UR', (), (1,))): 'SSD4RndFlx2', ('prot_prims_in_order_AND_directionv2', ('arcdeep-4-1', 'V-2-4', 'line-8-4', 'V-2-2', 'Lcentered-4-3', 'UL')): 'SSP1', ('prot_prims_in_order_AND_directionv2', ('arcdeep-4-1', 'line-8-3', 'V-2-4', 'line-8-4', 'V-2-2', 'Lcentered-4-3', 'UL')): 'SSP2', ('prot_prims_in_order_AND_directionv2', ('V-2-4', 'Lcentered-4-3', 'V-2-2', 'line-8-3', 'arcdeep-4-1', 'line-8-4', 'UL')): 'SSP3', ('prot_prims_in_order_AND_directionv2', ('V-2-4', 'Lcentered-4-3', 'V-2-2', 'line-8-3', 'arcdeep-4-1', 'line-8-4', 'line-8-1', 'UL')): 'SSP4', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('V-2-4', 'Lcentered-4-3', 'V-2-2', 'line-8-3', 'arcdeep-4-1', 'line-8-4', 'line-8-1', 'UL', (), ())): 'SSP4Rnd', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('V-2-4', 'Lcentered-4-3', 'V-2-2', 'line-8-3', 'arcdeep-4-1', 'line-8-4', 'line-8-1', 'UL', (1,), (2, 3))): 'SSP4RndFlx1', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('V-2-4', 'Lcentered-4-3', 'V-2-2', 'line-8-3', 'arcdeep-4-1', 'line-8-4', 'line-8-1', 'UL', (), (1,))): 'SSP4RndFlx2', ('prot_prims_chunks_in_order', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2')): 'AnBmCk2NODIR', ('prot_prims_in_order_AND_directionv2_FIRSTSTROKEONLY', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2', 'left')): 'AnBmCk2FstStk', ('prot_prims_in_order_AND_directionv2_FIRSTSTROKEEXCLUDE', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2', 'left')): 'AnBmCk2NOFstStk', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'UL', (1,), (2, 3, 4, 5))): 'llCV3RndFlx1', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'UL', (1, 2), (3, 4, 5))): 'llCV3RndFlx12', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('zigzagSq-1-1', 'Lcentered-4-4', 'line-6-2', 'line-8-1', 'line-9-1', 'line-6-1', 'arcdeep-4-3', 'V-2-4', 'UL', (1, 2, 3), (4, 5))): 'llCV3RndFlx123', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2', 'left', (), (1, 2, 3, 4))): 'AnBmCk2RndFlx0', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2', 'left', (1,), (2, 3, 4))): 'AnBmCk2RndFlx1', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('line-8-3', 'line-6-3', 'line-13-13', 'line-8-4', 'line-6-4', 'line-13-14', 'V-2-4', 'V2-2-4', 'V2-2-2', 'line-8-1', 'line-8-2', 'line-6-1', 'line-6-2', 'left', (1, 2), (3, 4))): 'AnBmCk2RndFlx12', ('prot_prims_in_order_AND_directionv2', ('V-2-2', 'line-6-2', 'line-14-2', 'line-8-1', 'line-9-1', 'line-6-1', 'line-14-1', 'arcdeep-4-3', 'V-2-4', 'Lcentered-4-2', 'Lcentered-4-3', 'UL')): 'gramD4', ('prot_prims_in_order_AND_directionv2', ('line-8-3', 'line-8-4', 'line-14-1', 'right')): 'gramP2', ('prot_prims_in_order_AND_directionv2', ('line-8-3', 'line-8-4', 'line-14-1', 'line-15-1', 'right')): 'gramP2b', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('line-8-3', 'line-8-4', 'line-14-1', 'line-15-1', 'right', (), (1, 2, 3, 4, 5))): 'gramP2bRnd', ('prot_prims_in_order_AND_directionv2_FLEXSTROKES', ('line-8-3', 'line-8-4', 'line-14-1', 'line-15-1', 'right', (1,), (2, 3, 4, 5))): 'gramP2bRndFlx1', ('shape_chunk_concrete', ('lolli', ('D', 'R'))): 'LolDR', ('rows_direction', ('down', 'right')): 'rowsDR', ('rows_direction', ('up', 'left')): 'rowsUL', ('rows_direction', ('up', 'snkLR')): 'rowsUsnkLR', ('cols_direction', ('right', 'down')): 'colsRD', ('cols_direction', ('left', 'up')): 'colsLU', ('randomize_strokes', ('randomize_strokes',)): 'rndstr', ('specific_order', ('indices',)): 'SpcOrd1'}\n",
      "Modified D.Dat[epoch]\n",
      "These counts for epochs levels: \n",
      "epoch\n",
      "llCV3    286\n",
      "UL       276\n",
      "base     101\n",
      "Name: count, dtype: int64\n",
      "These counts for epoch_rule_tasksequencer levels: \n",
      "epoch_rule_tasksequencer\n",
      "llCV3    286\n",
      "UL       276\n",
      "base     101\n",
      "Name: count, dtype: int64\n",
      " \n",
      "appended col to self.Dat:\n",
      "epoch_color\n",
      "Reassigned rules taking conjucntion of old rules x color instruction\n",
      "New epochs\n",
      "epoch_color\n",
      "llCV3|0    286\n",
      "UL|0       276\n",
      "base|0     101\n",
      "Name: count, dtype: int64\n",
      "For these epochs, replacing epoch with epoch_color:\n",
      "[]\n",
      "ADded new column: supervision_online\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_SEQUENCE_ALPHA]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "Appended self.Dat[superv_VISUALFB_METH]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_new\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_concise\n",
      "Append column to self.Dat:  supervision_stage_semantic\n",
      "Extracted into self.Dat[epoch_orig]\n",
      "Modified self.Dat[epoch]\n",
      "663\n",
      "- starting/ending len (getting sequence):\n",
      "663\n",
      "663\n",
      "--- Removing nans\n",
      "start len: 663\n",
      "- num names for each col\n",
      "not removing nans, since columns=[]\n",
      "Reassigned train/test, using key: supervision_online\n",
      "and values:\n",
      "Train =  [True]\n",
      "Test =  [False]\n",
      " \n",
      "New distribution of train/test:\n",
      "monkey_train_or_test\n",
      "test     645\n",
      "train     18\n",
      "Name: count, dtype: int64\n",
      "Appended column: los_info and los_set \n",
      "Computing features each probe\n",
      "[taskgroup_reassign_by_mapper], reassigned values in column: taskgroup\n",
      "[taskgroup_reassign_by_mapper], reassigned values in column: taskgroup\n",
      "GROUPING epoch\n",
      "GROUPING_LEVELS ['base', 'llCV3', 'UL']\n",
      "FEATURE_NAMES ['hdoffline', 'num_strokes_beh', 'num_strokes_task', 'circ', 'dist']\n",
      "SCORE_COL_NAMES []\n",
      "appended col to self.Dat:\n",
      "date_epoch\n",
      "Num nan/total, for num_strokes_task\n",
      "0 / 663\n",
      "Added these features:\n",
      "['FEAT_num_strokes_task']\n",
      "For n_clusters = 6 The average silhouette_score is : 0.5864822560919616\n",
      "For n_clusters = 7 The average silhouette_score is : 0.6406863565707376\n",
      "For n_clusters = 8 The average silhouette_score is : 0.6700383517669709\n",
      "For n_clusters = 9 The average silhouette_score is : 0.7011936770400501\n",
      "For n_clusters = 10 The average silhouette_score is : 0.7185351305721215\n",
      "For n_clusters = 11 The average silhouette_score is : 0.7574770557196695\n",
      "For n_clusters = 12 The average silhouette_score is : 0.7690815923547769\n",
      "For n_clusters = 13 The average silhouette_score is : 0.7445957774854056\n",
      "For n_clusters = 14 The average silhouette_score is : 0.7213929485616762\n",
      "For n_clusters = 15 The average silhouette_score is : 0.6547829991622566\n",
      "For n_clusters = 16 The average silhouette_score is : 0.6196201803979285\n",
      "For n_clusters = 17 The average silhouette_score is : 0.605709393401451\n",
      "For n_clusters = 18 The average silhouette_score is : 0.5715080234733291\n",
      "For n_clusters = 19 The average silhouette_score is : 0.549678404557871\n",
      "For n_clusters = 20 The average silhouette_score is : 0.5303735378903945\n",
      "For n_clusters = 21 The average silhouette_score is : 0.5015388488433807\n",
      "For n_clusters = 22 The average silhouette_score is : 0.48096495436156833\n",
      "For n_clusters = 23 The average silhouette_score is : 0.46167246155145714\n",
      "For n_clusters = 24 The average silhouette_score is : 0.4580249688037487\n",
      "For n_clusters = 25 The average silhouette_score is : 0.45331218964223735\n",
      "For n_clusters = 26 The average silhouette_score is : 0.44616395869292624\n",
      "Using n_clusters = 12\n",
      "SAVING at:  /home/danhan/freiwaldDrive/dhanuska/analyses/main/preprocess_general/Diego_230918_dirgrammardiego8b\n",
      "For n_clusters = 4 The average silhouette_score is : 0.8056352896115296\n",
      "For n_clusters = 5 The average silhouette_score is : 0.7474364207716437\n",
      "For n_clusters = 6 The average silhouette_score is : 0.647162888188151\n",
      "For n_clusters = 7 The average silhouette_score is : 0.573116994000383\n",
      "For n_clusters = 8 The average silhouette_score is : 0.5443281370097723\n",
      "For n_clusters = 9 The average silhouette_score is : 0.5495856451815812\n",
      "For n_clusters = 10 The average silhouette_score is : 0.4469996483349583\n",
      "For n_clusters = 11 The average silhouette_score is : 0.4287818499312523\n",
      "For n_clusters = 12 The average silhouette_score is : 0.41684401756993456\n",
      "For n_clusters = 13 The average silhouette_score is : 0.39362702854633996\n",
      "For n_clusters = 14 The average silhouette_score is : 0.38142518610322135\n",
      "For n_clusters = 15 The average silhouette_score is : 0.3899883140525432\n",
      "For n_clusters = 16 The average silhouette_score is : 0.3861604638775568\n",
      "For n_clusters = 17 The average silhouette_score is : 0.3798574901408203\n",
      "For n_clusters = 18 The average silhouette_score is : 0.3731502090322767\n",
      "For n_clusters = 19 The average silhouette_score is : 0.37872504273884183\n",
      "For n_clusters = 20 The average silhouette_score is : 0.37527605520945295\n",
      "For n_clusters = 21 The average silhouette_score is : 0.36936532604779976\n",
      "For n_clusters = 22 The average silhouette_score is : 0.3634974986431352\n",
      "For n_clusters = 23 The average silhouette_score is : 0.35598398130598946\n",
      "For n_clusters = 24 The average silhouette_score is : 0.3492771980095884\n",
      "For n_clusters = 25 The average silhouette_score is : 0.35897196346335153\n",
      "For n_clusters = 26 The average silhouette_score is : 0.3525009147575573\n",
      "Using n_clusters = 4\n",
      "ndims for feature loc_on = 2\n",
      "New colname in tokens: loc_on_binned\n",
      "ndims for feature angle = 1\n",
      "New colname in tokens: angle_binned\n",
      "ndims for feature center = 2\n",
      "New colname in tokens: center_binned\n",
      "ndims for feature center = 2\n",
      "New colname in tokens: center_binned\n",
      "ndims for feature center = 2\n",
      "New colname in tokens: center_binned\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "This many strokes extracted:  2235\n",
      "DONE!\n",
      "Appended epoch to self.Dat\n",
      "Appended character to self.Dat\n",
      "Basis set of strokes: ['Lcentered-4-1-0', 'Lcentered-4-2-0', 'Lcentered-4-3-0', 'Lcentered-4-4-0', 'V-2-2-0', 'V-2-3-0', 'V-2-4-0', 'arcdeep-4-2-0', 'arcdeep-4-3-0', 'arcdeep-4-4-0', 'circle-6-1-0', 'line-8-1-0', 'line-8-2-0', 'line-8-3-0', 'line-8-4-0', 'squiggle3-3-1-0', 'squiggle3-3-1-1', 'squiggle3-3-2-0', 'squiggle3-3-2-1', 'usquare-1-2-0', 'usquare-1-3-0', 'usquare-1-4-0', 'zigzagSq-1-1-0', 'zigzagSq-1-1-1', 'zigzagSq-1-2-0', 'zigzagSq-1-2-1']\n",
      "Deleting these columns with seqc in name: []\n",
      "Appended columns gridsize!\n",
      "SAVING at:  /home/danhan/freiwaldDrive/dhanuska/analyses/main/preprocess_general/Diego_230918_dirgrammardiego8b\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "This many strokes extracted:  2235\n",
      "DONE!\n",
      "Appended epoch to self.Dat\n",
      "Appended character to self.Dat\n",
      "- Keeping only dataset trials that exist in neural\n",
      "Starting length:  663\n",
      "Ending length:  663\n",
      "**Loaded dataset! daily\n",
      "Pruning events in EventsTimeUsingPhd to exclude those using datasetbeh strokes...\n",
      "Extracted into self.Dat[epoch_orig]\n",
      "-- loaded presaved data: /home/danhan/freiwaldDrive/kgupta/macaque_data/Diego/230918/230918_150322_dirgrammardiego8b_Diego_1.pkl\n",
      "Extracted successfully for session:  0\n",
      "Generated index mappers!\n"
     ]
    }
   ],
   "source": [
    "MS = load_mult_session_helper(230918,'Diego')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'230918-1-301'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pancho_dates = [230908,230609,231211]\n",
    "# diego_dates = [230530,230730,231201]\n",
    "%matplotlib qt\n",
    "# MS = diego_MS_dict[230530]\n",
    "sn = MS.SessionsList[0]\n",
    "sn._MapperTrialcode2TrialToTrial\n",
    "for sn in MS.SessionsList:\n",
    "    sn._savelocalcached_save(save_dataset_beh=False, save_datslices=False, ONLY_EXTRA_STUFF=True)\n",
    "sites = sn.sitegetterKS_all_sites()[0:1]\n",
    "trials = sn.get_trials_list(True)\n",
    "sn.datasetbeh_trial_to_trialcode(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1500x1400 with 2 Axes>, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = 300\n",
    "sn.plotwrapper_raster_oneetrial_multsites(trial,only_cam_stuff=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
