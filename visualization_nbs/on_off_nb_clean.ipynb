{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pythonlib.tools.stroketools import strokesInterpolate2, strokesFilter, smoothStrokes\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On off calculation notebook\n",
    "Same as the panchodate/diegodate nbs but this one is a bit cleaner and clearer for posterity sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaded here is the dat object that is returned from the process_data_singletrial function in the handtrack class\n",
    "with open(\"/home/danhan/freiwaldDrive/dhanuska/230126_pancho_proc_data.pkl\", 'rb') as f:\n",
    "    dfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Five point stencil for velocity and acceleration calculation\n",
    "This is an accepted method in math to calculate the velocity and acceleration for discrete data at a given point by using the surrounding points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fps(x, fs):\n",
    "    '''Five point stentil function for discrete derivative, scales to m/s auto'''\n",
    "    v = [(-x[i+2] + 8*x[i+1] - 8*x[i-1] + x[i-2])/12 for i in range(len(x)) if 2<=i<len(x)-2]\n",
    "    return np.array(v) * fs\n",
    "def fps2(x, fs):\n",
    "    '''Same as above but for second derivative scales to m/s**2 auto'''\n",
    "    a = [(-x[i+2] + 16*x[i+1] - 30*x[i] + 16*x[i-1] - x[i-2])/12 for i in range(len(x)) if 2<=i<len(x)-2]\n",
    "    return np.array(a) * fs**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heuristic based approach\n",
    "Works decently, left it here in case it become useful later. Works by using a few observed patterns in the trajectory structure. Pretty accurate but does not handle edge cases super well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dist_heuristic(x, mode):\n",
    "    '''\n",
    "    x, n,2 array with a value and a time\n",
    "    target, target value to get close in this case a mean\n",
    "    mode, onsets or offsets\n",
    "    '''\n",
    "    diffs = np.diff(np.diff(x[:,0]))\n",
    "\n",
    "    if mode == 'on':\n",
    "        #Return pt who has biggest difference from previous\n",
    "        return x[np.argmin(diffs)+1]\n",
    "    elif mode == 'off':\n",
    "        #Return pt who has biggest diff from next pt\n",
    "        return x[np.argmin(diffs)]\n",
    "    else:\n",
    "        assert False, 'give mode on or off'\n",
    "    \n",
    "def on_off_heuristics(stroke_vs, stroke_as, wind, t, mode, window_size = 0.0008):\n",
    "\n",
    "    if mode == 'on':\n",
    "        vz_lb = np.mean(stroke_vs) - window_size\n",
    "        az_ub = np.mean(stroke_as) + window_size\n",
    "        az_lb = np.mean(stroke_as) - window_size\n",
    "        above_lb = wind[:,0] >= vz_lb\n",
    "        a_in_thresh = (wind[:,1] >= az_lb) & (wind[:,1] <= az_ub)\n",
    "        above_lb_and_no_next_below = []\n",
    "\n",
    "        #Make sure all following vs are in thresh\n",
    "        next_val_true = True\n",
    "        for val in reversed(above_lb):\n",
    "            if not val:\n",
    "                next_val_true = False\n",
    "            above_lb_and_no_next_below.append(next_val_true)\n",
    "        above_lb_and_no_next_below.reverse()\n",
    "\n",
    "        #Maker sure all following as are in thresh\n",
    "        next_val_true = True\n",
    "        a_in_thresh_no_next_out = []\n",
    "        for val in reversed(a_in_thresh):\n",
    "            if not val:\n",
    "                next_val_true = False\n",
    "            a_in_thresh_no_next_out.append(next_val_true)\n",
    "        a_in_thresh_no_next_out.reverse()\n",
    "\n",
    "        prev_point_more_neg = wind[:,0] > np.roll(wind[:,0],1)\n",
    "        both = above_lb_and_no_next_below & prev_point_more_neg & a_in_thresh_no_next_out\n",
    "        both[0] = False\n",
    "        filtered = wind[both]\n",
    "        if len(filtered) == 0:\n",
    "            return [-100,0,t]\n",
    "        else:\n",
    "            pt = filtered[filtered[:,2].argsort()][0]\n",
    "            return pt\n",
    "    elif mode == 'off':\n",
    "        vz_ub = np.mean(stroke_vs) + window_size-0.0002\n",
    "        under_ub = wind[:,0] <= vz_ub\n",
    "        below_ub_and_no_prev_below = []\n",
    "        prev_val_true = True\n",
    "        for val in under_ub:\n",
    "            if not val:\n",
    "                prev_val_true = False\n",
    "            below_ub_and_no_prev_below.append(prev_val_true)\n",
    "        next_point_more_pos = wind[:,0] < np.roll(wind[:,0],-1)\n",
    "        both = below_ub_and_no_prev_below & next_point_more_pos\n",
    "        both[0] = False\n",
    "        filtered = wind[both]\n",
    "        if len(filtered) == 0:\n",
    "            return [-100,0,t]\n",
    "        else:\n",
    "            pt = filtered[filtered[:,2].argsort()][-1]\n",
    "            return pt\n",
    "    else:\n",
    "        assert False, 'give mode on or off'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize intersection method\n",
    "This method seems to work the best to find the onset/offset points. it is going to take in a data structure, dat and then at each touchscreen determined onset/offset point it will fit two lines. One line follows the trajectory of the velocity into/out of the stroke, and the other fits horizontally to the velocity in the stroke. The poiint where these lines intersect is what is taken as the onset/offset. The intuition here is that we are essentially optimizing the elbow of a fitted polynomial/log function but two lines gave a more precise point rather than trying to threshold a continuous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFixOff(dat_trial):\n",
    "    \"\"\" Function to find when on fix happens \n",
    "\n",
    "    Args:\n",
    "        dat_trial (_type_): _description_\n",
    "    \"\"\"\n",
    "def calcOnsetOffset(dat, search_window=0.015, do_ts_average=True, data_use = 'trans'):\n",
    "    \"\"\"Loops though strok data and calculates onset anbd offset points by optimizing intersection point of positive sloped and horizontal line, fitting\n",
    "    the data near a stroke. \n",
    "\n",
    "    Args:\n",
    "        dat (df or soemthing): DF holding the data needed for the computation here. Mainly we need all the fields returned from the HT.process data function\n",
    "        (touch/cam positions and interpolated versions also)\n",
    "        \n",
    "        search_window: Numb er in seconds to tell algorithm how far to look before/after stroke to find min/max point (fitted line goes from min/max point to intercept)\n",
    "        do_ts_average (bool): Average the caluclated point with the touchscreen point (helps reduce variance from less than ideal fits)\n",
    "        data_use (str): Which data to use ('raw', 'trans'). Raw is raw z coord, trans is z corod after regression with transformation marix\n",
    "    Returns:\n",
    "        on_off_pts (dict): Dictionary containing onset and offset pts for {on_fix(offset only), strokes 1...n, off_fix(onset only)}\n",
    "    \"\"\"\n",
    "    on_off_pts = {}\n",
    "\n",
    "    assert len(dat) > 0, \"No data here\"\n",
    "    if data_use == 'trans':\n",
    "        strokes_cam = dat[\"trans_strokes_cam\"]\n",
    "        gaps_cam = dat[\"trans_gaps_cam\"]\n",
    "        strokes_touch = dat[\"strokes_touch\"]\n",
    "    elif data_use == 'raw':\n",
    "        strokes_cam = dat[\"reg_strokes_cam\"]\n",
    "        gaps_cam = dat[\"reg_gaps_cam\"]\n",
    "        strokes_touch = dat[\"strokes_touch\"]\n",
    "    else:\n",
    "        assert False, \"Not sure what data you want to use\"\n",
    "\n",
    "    t_onfix_off = strokes_touch[0][-1,2]\n",
    "    t_offfix_on = strokes_touch[-1][0,2]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipe_dlc",
   "language": "python",
   "name": "pipe_dlc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
