{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "saving files as bhv2 instead of hdf5. Here code to load bhv2.\n",
    "CONCLUSION:\n",
    "Stopped, since decided better tactic was bhv2 --> h5, then treat as before. Have confirmed that this owrks. \n",
    "IF for some reason want to continue tactic of bhv2 --> mat --> pkl, then here are notes of where left off:\n",
    "- go to ## modifications to filedata\n",
    "- need to hadn write things to make the extracted dict match old filedata.\n",
    "- one general problem is that everythign in old version is like {1: [], 2: [], ...} while\n",
    "in new version is list [[], [], []].  See below for example of one field where fixed.\n",
    "Could change to this in bulk? not sure if in bulk would work - in some cases might not wabnt to change.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/data1/code/python\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.utils import * \n",
    "from tools.plots import *\n",
    "from tools.analy import *\n",
    "from tools.calc import *\n",
    "from tools.analyplot import *\n",
    "from tools.preprocess import *\n",
    "from tools.dayanalysis import *\n",
    "from analysis.modelexpt import *\n",
    "from analysis.line2 import PROBEDATfromFD\n",
    "\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STARTING FROM .MAT (after convert bhv2 to mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .mat\n",
    "import scipy.io as sio\n",
    "fname_mat = \"/data2/animals/Diego/210127/210127_113923_naive6_Diego_1.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = sio.loadmat(fname_mat, struct_as_record=False, squeeze_me=True)\n",
    "dat = sio.loadmat(fname_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRATCH, useful things:\n",
    "# got from searching somthing like \"how to convert mat to dict\"\n",
    "dat[\"TrialRecord\"][0,0].dtype.descr\n",
    "\n",
    "val = dat[\"TrialRecord\"][0,0]\n",
    "val[\"BlocksPlayed\"]\n",
    "\n",
    "val = dat[\"TrialRecord\"][0,0]\n",
    "val.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### good below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types, for those categorized as 'else'\n",
      "{<class 'str'>, <class 'numpy.ndarray'>}\n"
     ]
    }
   ],
   "source": [
    "def _check_keys( DICT):\n",
    "    \"\"\"\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    \"\"\"\n",
    "    for key in DICT:\n",
    "        if isinstance(DICT[key], sio.matlab.mio5_params.mat_struct):\n",
    "            DICT[key] = _todict(DICT[key])\n",
    "    return DICT\n",
    "\n",
    "def _check_if_all_matstruct(array, check_if=\"true\"):\n",
    "    \"\"\" returns True if all items are mat_struct.\n",
    "    False otherwise. flip this criterion by making check_if=false.\"\"\"\n",
    "    \n",
    "    x = [isinstance(a, sio.matlab.mio5_params.mat_struct) for a in array]\n",
    "    if check_if==\"true\":\n",
    "        return all(x)\n",
    "    elif check_if==\"false\":\n",
    "        return all([not xx for xx in x])\n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "TYPES = []\n",
    "def _todict(matobj):\n",
    "    \"\"\"\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    \"\"\"\n",
    "    DICT = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "#         if strg==\"num_finger_raises\" and isinstance(elem, int):\n",
    "#             print(elem)\n",
    "#             print(np.array([[elem]]))\n",
    "#             assert False\n",
    "        if isinstance(elem, sio.matlab.mio5_params.mat_struct):\n",
    "            DICT[strg] = _todict(elem)\n",
    "        elif isinstance(elem, (int, float)):\n",
    "            DICT[strg] = np.array([[elem]])\n",
    "        elif isinstance(elem, np.ndarray) and len(elem)>0:\n",
    "            if _check_if_all_matstruct(elem):\n",
    "                # then children are all structure\n",
    "                for i, e in enumerate(elem):\n",
    "                    elem[i] = _todict(e)\n",
    "                DICT[strg] = elem\n",
    "            elif _check_if_all_matstruct(elem, check_if=\"false\"):\n",
    "                # then all chyildren not structs, this is data.\n",
    "                DICT[strg] = np.array([elem]) # becuase the old h5 code did this.\n",
    "#                 if len(elem)==1:\n",
    "#                     DICT[strg] = 1000000 # becuase the old h5 code did this.\n",
    "            else:\n",
    "#                 print(elem)\n",
    "#                 assert False, \"how can have mixture of struct and data?\"\n",
    "                for i, e in enumerate(elem):\n",
    "                    if isinstance(e, sio.matlab.mio5_params.mat_struct):\n",
    "                        elem[i] = _todict(e)\n",
    "                    else:\n",
    "                        assert len(e)==0, \"I expect that if this mixed with struct, then is empty\"\n",
    "                        elem[i] = e # becuase the old h5 code did this.\n",
    "                DICT[strg] = elem\n",
    "                \n",
    "#         elif isinstance(elem, np.ndarray):\n",
    "# #             doprint=False\n",
    "# #             elem2 = np.copy(elem)\n",
    "#             for i, e in enumerate(elem):\n",
    "#                 if isinstance(e, sio.matlab.mio5_params.mat_struct):\n",
    "# #                     doprint=True\n",
    "#                     elem[i] = _todict(e)\n",
    "#                 else:\n",
    "#                     print(e)\n",
    "#                     elem[i] = np.array([[e]]) # becuase the old h5 code did this.\n",
    "#                     print(elem)\n",
    "#                     print(i)\n",
    "#                     assert False\n",
    "#             DICT[strg] = elem\n",
    "#             if doprint:\n",
    "#                 print(elem2)\n",
    "#                 print(dict[strg])\n",
    "        \n",
    "        else:\n",
    "            TYPES.append(type(elem))\n",
    "            DICT[strg] = elem\n",
    "    return DICT\n",
    "\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\"\n",
    "    this function should be called instead of direct scipy.io .loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    \"\"\"\n",
    "    data = sio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "fname_mat = \"/data2/animals/Diego/210127/210127_113923_naive6_Diego_1.mat\"\n",
    "dat = loadmat(fname_mat)\n",
    "print(\"types, for those categorized as 'else'\")\n",
    "print(set(TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == VARIOUS PROCESSING NEEDED to make dat simialr to filedata. \n",
    "# STILL IN PROGRESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = {}\n",
    "dat2[\"ML\"] = {\n",
    "    \"TrialRecord\":dat[\"TrialRecord\"],\n",
    "    \"MLConfig\":dat[\"MLConfig\"]}\n",
    "for k, v in dat.items():\n",
    "    if \"Trial\" in k:\n",
    "        dat2[\"ML\"][k]=v\n",
    "dat = dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = \"Diego\"\n",
    "date = \"210127\"\n",
    "expt = \"naive6\"\n",
    "session = 1\n",
    "fname = fname_mat\n",
    "resave_as_dict = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to dict - may take a whiel, liek a minute or two\n",
      "Saving pickle file /data2/animals/Diego/210127/210127_113923_naive6_Diego_1.pkl\n",
      "-- saving\n"
     ]
    }
   ],
   "source": [
    "TrialRecord = dat[\"ML\"][\"TrialRecord\"]\n",
    "MLConfig = dat[\"ML\"][\"MLConfig\"]\n",
    "\n",
    "############################## EXTRACT PARAMS FOR THIS FILE\n",
    "params = {}\n",
    "\n",
    "params[\"pix_per_deg\"] = MLConfig[\"PixelsPerDegree\"][()]\n",
    "\n",
    "try:\n",
    "    resolution = MLConfig[\"Resolution\"][()].decode()\n",
    "except:\n",
    "    resolution = MLConfig[\"Resolution\"]\n",
    "\n",
    "h = int(resolution[0:resolution.find(' x ')])\n",
    "tmp = resolution.find(' 59 Hz')\n",
    "if tmp==-1:\n",
    "    tmp = resolution.find(' 75 Hz')\n",
    "v = int(resolution[resolution.find(' x ')+3:tmp])\n",
    "assert (h==1024 and v==768), \"diff resolution?\"\n",
    "params[\"resolution\"] = (h, v)\n",
    "\n",
    "# num trials\n",
    "trials = [int(key[5:]) for key in dat[\"ML\"].keys() if (key[:5]==\"Trial\" and key!=\"TrialRecord\")]\n",
    "params[\"n_trials\"] = max(trials)\n",
    "try:\n",
    "    params[\"n_trialoutcomes\"] = len(TrialRecord[\"User\"][\"TrialOutcomes\"])\n",
    "except KeyError as error:\n",
    "    params[\"n_trialoutcomes\"] = ()\n",
    "\n",
    "    \n",
    "params[\"animal\"]=animal\n",
    "params[\"date\"] = date\n",
    "params[\"expt\"] = expt\n",
    "params[\"session\"] = session\n",
    "params[\"fname\"] = fname\n",
    "\n",
    "# ################## extract all trials into a dict (e.g, dict[1] = trial data)\n",
    "if False:\n",
    "    # converts to dict - slow\n",
    "    trials = {}\n",
    "    for t in range(1, params[\"n_trials\"]+1):\n",
    "        trials[t] = group2dict(dat[\"ML\"][f\"Trial{t}\"])\n",
    "else:\n",
    "    # saves as hdf5 group, not dict - fast\n",
    "    trials = {}\n",
    "    for t in range(1, params[\"n_trials\"]+1):\n",
    "        trials[t] = dat[\"ML\"][f\"Trial{t}\"]\n",
    "\n",
    "########################## OUTPUT A DICT\n",
    "filedata = {\n",
    "    # \"data\":data,\n",
    "    \"TrialRecord\":TrialRecord,\n",
    "    \"MLConfig\":MLConfig,\n",
    "    \"params\":params,\n",
    "    \"trials\":trials,\n",
    "    }\n",
    "\n",
    "###### decide if convert to dict and save\n",
    "if resave_as_dict:\n",
    "    # 1) conver to dict\n",
    "    print('Converting to dict - may take a whiel, liek a minute or two')\n",
    "    # del filedata[\"data\"]    # delete \"data\", is reduntant\n",
    "\n",
    "    # if True:\n",
    "    import os\n",
    "    ext = os.path.splitext(fname)[1]\n",
    "    if expt==\".h5\":\n",
    "        # then is still h5, need toconver to dict.\n",
    "        print(\"-- group2dict\")\n",
    "        filedata = group2dict(filedata)\n",
    "    else:\n",
    "        assert ext==\".mat\", \"dont know this?\"\n",
    "    \n",
    "    # 2) save pickle\n",
    "    import os, pickle\n",
    "    fname_dict = os.path.splitext(fname)[0] + \".pkl\"\n",
    "    filedata[\"params\"][\"fname_dict\"] = fname_dict\n",
    "    print(f\"Saving pickle file {fname_dict}\")\n",
    "    with open(fname_dict, \"wb\") as f2:\n",
    "        print(\"-- saving\")\n",
    "        pickle.dump(filedata, f2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modifications to filedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: paused, ideally can convert mat to h5, then load that. otherwise a key problem is that everythign in old version is like {1: [], 2: [], ...}. could change to this in bulk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlockParams shouold be dict{1...}\n",
    "BP = filedata[\"TrialRecord\"][\"User\"][\"BlockParams\"]\n",
    "if len(BP)<2:\n",
    "    print(BP)\n",
    "    assert len(BP)>1, \"im not sure the follopwing is correct. need to check\"\n",
    "\n",
    "DICT = {}\n",
    "for i, v in enumerate(BP):\n",
    "    DICT[f\"{i+1}\"] = v\n",
    "filedata[\"TrialRecord\"][\"User\"][\"BlockParams\"] = DICT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_dot\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-21591ffde1a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupdateFiledataParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data1/code/python/drawmonkey/tools/preprocess.py\u001b[0m in \u001b[0;36mupdateFiledataParams\u001b[0;34m(filedata)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;31m# populate task sets in BlockParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mupdateBlockParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"behEvaluation\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiledata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TrialRecord\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;31m# print(filedata[\"TrialRecord\"][\"User\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/drawmonkey/tools/preprocess.py\u001b[0m in \u001b[0;36mupdateBlockParams\u001b[0;34m(filedata)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBlockParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBlockParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TaskSet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tasklist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBlockParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TaskSet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tasklist\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# first find what all the keys are (ie.., how many task sets, like [\"1\", \"2\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "updateFiledataParams(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TrialOutcomes should be dict{trialnum}, not list[trialnum-1]\n",
    "\n",
    "DICT = {}\n",
    "for i, v in enumerate(filedata[\"TrialRecord\"][\"User\"][\"TrialOutcomes\"]):\n",
    "    DICT[f\"{i+1}\"] = v\n",
    "filedata[\"TrialRecord\"][\"User\"][\"TrialOutcomes\"] = DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
