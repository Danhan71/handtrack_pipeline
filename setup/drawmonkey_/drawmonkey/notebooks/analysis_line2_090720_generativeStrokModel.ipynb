{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Breaking out from main mulitday analysis,\n",
    "focusing on setting up and analyzing strokmodel analysis.\n",
    "OBSOLETE - see Notes below.\n",
    "Training is at line2_strokmodelfits.py\n",
    "Testing is at (see bleow)\n",
    "\n",
    "NOTE: more analsysi (taking into account expt structure) is in \n",
    "analysis_modelexpt_multsession_strokmodel_100420\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.utils import * \n",
    "from tools.plots import *\n",
    "from tools.analy import *\n",
    "from tools.calc import *\n",
    "from tools.analyplot import *\n",
    "from tools.preprocess import *\n",
    "from tools.dayanalysis import *\n",
    "from analysis.line2 import *\n",
    "\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE ANIMAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythonlib.tools.datetools import getDateList\n",
    "\n",
    "# sdate = 200903\n",
    "# edate = 200903\n",
    "# datelist = getDateList(sdate, edate)\n",
    "\n",
    "# expt = \"lines2\"\n",
    "# animal = \"Pancho\"\n",
    "    \n",
    "# dattoget = []\n",
    "# for d in datelist:\n",
    "#     dattoget.append([expt, animal, d])\n",
    "\n",
    "# FD = loadMultData(dattoget)\n",
    "\n",
    "# # saving dir\n",
    "# SAVEDIR = f\"{FD[0]['fd']['params']['figuredir_notebook']}/analysis_line2_090720/multday_{animal}_{sdate}_to_{edate}\"\n",
    "# import os\n",
    "# os.makedirs(SAVEDIR, exist_ok=True)\n",
    "# print(f\"saving at {SAVEDIR}\")\n",
    "\n",
    "# # ==== Flatten all trials across days x animals\n",
    "# # for each trial collect relevant information\n",
    "# from analysis.line2 import PROBEDATfromFD\n",
    "\n",
    "# PROBEDAT = PROBEDATfromFD(FD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORIZE STROKES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******** 1) Plot grid of all strokes to visualize if any structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** 2) Do stuff with the timecourse?\n",
    "\n",
    "i = random.randint(0, len(PROBEDAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrialSingleOverview(PROBEDAT[i][\"filedata\"], PROBEDAT[i][\"trial\"]);\n",
    "# plotTrialSimpleTimecourse(PROBEDAT[i][\"filedata\"], PROBEDAT[i][\"trial\"])\n",
    "# plotTrialSimple(PROBEDAT[i][\"filedata\"], PROBEDAT[i][\"trial\"], zoom=True, plotver=\"order\", kwargs={'each_stroke_separate': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT GENERATIVE MODEL FOR SINGLE STROKES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See analysis/line2_strokmodelfits for code doing these analyses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ==== Generative model for strokes\n",
    "\n",
    "# # 1) First see if better to model x and y velocities, or to model speed and and angle (i.e, \n",
    "# # they are equivalent, since both 2 DOF). \n",
    "# # - x and y could match nicely to the nerual netwrok model\n",
    "# # - could model line as (duration, peak x vel, peak y vel. if assume start at 0 (or close), \n",
    "# # then this is good enough.\n",
    "\n",
    "# from pythonlib.drawmodel.motormodel import *\n",
    "# from pythonlib.drawmodel import primitives as P\n",
    "# from analysis.line2_strokmodelfits import getShuffleBehDistances\n",
    "# from math import pi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # --------------- MODELS\n",
    "# vec_over_spatial_ratio = getShuffleBehDistances(fd, fs, N=100, ploton=False)\n",
    "\n",
    "\n",
    "# # ---------------- BEHAVIOR\n",
    "# fs = fd[\"params\"][\"sample_rate\"]\n",
    "# # Given a behavioral target:\n",
    "# t = random.sample([t for t in getIndsTrials(fd) if getTrialsFixationSuccess(fd, t)], 1)[0]\n",
    "\n",
    "# strok_beh = getTrialsStrokesByPeanuts(fd,t)[0]\n",
    "# T = strok_beh[-1,2] - strok_beh[0,2]\n",
    "\n",
    "\n",
    "# plotTrialSimple(fd, t, use_peanut_params={'replaynum': None, 'active': True})\n",
    "\n",
    "# ## threshold for stroke length\n",
    "# MINDIST=50\n",
    "# if strokeDistances([strok_beh])[0]<MINDIST:\n",
    "#     assert False\n",
    "\n",
    "# # plot distrubtion of all distances\n",
    "# if False:\n",
    "#     distall = []\n",
    "#     for t in getIndsTrials(fd):\n",
    "#         if getTrialsFixationSuccess(fd, t):\n",
    "#             strokestmp = getTrialsStrokesByPeanuts(fd, t)\n",
    "#             d = strokeDistances(strokestmp)\n",
    "#             distall.extend(d)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.hist(distall, bins=100);\n",
    "\n",
    "# import pickle\n",
    "# with open(\"/tmp/test\", \"wb\") as f:\n",
    "#     pickle.dump([1], f)\n",
    "\n",
    "# strokclass = strokModel(fs, vec_over_spatial_ratio=vec_over_spatial_ratio)\n",
    "\n",
    "# from analysis.line2_strokmodelfits import getFitStuff\n",
    "\n",
    "# # === get score for all models, compared to this beh\n",
    "# from pythonlib.tools.modfittools import minimize    \n",
    "# for Nsub in [1,2, 3]:\n",
    "#     program_func, params0, bounds = getFitStuff(Nsub, \n",
    "#                                                 theta0=stroke2angle([strok_beh])[0],\n",
    "#                                                dist0 = strokeDistances([strok_beh])[0])\n",
    "\n",
    "#     func = strokclass.getCostFunc(strok_beh, program_func)\n",
    "#     # strokclass.synthesize(program_func(params0), ploton=True)\n",
    "\n",
    "#     res = minimize(func, params0, bounds=bounds)\n",
    "#     print(res)\n",
    "\n",
    "#     # == take optimization results and extract useful things\n",
    "#     ploton=True\n",
    "#     cost = res[\"fun\"]\n",
    "#     success = res[\"success\"]\n",
    "#     params_fit = res[\"x\"]\n",
    "\n",
    "#     if ploton:\n",
    "#         func(params0, ploton=True)\n",
    "#         func(params_fit, ploton=True)\n",
    "\n",
    "# ## ============= ITERATE OVER A DAY OF STROKES, COLLECTING MODEL RESULTS ACROSS ALL STROKES\n",
    "# MINTIME = 0.175\n",
    "# Nsub_to_run = [1,2]\n",
    "\n",
    "# # 1) Get list of strokes across tasks\n",
    "# trialslist = [t for t in getIndsTrials(fd) if getTrialsFixationSuccess(fd,t)]\n",
    "# strokeslist = [getTrialsStrokesByPeanuts(fd,t) for t in trialslist]\n",
    "# strok_list = [s for strok in strokeslist for s in strok]\n",
    "\n",
    "# # === get a random subset for now\n",
    "# strok_list = random.sample(strok_list, 200)\n",
    "# modelfits = []\n",
    "# for i, strok_beh in enumerate(strok_list):\n",
    "#     T = strok_beh[-1,2] - strok_beh[0,2]\n",
    "#     theta0 =stroke2angle([strok_beh])[0]\n",
    "#     dist0 = strokeDistances([strok_beh])[0]\n",
    "    \n",
    "#     print(i)\n",
    "#     if strokeDistances([strok_beh])[0]>MINDIST and T>MINTIME:\n",
    "        \n",
    "#         # === get score for all models, compared to this beh\n",
    "#         for Nsub in Nsub_to_run:\n",
    "#             program_func, params0, bounds = getFitStuff(Nsub, \n",
    "#                                                         theta0 = theta0,\n",
    "#                                                        dist0 = dist0)\n",
    "\n",
    "#             func = strokclass.getCostFunc(strok_beh, program_func)\n",
    "#             # strokclass.synthesize(program_func(params0), ploton=True)\n",
    "\n",
    "#             res = minimize(func, params0, bounds=bounds)\n",
    "\n",
    "#             # == take optimization results and extract useful things\n",
    "#             ploton=False\n",
    "#             if ploton:\n",
    "#                 func(params0, ploton=True)\n",
    "#                 func(params_fit, ploton=True)\n",
    "            \n",
    "#             modelfits.append({\n",
    "#                 \"strok_num\":i,\n",
    "#                 \"nsubstrokes\":Nsub,\n",
    "#                 \"finalcost\":res[\"fun\"],\n",
    "#                 \"success\":res[\"success\"],\n",
    "#                 \"paramsfit\":res[\"x\"],\n",
    "#                 \"message\":res[\"message\"]})\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and analyzing previously run/saved data\n",
    "### runs from analysis/lline2_strokmodelfits (not from the code above, which is the same)\n",
    "### could also anlyze rusn from above but would have to change loading scheme, etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === SUMMARY PLOTS AFTER TRAINING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2466\n",
    "DF2 cols\n",
    "Index([      'trial', 'strok_num_0',             1,             2,\n",
    "         'strok_dur',     'index_x',     '0/(0+1)',     'index_y',\n",
    "               '0/1'],\n",
    "      dtype='object')\n",
    "DF cols\n",
    "Index(['strok_beh', 'strok_dur', 'trial', 'strok_num_1', 'strok_num_0',\n",
    "       'nsubstrokes', 'model', 'finalcost', 'success', 'paramsfit', 'message',\n",
    "       'strok_mod'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for animal in [\"Red\", \"Pancho\"]:\n",
    "#     animal = \"Red\"\n",
    "    expt = \"lines5\"\n",
    "\n",
    "    ## quick loading of FD based on experimental metadat\n",
    "    from analysis.modelexpt import loadMetadat, loadMultDataForExpt\n",
    "    from analysis.line2_strokmodelfits import *\n",
    "\n",
    "    # FD, MD = loadMultDataForExpt(expt, animal, \"summary\")\n",
    "    sessdict = loadMultDataForExpt(expt, animal, \"summary\", metadatonly=True)\n",
    "    print(\"\\nsessions:\")\n",
    "    print(sessdict)\n",
    "\n",
    "\n",
    "    for date, sessionlist in sessdict.items():\n",
    "        for sess in sessionlist:\n",
    "            # i.e, each session\n",
    "    #         sess = F[\"session\"]\n",
    "    #         date = F[\"date\"]\n",
    "\n",
    "            strokdat, DF, DF2, fd = postProcess(a=animal, s=sess, d=date, e=expt,\n",
    "                                                fit_tstamp=MD[\"strokmodel_tstamp\"], \n",
    "                                                model=MD[\"strokmodel_kind\"], ploton=True);\n",
    "            plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: \n",
    "- overlay model fits DONE\n",
    "- plto velocity traj DONE\n",
    "- plot sorted by ratio DONE\n",
    "- retrun model.. focusing on spatial (or try diff reweighting) \n",
    "- only include strokes starting from 0 vel? (or model those seoparately?)\n",
    "\n",
    "- dont let single stroke be off middle.\n",
    "- flatten single stroke - allow onset/offset to be off edge (so flatter)\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW: Scratch for model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "# ---------------- BEHAVIOR\n",
    "# Given a behavioral target:\n",
    "strok_beh = getTrialsStrokesByPeanuts(fd,100)[1]\n",
    "\n",
    "# ---------------- MODELS\n",
    "# Generate a model strok with the same timeseries\n",
    "\n",
    "# --- Model 1: single stroke\n",
    "program = {\n",
    "    \"substroks\":[\n",
    "        (0, 0.6*T, 0, 100),    \n",
    "        (0.4*T, T, pi/2, 200)],\n",
    "    \"totaltime\":T,\n",
    "    \"fs\":fs}\n",
    "vec_over_spatial_ratio = getShuffleBehDistances(fd, fs=fs, N=20)\n",
    "strokclass = strokModel(fs, vec_over_spatial_ratio)\n",
    "strok_mod = strokclass.synthesize(program)\n",
    "\n",
    "# === compare strok to behavior\n",
    "strokclass.scoreVsBeh(strok_beh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN\n",
    "params = (0.6, 0.4, 0, pi/2, 200, 100)\n",
    "# params = [  0.36419443,   0.3       ,   3.07142968,   3.3443616 ,\n",
    "#        131.88276162, 101.57837757]\n",
    "\n",
    "bounds = [\n",
    "    (0.1, 0.7),\n",
    "    (0.3, 0.9),\n",
    "    (0, 2*pi),\n",
    "    (0, 2*pi),\n",
    "    (50, 300),\n",
    "    (50,300)]\n",
    "\n",
    "from pythonlib.tools.modfittools import minimize    \n",
    "func =strokclass.getCostFunc(strok_beh)\n",
    "\n",
    "res = minimize(func, params, bounds=bounds)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to fit by hand\n",
    "# params = (0.4, 0.4, pi, 1.3*pi, 200, 50)\n",
    "params_fit = res[\"x\"]\n",
    "func(params, ploton=True)\n",
    "func(params_fit, ploton=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR EACH TASK, PLOT THE DISTRIBUTIONS OF FEATURES, COMPARING TWO DAYS\n",
    "\n",
    "DATE1 = \"200903\"\n",
    "DATE2 = \"200907\"\n",
    "TASKlIST = \"F_1-protype\"\n",
    "\n",
    "# --- get flattened list of all stroks\n",
    "DAT = []\n",
    "for P in PROBEDAT:\n",
    "    if P[\"date\"] in [DATE1, DATE2] and P[\"unique_task_name\"]==TASK:\n",
    "        DAT.append(\n",
    "            {\n",
    "                \"date\":str(P[\"date\"]),\n",
    "                \"strokes\":getTrialsStrokesByPeanuts(P[\"filedata\"], P[\"trial\"])\n",
    "            })\n",
    "\n",
    "##############################\n",
    "strokesfeatures = strokeFeatures([D[\"strokes\"] for D in DAT])\n",
    "for sf, D in zip(strokesfeatures, DAT):\n",
    "    D[\"features\"] = sf\n",
    "    \n",
    "strokfeats = flattenByStrok(DAT)\n",
    "strokfeats[0]\n",
    "\n",
    "\n",
    "# --- Plot distributions\n",
    "SF = pd.DataFrame(strokfeats)\n",
    "sns.pairplot(SF, vars = [\"strokenum\", \"circularity\", \"distance\"], hue=\"date\", kind=\"reg\")\n",
    "sns.pairplot(SF, vars = [\"strokenum\", \"circularity\", \"distance\"], hue=\"date\")\n",
    "\n",
    "sns.catplot(data=SF, x=\"date\", y=\"distance\", hue=\"strokenum\", jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strokefeats2title(strokfeats):\n",
    "    \"\"\"strokfeats is a list of dicts.\n",
    "    title is string, each row is a list element\"\"\"\n",
    "    sfeat = strokfeats[0]\n",
    "    s = \"\"\n",
    "    for i, sfeat in enumerate(strokfeats):\n",
    "        s=f\"{s}\\n[{i+1}]\"\n",
    "        for k, v in sfeat.items():\n",
    "            if k!=\"strokenum\":\n",
    "                s=f\"{s}-{k[:3]}\"\n",
    "                s=f\"{s}({v:.2f})\"\n",
    "        #     s+=v\n",
    "    return s\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PLOT TRAILS STROKES ALONG WITH THEIR FEATURES\n",
    "\n",
    "idxlist = [random.randrange(1, len(PROBEDAT)) for _ in range(20)]\n",
    "\n",
    "# 1) collect features\n",
    "# strokeslist = [getTrialsStrokesByPeanuts(PROBEDAT[i][\"filedata\"], PROBEDAT[i][\"trial\"]) for i in idxlist]\n",
    "# strokfeats = strokeFeatures(strokeslist)\n",
    "\n",
    "# 2) plot\n",
    "titles = []\n",
    "filedatas = []\n",
    "trialslist = []\n",
    "for i in idxlist:\n",
    "    strokeslist = [getTrialsStrokesByPeanuts(PROBEDAT[i][\"filedata\"],PROBEDAT[i][\"trial\"])]\n",
    "    strokfeats = strokeFeatures(strokeslist)[0]\n",
    "    \n",
    "    titles.append(strokefeats2title(strokfeats))\n",
    "    filedatas.append(PROBEDAT[i][\"filedata\"])\n",
    "    trialslist.append(PROBEDAT[i][\"trial\"])\n",
    "    \n",
    "plotMultTrialsSimple(filedatas, trialslist, titles=titles, zoom=True, strokes_ver=\"peanuts\");\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokeFeatures(strokeslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute distribution of angle bends per stroke\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    2a) Cluster strokes:\n",
    "    a) using statistics above\n",
    "    b) pairwise distance matrix;\n",
    "    show that there are lines and Ls as two distinct clusters.\n",
    "\n",
    "\n",
    "    2) Categories strokes\n",
    "    - for each stroke, categorize based on the clustering model above.\n",
    "    [ Or do it in a supervised way?]\n",
    "    -- goal: 2d plot (line weight vs. L-weight, probabilistic).\n",
    "\n",
    "    3) Model-based analysis - assigning entire parse a score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW - OLD SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## COMPUTE COMPOSITIONAL SCORE\n",
    "# [Quick version] DTW score relative to non-DTW score\n",
    "\n",
    "## ==== [testing] stroke based hd\n",
    "from pythonlib.tools.stroketools import distanceDTW\n",
    "t = random.sample(getIndsTrials(fd),1)[0]\n",
    "\n",
    "strokes_beh = getTrialsStrokesByPeanuts(fd, t, replaynum=1)\n",
    "strokes_task = getTrialsTaskAsStrokes(fd, t)\n",
    "\n",
    "for ass in [True, False]:\n",
    "    print(f\"assymetric: {ass}\")\n",
    "    plotTrialSimple(fd, t, zoom=True, plot_fix=False, plotver=\"strokes\", \n",
    "                    use_peanut_params={'replaynum': 1, 'active': True})\n",
    "\n",
    "    print(distanceDTW(strokes_beh, strokes_task[::-1], ver=\"segments\", asymmetric=ass))\n",
    "    print(distanceDTW(strokes_beh, strokes_task, ver=\"segments\", asymmetric=ass))\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot(211)\n",
    "    plotDatStrokes(strokes_beh, ax=ax)\n",
    "    plotDatStrokes(strokes_task[::-1], ax=ax)\n",
    "\n",
    "    ax = plt.subplot(212)\n",
    "    plotDatStrokes(strokes_beh, ax=ax)\n",
    "    plotDatStrokes(strokes_task, ax=ax)\n",
    "\n",
    "# compute minimum score for all permutations of task strokes\n",
    "# make assymetric false, so forced to use all task strokes.\n",
    "print(\"-- all permutations\")\n",
    "from itertools import permutations\n",
    "scores =[]\n",
    "for s in permutations(strokes_task):\n",
    "    print(distanceDTW(strokes_beh, s, ver=\"segments\", asymmetric=False))\n",
    "    scores.append(distanceDTW(strokes_beh, s, ver=\"segments\", asymmetric=False)[0])\n",
    "score = min(scores)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.listtools import permuteRand\n",
    "\n",
    "permuteRand([1,2,3], 6, not_enough_ok=True)\n",
    "from itertools import permutations\n",
    "\n",
    "for i in permutations([1,2,3]):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurestoplot = []\n",
    "for key, val in getTrialsBlockParams(fd, 1)[\"behEval\"][\"beh_eval\"].items():\n",
    "    if val[\"feature\"] ==\"hausdorff\" and val[\"weight\"][0][0]>0:\n",
    "        featurestoplot.append(\"hausdorff\")\n",
    "    if val[\"feature\"] ==\"frac_touched\" and val[\"weight\"][0][0]>0:\n",
    "        featurestoplot.append(\"frac_touched\")\n",
    "featurestoplot.append(\"score_offline\")\n",
    "\n",
    "fig1, fig2 = plotOverview_(df, featurestoplot=featurestoplot)\n",
    "fig1.savefig(f\"{SAVEDIRDAY}/overview1.pdf\")\n",
    "fig2.savefig(f\"{SAVEDIRDAY}/overview2.pdf\")\n",
    "\n",
    "# 2) relationship between reward and factors that go into reward\n",
    "figs = plotReward(df, featurestoplot=featurestoplot)\n",
    "for i, f in enumerate(figs):\n",
    "    f.savefig(f\"{SAVEDIRDAY}/reward_score_{i}.pdf\")\n",
    "\n",
    "# 3) PLOT BEHAVIOR FOR TRIALS SORTED BY SCORE\n",
    "import copy\n",
    "scoretypes = copy.copy(featurestoplot)\n",
    "scoretypes.extend([\"behscore\", \"reward\"])\n",
    "for score_type in scoretypes:\n",
    "    FIGS = plotBehSortedByScore(df, fd, score_type)\n",
    "    for ver, figs in FIGS.items():\n",
    "        for i, f in enumerate(figs):\n",
    "            f.savefig(f\"{SAVEDIRDAY}/trialsSortedByScore_{score_type}_{ver}_{i}_.pdf\")\n",
    "\n",
    "# 4) Plot behavior subsampling in chronological order\n",
    "trials = [t for t in getIndsTrials(fd) if getTrialsFixationSuccess(fd, t)]\n",
    "Nrand = 80\n",
    "fig = plotMultTrialsSimple(fd, trials, zoom=True, strokes_ver=\"peanuts\", plot_fix=False,\n",
    "                        plotver=\"strokes\", rand_subset=Nrand)\n",
    "fig.savefig(f\"{SAVEDIRDAY}/trialsRandomChronOrder.pdf\")\n",
    "\n",
    "# 5) TASK VISUALIZATIONS, SCHEDULE, REPETITION\n",
    "figs = plotTaskSchedules(df)\n",
    "for i, f in enumerate(figs):\n",
    "    f.savefig(f\"{SAVEDIRDAY}/taskSchedule{i}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    animal = \"Pancho\"\n",
    "    expt = \"pilot\"\n",
    "    date = 200822\n",
    "    session = 1\n",
    "\n",
    "    fd = loadSingleData(animal, date, expt, session, resave_as_dict=False, load_resaved_data=True, \n",
    "                              resave_overwrite=False)\n",
    "\n",
    "    ## ==== [testing] stroke based hd\n",
    "    from pythonlib.tools.stroketools import distanceDTW\n",
    "    t = random.sample(getIndsTrials(fd),1)[0]\n",
    "\n",
    "    for ass in [True, False]:\n",
    "        print(f\"assymetric: {ass}\")\n",
    "        plotTrialSimple(fd, t, zoom=True, plot_fix=False, plotver=\"strokes\", \n",
    "                        use_peanut_params={'replaynum': 1, 'active': True})\n",
    "\n",
    "        strokes_beh = getTrialsStrokesByPeanuts(fd, t, replaynum=1)\n",
    "        strokes_task = getTrialsTaskAsStrokes(fd, t)\n",
    "        print(distanceDTW(strokes_beh, strokes_task[::-1], ver=\"segments\", asymmetric=ass))\n",
    "        print(distanceDTW(strokes_beh, strokes_task, ver=\"segments\", asymmetric=ass))\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.subplot(211)\n",
    "        plotDatStrokes(strokes_beh, ax=ax)\n",
    "        plotDatStrokes(strokes_task[::-1], ax=ax)\n",
    "\n",
    "        ax = plt.subplot(212)\n",
    "        plotDatStrokes(strokes_beh, ax=ax)\n",
    "        plotDatStrokes(strokes_task, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==== plot scoring separated by task type\n",
    "\n",
    "df = extractSessionDf(fd)\n",
    "\n",
    "# === add note about what probe type this is\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "(1) get all permutations\n",
    "(2) normalize by num strokes.\n",
    "(3) systematic - compare to old version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
