{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "manifold for strokes.\n",
    "clustering\n",
    "analysis of changes in cluster memebrship with learning.\n",
    "\n",
    "EXTRACTED FROM devo_strokemanifold... to here just focus on analysis.\n",
    "\n",
    "Focus on cleaner general-purpose analyses.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/code/python/drawmonkey\n",
      "NOTE: need to not overwrite strokes_all_task, because then the orders saved will stop being accurate. Modify\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "from tools.utils import * \n",
    "from tools.plots import *\n",
    "from tools.analy import *\n",
    "from tools.calc import *\n",
    "from tools.analyplot import *\n",
    "from tools.preprocess import *\n",
    "from tools.dayanalysis import *\n",
    "from analysis.strok import *\n",
    "from analysis.line2 import *\n",
    "from analysis.probedatTaskmodel import *\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.strok import *\n",
    "from pythonlib.tools.plottools import plotScatterOverlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLOTTING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "plotGrid=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (old code) wrapper for all plots, just give it paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Load\n",
    "# SDIR = \"/data2/analyses/database/clustering/bysimilarity/arc2_lines5/Red-210316_012248\"\n",
    "# SDIR = \"/data2/analyses/database/clustering/bysimilarity/arc2_lines5/Pancho-210316_013419\"\n",
    "# SDIR = \"/data2/analyses/database/clustering/bysimilarity/arc2_lines5_shapes3/Red-210316_001517\"\n",
    "# SDIR = \"/data2/analyses/database/clustering/bysimilarity/arc2_lines5/Red-210316_024118\"\n",
    "\n",
    "# SDIRLIST = [\n",
    "#     \"/data2/analyses/database/clustering/bysimilarity/arc2_lines5/Red-210316_024118\",\n",
    "#     \"/data2/analyses/database/clustering/bysimilarity\"/arc2_lines5/Pancho-210316_025556\"\n",
    "#     ]\n",
    "\n",
    "# exptlist = [\"arc2\", \"lines5\", \"figures89\"]\n",
    "# exptlist = [\"lines5\", \"figures9\", \"shapes3\", \"arc2\"]\n",
    "exptlist = []\n",
    "animallist = [\"Red\", \"Pancho\"]\n",
    "distancelist = [\"euclidian_diffs\", \"euclidian\", \"hausdorff_means\"]\n",
    "SDIRMAIN = \"/data2/analyses/database/clustering/bysimilarity\"\n",
    "strokesver_list = [\"beh\", \"parse\"]\n",
    "strokesver_list = [\"\"]\n",
    "rescale = \"stretch_to_1\"\n",
    "suffix = \"-combined_parse_beh\"\n",
    "overwrite = False\n",
    "dry_run=True\n",
    "\n",
    "SDIRlist=[]\n",
    "import glob\n",
    "for anim in animallist:\n",
    "    for distver in distancelist:\n",
    "        for sver in strokesver_list:\n",
    "            if sver:\n",
    "                sverthis = f\"-strokes_{sver}\"\n",
    "            else:\n",
    "                sverthis = \"\"\n",
    "            f = f\"{SDIRMAIN}/*{'*'.join(exptlist)}*-rescale_{rescale}-dist_{distver}{sverthis}{suffix}/{anim}*\"\n",
    "#             print(f)\n",
    "            dirlist = glob.glob(f)\n",
    "            \n",
    "            for d in dirlist:\n",
    "\n",
    "                SDIR = d\n",
    "                print(SDIR)\n",
    "                SDIRlist.append(SDIR)\n",
    "                \n",
    "            if not dry_run:                \n",
    "                plots(SDIR, overwrite, gmm_n=14, plotGrid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (new + old) new way of loading dirs, but old way of wrapper, all plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching using this string:\n",
      "/data2/analyses/database/clustering/bysimilarity/*indiv*/*rescale*stretch_to_1*euclidian_diffs*strokes_beh_splines*/*Pancho*/*SAVEDAT*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/data2/analyses/database/clustering/bysimilarity/indiv/rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh_splines/Pancho-210403_180027\n",
      "** Plotting this dir: /data2/analyses/database/clustering/bysimilarity/indiv/rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh_splines/Pancho-210403_180027\n",
      "{'animallist': ['Pancho'], 'exptlist': ['arc2', 'figures9', 'lines5', 'shapes3', 'shapes3v2'], 'params': {'rescale_strokes_ver': 'stretch_to_1', 'distancever': 'euclidian_diffs'}}\n",
      "dict_keys(['animallist', 'exptlist', 'params'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tsne_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-75f4c7f16708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mSDIR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSDIRlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotGrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplotGrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mplots\u001b[0;34m(SDIR, overwrite, gmm_n, perp, plotGrid)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# === add columns to SF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mSF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepSF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVEDAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[0;31m# === pca plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mprepSF\u001b[0;34m(SF, SAVEDAT, perp)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVEDAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVEDAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mXtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"D_fit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVEDAT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tsne_models\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"perp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mperp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXtsne\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mSF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Xtsne\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tsne_models'"
     ]
    }
   ],
   "source": [
    "from pythonlib.tools.expttools import findPath\n",
    "dry_run=False\n",
    "overwrite = True\n",
    "plotGrid = False\n",
    "\n",
    "path_base = \"/data2/analyses/database/clustering/bysimilarity\"\n",
    "\n",
    "# Inidiv params\n",
    "indiv=True\n",
    "strokes_ver = \"strokes_beh_splines\"\n",
    "list_animal = [\"Pancho\"]\n",
    "# strokes_ver = \"strokes_parse\"\n",
    "for animal in list_animal:\n",
    "#     animal = \"Red\"\n",
    "\n",
    "    path_fname = \"SAVEDAT\"\n",
    "    ext = \".pkl\"\n",
    "\n",
    "\n",
    "    # Load paths for indiv data\n",
    "    if indiv:\n",
    "        path_hierarchy = [\n",
    "            [\"indiv\"],\n",
    "            [\"rescale\", \"stretch_to_1\", \"euclidian_diffs\", strokes_ver],\n",
    "            [animal],\n",
    "        ]\n",
    "    else:\n",
    "        # Load paths for combined data\n",
    "        assert False, \"what is this bullshit\"\n",
    "        path_hierarchy = [\n",
    "            [\"combined\"],\n",
    "            [\"Red\", \"Pancho\"],\n",
    "            [\"Pancho\", \"Red\"],\n",
    "        ]\n",
    "\n",
    "    SDIRlist = findPath(path_base, path_hierarchy, path_fname, ext, \n",
    "                        return_without_fname=True)\n",
    "\n",
    "\n",
    "    if not dry_run:      \n",
    "        for SDIR in SDIRlist:\n",
    "            plots(SDIR, overwrite, gmm_n=14, plotGrid=plotGrid);\n",
    "            plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (new code) Loading pre-computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.expttools import findPath\n",
    "# Load paths for indiv data\n",
    "path_base = \"/data2/analyses/database/clustering/bysimilarity/indiv\"\n",
    "path_fname = \"SAVEDAT\"\n",
    "ext = \".pkl\"\n",
    "\n",
    "path_hierarchy = [\n",
    "    [\"stretch_to_1\", \"dist_euclidian_diffs\", \"strokes_beh_splines\"],\n",
    "    [\"\"]]\n",
    "SDIRlist1 = findPath(path_base, path_hierarchy, path_fname, ext, return_without_fname=True)\n",
    "\n",
    "path_hierarchy = [\n",
    "    [\"stretch_to_1\", \"dist_euclidian_diffs\", \"strokes_parse\"],\n",
    "    [\"\"]]\n",
    "SDIRlist2 = findPath(path_base, path_hierarchy, path_fname, ext, return_without_fname=True)\n",
    "\n",
    "SDIR_list = SDIRlist1\n",
    "SDIR_list.extend(SDIRlist2)\n",
    "print(\"=== GETTING THESE SF indivs\")\n",
    "print(len(SDIR_list))\n",
    "[print(s) for s in SDIR_list]\n",
    "\n",
    "# Load multiple presaved SF, and concatnate.\n",
    "import pickle\n",
    "SFall =[]\n",
    "print(\"LOADING SF:\")\n",
    "for SDIR in SDIR_list:\n",
    "    path = f\"{SDIR}/SF.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        SF = pickle.load(f)\n",
    "\n",
    "    # add column to map back to original dataset\n",
    "    SF[\"path_to_sf\"] = path\n",
    "\n",
    "    if \"Dataset\" in SF.columns:\n",
    "        del SF[\"Dataset\"]\n",
    "    print(\"---\")\n",
    "    print(path)\n",
    "    print(\"extracted SF, length\")\n",
    "    print(len(SF))\n",
    "    SFall.append(SF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# SF = SFall[0]\n",
    "SF = pd.concat(SFall)\n",
    "SF = SF.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist([s.shape[1] for s in SF[\"strok\"].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  GOOD - load coimbined data (single dataset, already done combinngi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.expttools import findPath\n",
    "\n",
    "# Load paths for combined data\n",
    "# path_base = \"/data2/analyses/database/clustering/bysimilarity\"\n",
    "# path_hierarchy = [\n",
    "#     [\"combined\"],\n",
    "#     [\"Red\", \"Pancho\", \"parse_vs_behsplines\"],\n",
    "#     [\"Pancho\", \"Red\"],\n",
    "# ]\n",
    "path_base = \"/data2/analyses/database/clustering/bysimilarity\"\n",
    "path_hierarchy = [\n",
    "    [\"combined\"],\n",
    "    [\"Red\", \"Pancho\", \"parse_vs_behsplines\"],\n",
    "    [\"Pancho\", \"Red\"],\n",
    "]\n",
    "path_fname = \"SAVEDAT\"\n",
    "ext = \".pkl\"\n",
    "SDIRlist = findPath(path_base, path_hierarchy, path_fname, ext, return_without_fname=True)\n",
    "\n",
    "# === Load data\n",
    "\n",
    "SF, SAVEDAT = loadSF(SDIRlist[0])\n",
    "\n",
    "\n",
    "# === print summary\n",
    "print(\"=== SUMMARIZING\")\n",
    "keys_to_skip = [\"similarity_matrix\", 'Xpca', 'tsne_models', 'gmm_models', 'pca_model']\n",
    "for k, v in SAVEDAT.items():\n",
    "    if k not in keys_to_skip:\n",
    "        print(\"--\")\n",
    "        print(k)\n",
    "        print(v)\n",
    "        \n",
    "nbase = SAVEDAT[\"similarity_matrix\"].shape\n",
    "print(\"-- Shape of similarity matrix:\")\n",
    "print(nbase)\n",
    "        \n",
    "\n",
    "# Assign parse status - for each row True or False.\n",
    "\n",
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "\n",
    "# HACK, to tell whether is parse or real, \n",
    "if \"path_to_sf\" not in SF.columns:\n",
    "    print(\"ARE YOU SURE - THIS ONLY WORKS IF PARSES HAVE TIMES WITH diffs of 1 (0, 1, 2....)\")\n",
    "    def F(x):\n",
    "        \"\"\" returns true is this is parse, bsaed on time intervals being 1\n",
    "        \"\"\"\n",
    "        return np.all(np.isclose(np.unique(np.diff(x[\"strok\"][:,2])), 1.))\n",
    "\n",
    "else:\n",
    "    # Note, use set(SF[\"path_to_sf\"]) to find the paths.\n",
    "    \n",
    "    print(\"USING BETTER OPTION, based on ground truth path name\")\n",
    "    # Map from path of original dataset --> whether is parse or beh\n",
    "    map_path_to_parse = {\n",
    "       \"/data2/analyses/database/clustering/bysimilarity/lines5_arc2_figures8_figures9_shapes3-rescale_stretch_to_1-dist_euclidian_diffs-strokes_parse/Red-210402_015236/SF.pkl\":True,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/lines5_arc2_figures9_shapes3v2_shapes3-rescale_stretch_to_1-dist_euclidian_diffs-strokes_parse/Pancho-210402_015304/SF.pkl':True,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3_arc2_figures8-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Red-210401_214709/SF.pkl':False,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3v2_shapes3_arc2-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Pancho-210401_214315/SF.pkl':False,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/indiv/lines5_arc2_figures8_figures9_shapes3-rescale_stretch_to_1-dist_euclidian_diffs-strokes_parse/Red-210402_015236/SF.pkl':True,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/indiv/lines5_arc2_figures9_shapes3v2_shapes3-rescale_stretch_to_1-dist_euclidian_diffs-strokes_parse/Pancho-210402_015304/SF.pkl':True,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/indiv/rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh_splines/Pancho-210403_180027/SF.pkl':False,\n",
    "        '/data2/analyses/database/clustering/bysimilarity/indiv/rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh_splines/Red-210403_180040/SF.pkl':False   \n",
    "    }\n",
    "    def F(x):\n",
    "        return map_path_to_parse[x[\"path_to_sf\"]]\n",
    "\n",
    "SF = applyFunctionToAllRows(SF, F, newcolname=\"is_parse\")\n",
    "\n",
    "\n",
    "# Dataset codes - have a field <animal>_<isparse>\n",
    "def F(x):\n",
    "    if x[\"is_parse\"]:\n",
    "        tmp = \"parse\"\n",
    "    else:\n",
    "        tmp = \"beh\"        \n",
    "    return f\"{x['animal']}_{tmp}\"\n",
    "    \n",
    "SF = applyFunctionToAllRows(SF, F, newcolname=\"animal_dset\")\n",
    "\n",
    "\n",
    "# Summarize assignment to datasets. make sure it is staircase like\n",
    "plt.figure()\n",
    "plt.plot(SF[\"animal_dset\"])\n",
    "print(\"Dataset -- Trial count\")\n",
    "SF[\"animal_dset\"].value_counts()\n",
    "\n",
    "# == filtering SF to get only same tasks\n",
    "from analysis.strok import prepSF, get_SF_shared_tasks\n",
    "\n",
    "SF = prepSF(SF, SAVEDAT, perp=45)\n",
    "\n",
    "# get common tasks.\n",
    "SF_sharedtasks = get_SF_shared_tasks(SF)\n",
    "\n",
    "# == plot example trials\n",
    "\n",
    "# 1) Go back and reload dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE PLOTS, but recolor different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.strok import plotTsneSeparateLabels\n",
    "plotTsneSeparateLabels(SF_sharedtasks, SAVEDAT)\n",
    "\n",
    "plotTsneSeparateLabelsHeatmap(SF, 40)\n",
    "\n",
    "from analysis.strok import gmm_labels, gmm_extract_model\n",
    "gmm_n = 14\n",
    "mod = gmm_extract_model(SAVEDAT, gmm_n)\n",
    "labels_gmm, SF = gmm_labels(SAVEDAT, gmm_n, SF)\n",
    "\n",
    "\n",
    "SF = gmm_labels_resort(SF)\n",
    "\n",
    "# == plot\n",
    "import seaborn as sns\n",
    "# plt.figure(figsize=(15,5))\n",
    "fig = sns.displot(data=SF, x=\"label_resorted\",hue=\"animal_dset\", stat=\"probability\", multiple=\"dodge\", \n",
    "                  element=\"bars\", shrink=1, aspect=3, height=5)\n",
    "fig.axes[0][0].set_xticks(range(len(diffs)))\n",
    "fig.axes[0][0].set_xticklabels([d[0] for d in diffs])\n",
    "# sns.histplot(data=SF, x=\"label\", hue=\"animal_dset\", stat=\"probability\", multiple=\"dodge\", element=\"bars\", shrink=1.5)\n",
    "fig = sns.displot(data=SF, x=\"label_resorted\", row=\"animal_dset\", stat=\"probability\", multiple=\"dodge\", element=\"bars\", shrink=1, aspect=3, height=5)\n",
    "\n",
    "# == plot example trials\n",
    "ploStrokOrderedByLabel(SF[\"label\"].values, SF, [d[0] for d in diffs])\n",
    "\n",
    "\n",
    "# one separate plot for each dataset, but coloring by label.\n",
    "for dset in sorted(list(set(labels_dset))):\n",
    "    inds = labels_dset == dset\n",
    "    Xthis = Xtsne[inds]\n",
    "    labels_this = labels_gmm[inds]\n",
    "    fig, ax = plotScatterOverlay(Xthis, labels_this, ver=\"overlay\", alpha=1)\n",
    "    # fig.savefig(f\"{SDIRFIGS}/tsne-scatter-epochs.pdf\")\n",
    "    fig.suptitle(dset)\n",
    "\n",
    "# def plotHistOfLabels(labels):\n",
    "#     \"\"\" Plot historgram of labels,\n",
    "#     INPUT:\n",
    "#     - labels, vector of labels, could be string or num, \n",
    "#     \"\"\"\n",
    "\n",
    "#     # get counts for each label\n",
    "#     from pythonlib.tools.listtools import tabulate_list\n",
    "#     tab = tabulate_list(labels, return_as_list=True)\n",
    "    \n",
    "#     # sort\n",
    "#     tab = sorted(tab, key=lambda x:x[0])\n",
    "    \n",
    "#     # plot\n",
    "#     x = [t[0] for t in tab]\n",
    "#     y = [t[1] for t in tab]\n",
    "#     plt.figure()\n",
    "#     plt.bar(x, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# plotHistOfLabels(labels_gmm)\n",
    "\n",
    "\n",
    "plotHistDatasets(SF)\n",
    "\n",
    "# === plot example trials, ordered by labels.\n",
    "from analysis.strok import *\n",
    "\n",
    "plotStrokOrderedByLabel(SF[\"label\"].values, SF)\n",
    "\n",
    "SF[\"monkey_train_or_test\"]\n",
    "\n",
    "#### PULL OUT SEPARATE DATASETS TO LOOK AT CHANGE OVER TIME\n",
    "\n",
    "animal_dset = \"Red_beh\"\n",
    "# expt_epochs_to_keep = ['lines5-2', 'lines5-1', 'arc2-1', 'figures9']\n",
    "expt_epochs_to_keep = ['lines5-2', 'lines5-1']\n",
    "train_test = \"test\"\n",
    "# expt_epochs_to_keep = ['lines5-2', 'lines5-1']\n",
    "\n",
    "# 1) pull out this dataset\n",
    "inds = (SF[\"animal_dset\"]==animal_dset) & (SF[\"expt-epoch\"].isin(expt_epochs_to_keep)) & (SF[\"monkey_train_or_test\"]==train_test)\n",
    "SFthis = SF[inds]\n",
    "\n",
    "# 2) equalize trials across expt-epochs\n",
    "# expt_epoch_list = list(set(SFthis[\"expt-epoch\"]))\n",
    "# SFthis = get_SF_shared_tasks(SFthis, col_to_equalize_over=\"expt-epoch\")\n",
    "\n",
    "labels=SFthis[\"expt-epoch\"].values\n",
    "plotTsneSeparateLabels(SFthis, SAVEDAT, labels)\n",
    "\n",
    "\n",
    "plotHistDatasets(SFthis, \"label\", sort_by=\"expt-epoch\", shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# === PLOT A SINGLE EXPT\n",
    "for SDIR in [\n",
    "    \"/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3_arc2_figures8-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Red-210401_214709\"\n",
    "    \n",
    "    \"/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3v2_shapes3_arc2-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Pancho-210401_214617\"\n",
    "    \"/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3v2_shapes3_arc2-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Pancho-210401_214617\"\n",
    "    \"/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3v2_shapes3_arc2-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Pancho-210401_214617\"\n",
    "]:\n",
    "    plots(SDIR, overwrite=True, gmm_n=14, plotGrid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === JUST LOAD AND PRINT INFORMATION\n",
    "SDIR = \"/data2/analyses/database/clustering/bysimilarity/lines5_figures9_shapes3v2_shapes3_arc2-rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh/Pancho-210401_214617\"\n",
    "\n",
    "SF, SAVEDAT = loadSF(SDIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/23/21 - trying to figure out old code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) load preextracted data (extraction in devo_strokemanifold_good_041221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/analyses/database/combined_strokfeats/Pancho-gridlinecircle-strokes_beh_splines-210923_210307/embeddings/similarity-stretch_to_1-euclidian_diffs-N5-210923_210307/\n",
      "* dat_clust: dict_keys(['pca_model', 'Xpca', 'models_tsne', 'models_gmm', 'similarity_matrix', 'gmm_n_mixtures', 'perplist', 'gmm_covariance_type'])\n",
      "* params: {'rescale_strokes_ver': 'stretch_to_1', 'distancever': 'euclidian_diffs', 'npts_space': 50, 'Nbasis': 5, 'idxs_stroklist_basis': [73, 76, 4, 3, 60], 'path_embeddings_similarity': '/data2/analyses/database/combined_strokfeats/Pancho-gridlinecircle-strokes_beh_splines-210923_210307/embeddings/similarity-stretch_to_1-euclidian_diffs-N5-210923_210307'}\n",
      "* SF Index(['stroknum', 'strok', 'row_in_Dataset', 'trial_end_method',\n",
      "       'online_abort', 'task_stagecategory', 'origin', 'donepos',\n",
      "       'motortiming', 'motorevents', 'holdtime', 'delaytime',\n",
      "       'unique_task_name', 'datetime', 'supervision_params', 'abort_params',\n",
      "       'animal', 'beh_multiplier', 'bias_multiplier', 'binary_evaluation',\n",
      "       'block', 'date', 'dist_total', 'frac_overlap', 'frac_touched',\n",
      "       'ft_decim', 'ft_minobj', 'hausdorff', 'keepforsummary', 'posterior',\n",
      "       'random_task', 'rew_total', 'score_final', 'session', 'shortness',\n",
      "       'taskgroup', 'traintest', 'trial', 'trialcode', 'which_metadat_idx',\n",
      "       'expt', 'monkey_train_or_test', 'tvalfake', 'tvalday', 'epoch',\n",
      "       'aborted', 'character', 'insummarydates', 'idx_metadat', 'strokes_ver',\n",
      "       'numstrokes', 'distance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pathdir = \"/data2/analyses/database/combined_strokfeats/Pancho-gridlinecircle-strokes_beh_splines-210923_210307/embeddings/similarity-stretch_to_1-euclidian_diffs-N5-210923_210307/\"\n",
    "\n",
    "print(pathdir)\n",
    "\n",
    "path_clust = f\"{pathdir}/clustering/DAT.pkl\"\n",
    "path_sim = f\"{pathdir}/dat.pkl\"\n",
    "\n",
    "with open(path_clust, \"rb\") as f:\n",
    "    dat_clust = pickle.load(f)\n",
    "    \n",
    "with open(path_sim, \"rb\") as f:\n",
    "    sim_mat = pickle.load(f)\n",
    "    \n",
    "with open(f\"{pathdir}/params.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "path_sf = pathdir = \"/data2/analyses/database/combined_strokfeats/Pancho-gridlinecircle-strokes_beh_splines-210923_210307/SF.pkl\"\n",
    "with open(path_sf, \"rb\") as f:\n",
    "    SF = pickle.load(f)\n",
    "    \n",
    "    \n",
    "print(\"* dat_clust:\", dat_clust.keys())\n",
    "print(\"* params:\", params)\n",
    "print(\"* SF\", SF.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset -- Trial count\n",
      "TODO, NOTE: shouuld instead match num trials, but havent coded\n",
      "0 _line_4-1-2562578359\n",
      "This many shared tasks (out of total...):\n",
      "69\n",
      "69\n",
      "New len of SF after matching tasks and num trials exactly:\n",
      "97\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythonlib.tools.expttools import findPath\n",
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "\n",
    "# TODO: Fill this column with whether is parse\"\n",
    "if True:\n",
    "    def F(x):\n",
    "        return False\n",
    "    SF = applyFunctionToAllRows(SF, F, newcolname=\"is_parse\")\n",
    "\n",
    "\n",
    "# Dataset codes - have a field <animal>_<isparse>\n",
    "def F(x):\n",
    "    if x[\"is_parse\"]:\n",
    "        tmp = \"parse\"\n",
    "    else:\n",
    "        tmp = \"beh\"        \n",
    "    return f\"{x['animal']}_{tmp}\"\n",
    "SF = applyFunctionToAllRows(SF, F, newcolname=\"animal_dset\")\n",
    "\n",
    "\n",
    "# Summarize assignment to datasets. make sure it is staircase like\n",
    "plt.figure()\n",
    "plt.plot(SF[\"animal_dset\"])\n",
    "print(\"Dataset -- Trial count\")\n",
    "SF[\"animal_dset\"].value_counts()\n",
    "\n",
    "# == filtering SF to get only same tasks\n",
    "from analysis.strok import prepSF, get_SF_shared_tasks\n",
    "\n",
    "# get common tasks.\n",
    "SF_sharedtasks = get_SF_shared_tasks(SF)\n",
    "\n",
    "# == plot example trials\n",
    "\n",
    "# 1) Go back and reload dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: go thru everything below and convert to work with current data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Xtsne'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Xtsne'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3124787a4c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotTsneSeparateLabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotTsneSeparateLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF_sharedtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplotTsneSeparateLabelsHeatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mplotTsneSeparateLabels\u001b[0;34m(SF, SAVEDAT, labels, perp)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;31m# Xtsne = extractTsne(SAVEDAT, perp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# assert Xtsne.shape[0]==len(SF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0mXtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tsne\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;31m# aasign each row a label, based on animal_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mextractX\u001b[0;34m(SF, ver)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Xsim\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Xtsne'"
     ]
    }
   ],
   "source": [
    "from analysis.strok import plotTsneSeparateLabels\n",
    "plotTsneSeparateLabels(SF_sharedtasks)\n",
    "\n",
    "plotTsneSeparateLabelsHeatmap(SF, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SF_sharedtasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8356202a043e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotTsneSeparateLabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotTsneSeparateLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF_sharedtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVEDAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplotTsneSeparateLabelsHeatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SF_sharedtasks' is not defined"
     ]
    }
   ],
   "source": [
    "from analysis.strok import gmm_labels, gmm_extract_model\n",
    "gmm_n = 14\n",
    "mod = gmm_extract_model(SAVEDAT, gmm_n)\n",
    "labels_gmm, SF = gmm_labels(SAVEDAT, gmm_n, SF)\n",
    "\n",
    "\n",
    "SF = gmm_labels_resort(SF)\n",
    "\n",
    "# == plot\n",
    "import seaborn as sns\n",
    "# plt.figure(figsize=(15,5))\n",
    "fig = sns.displot(data=SF, x=\"label_resorted\",hue=\"animal_dset\", stat=\"probability\", multiple=\"dodge\", \n",
    "                  element=\"bars\", shrink=1, aspect=3, height=5)\n",
    "fig.axes[0][0].set_xticks(range(len(diffs)))\n",
    "fig.axes[0][0].set_xticklabels([d[0] for d in diffs])\n",
    "# sns.histplot(data=SF, x=\"label\", hue=\"animal_dset\", stat=\"probability\", multiple=\"dodge\", element=\"bars\", shrink=1.5)\n",
    "fig = sns.displot(data=SF, x=\"label_resorted\", row=\"animal_dset\", stat=\"probability\", multiple=\"dodge\", element=\"bars\", shrink=1, aspect=3, height=5)\n",
    "\n",
    "# == plot example trials\n",
    "ploStrokOrderedByLabel(SF[\"label\"].values, SF, [d[0] for d in diffs])\n",
    "\n",
    "\n",
    "# one separate plot for each dataset, but coloring by label.\n",
    "for dset in sorted(list(set(labels_dset))):\n",
    "    inds = labels_dset == dset\n",
    "    Xthis = Xtsne[inds]\n",
    "    labels_this = labels_gmm[inds]\n",
    "    fig, ax = plotScatterOverlay(Xthis, labels_this, ver=\"overlay\", alpha=1)\n",
    "    # fig.savefig(f\"{SDIRFIGS}/tsne-scatter-epochs.pdf\")\n",
    "    fig.suptitle(dset)\n",
    "\n",
    "# def plotHistOfLabels(labels):\n",
    "#     \"\"\" Plot historgram of labels,\n",
    "#     INPUT:\n",
    "#     - labels, vector of labels, could be string or num, \n",
    "#     \"\"\"\n",
    "\n",
    "#     # get counts for each label\n",
    "#     from pythonlib.tools.listtools import tabulate_list\n",
    "#     tab = tabulate_list(labels, return_as_list=True)\n",
    "    \n",
    "#     # sort\n",
    "#     tab = sorted(tab, key=lambda x:x[0])\n",
    "    \n",
    "#     # plot\n",
    "#     x = [t[0] for t in tab]\n",
    "#     y = [t[1] for t in tab]\n",
    "#     plt.figure()\n",
    "#     plt.bar(x, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# plotHistOfLabels(labels_gmm)\n",
    "\n",
    "\n",
    "plotHistDatasets(SF)\n",
    "\n",
    "# === plot example trials, ordered by labels.\n",
    "from analysis.strok import *\n",
    "\n",
    "plotStrokOrderedByLabel(SF[\"label\"].values, SF)\n",
    "\n",
    "SF[\"monkey_train_or_test\"]\n",
    "\n",
    "#### PULL OUT SEPARATE DATASETS TO LOOK AT CHANGE OVER TIME\n",
    "\n",
    "animal_dset = \"Red_beh\"\n",
    "# expt_epochs_to_keep = ['lines5-2', 'lines5-1', 'arc2-1', 'figures9']\n",
    "expt_epochs_to_keep = ['lines5-2', 'lines5-1']\n",
    "train_test = \"test\"\n",
    "# expt_epochs_to_keep = ['lines5-2', 'lines5-1']\n",
    "\n",
    "# 1) pull out this dataset\n",
    "inds = (SF[\"animal_dset\"]==animal_dset) & (SF[\"expt-epoch\"].isin(expt_epochs_to_keep)) & (SF[\"monkey_train_or_test\"]==train_test)\n",
    "SFthis = SF[inds]\n",
    "\n",
    "# 2) equalize trials across expt-epochs\n",
    "# expt_epoch_list = list(set(SFthis[\"expt-epoch\"]))\n",
    "# SFthis = get_SF_shared_tasks(SFthis, col_to_equalize_over=\"expt-epoch\")\n",
    "\n",
    "labels=SFthis[\"expt-epoch\"].values\n",
    "plotTsneSeparateLabels(SFthis, SAVEDAT, labels)\n",
    "\n",
    "\n",
    "plotHistDatasets(SFthis, \"label\", sort_by=\"expt-epoch\", shrink=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Plotting this dir: /data2/analyses/database/clustering/bysimilarity/indiv/rescale_stretch_to_1-dist_euclidian_diffs-strokes_beh_splines/Pancho-210403_180027\n",
      "{'animallist': ['Pancho'], 'exptlist': ['arc2', 'figures9', 'lines5', 'shapes3', 'shapes3v2'], 'params': {'rescale_strokes_ver': 'stretch_to_1', 'distancever': 'euclidian_diffs'}}\n",
      "dict_keys(['animallist', 'exptlist', 'params'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tsne_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2c8aa28f4ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1) modify the below to take in current diectory structuer (old plots wrapper)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotGrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mplots\u001b[0;34m(SDIR, overwrite, gmm_n, perp, plotGrid)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# === add columns to SF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mSF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepSF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVEDAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[0;31m# === pca plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mprepSF\u001b[0;34m(SF, SAVEDAT, perp)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVEDAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVEDAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mXtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"D_fit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVEDAT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tsne_models\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"perp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mperp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXtsne\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mSF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Xtsne\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tsne_models'"
     ]
    }
   ],
   "source": [
    "# 1) modify the below to take in current diectory structuer (old plots wrapper)    \n",
    "plots(SDIR, overwrite=True, gmm_n=14, plotGrid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SFthis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c024d0ce16d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotHistDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSFthis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expt-epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplotTsneSeparateLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSFthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVEDAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SFthis' is not defined"
     ]
    }
   ],
   "source": [
    "from analysis.strok import plotHistDatasets\n",
    "labels=SFthis[\"expt-epoch\"].values\n",
    "plotTsneSeparateLabels(SFthis, SAVEDAT, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `label` for parameter `x`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3f958630fc81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotHistDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotHistDatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data1/code/python/drawmonkey/analysis/strok.py\u001b[0m in \u001b[0;36mplotHistDatasets\u001b[0;34m(SF, label, sort_by, shrink)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \"\"\"\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"probability\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dodge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"probability\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dodge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mdisplot\u001b[0;34m(data, x, y, hue, row, col, weights, kind, rug, rug_kws, log_scale, legend, palette, hue_order, hue_norm, color, col_wrap, row_order, col_order, height, aspect, facet_kws, **kwargs)\u001b[0m\n\u001b[1;32m   2147\u001b[0m     p = _DistributionFacetPlotter(\n\u001b[1;32m   2148\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2149\u001b[0;31m         \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DistributionFacetPlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2150\u001b[0m     )\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    107\u001b[0m     ):\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             plot_data, variables = self._assign_variables_longform(\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m             )\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `label` for parameter `x`"
     ]
    }
   ],
   "source": [
    "plotHistDatasets(SF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stroknum', 'strok', 'row_in_Dataset', 'trial_end_method',\n",
       "       'online_abort', 'task_stagecategory', 'origin', 'donepos',\n",
       "       'motortiming', 'motorevents', 'holdtime', 'delaytime',\n",
       "       'unique_task_name', 'datetime', 'supervision_params', 'abort_params',\n",
       "       'animal', 'beh_multiplier', 'bias_multiplier', 'binary_evaluation',\n",
       "       'block', 'date', 'dist_total', 'frac_overlap', 'frac_touched',\n",
       "       'ft_decim', 'ft_minobj', 'hausdorff', 'keepforsummary', 'posterior',\n",
       "       'random_task', 'rew_total', 'score_final', 'session', 'shortness',\n",
       "       'taskgroup', 'traintest', 'trial', 'trialcode', 'which_metadat_idx',\n",
       "       'expt', 'monkey_train_or_test', 'tvalfake', 'tvalday', 'epoch',\n",
       "       'aborted', 'character', 'insummarydates', 'idx_metadat', 'strokes_ver',\n",
       "       'numstrokes', 'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO - plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. better auto model selection\n",
    "2. plot more rows for heat map, pca [DONE]\n",
    "3. shuffle analysis for the \"control for stimulus\" version of category labels.\n",
    "4. for each category, how confident are the assignemnets?\n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAKIGN STOCK - clustering\n",
    "\n",
    "Best representation:\n",
    "1. metric: hausdorff (mean,mean, this is crucial to make the distrubtiions gaussian-like. if use max, then will not be.\n",
    "2. use similarity, scaled bwteen range 0 to 1.\n",
    "\n",
    "Note, it is possible that will be able to fit with GMM, seems to have clusters,\n",
    "especialyl when include more variation in primitives.\n",
    "\n",
    "But clearly is different for testing for the same tasks, across epochs, and clearly falls into more longer/curvy vs. short/straight\n",
    "\n",
    "Should improve the embeddings, perhaps include also hand-crafted componetns, like length, curvature, etc.\n",
    "\n",
    "Distance metric:\n",
    "- Consider also allowing for some variation, kind of like procrustes score. \n",
    "Or use splines?\n",
    "\n",
    "GMM notes:\n",
    "- diagonal covariance with much works cross val score (ll and bic). comapred to full.\n",
    "\n",
    "What learn from this:\n",
    "1. Structure of variation across strokes in repertoire\n",
    "2. Difference in this structure based on learning (and animal)\n",
    "3. Non-uniform distribution - evidence for compression. Test this by comparing to null distribution.\n",
    "4. Growth in primitives over learning (strongest evidence, consider same tasks shown througout lifetime\n",
    "5. Different primitives \n",
    "\n",
    "To do:\n",
    "1. Construct global embedding, using all models that will be considered: (animals) (task/ground truth) (nn) \n",
    "2. Then plot each expt in this space. (e.g., show that animals more clustered than \n",
    "3. Include more expriments, inculding more vairation in primtiives (e..g, curves, arcs, etc)\n",
    "4. Fit GMM within each expt, since part of this could be drift over time. Think of this as: first get some embedding that is global, then do clustering in that space (ie space of PCA of features)\n",
    "5. GMM tends to split. Somehow constrain to combine more? maybe dont use full covariance?\n",
    "\n",
    "-- NOTES ON SIMILARITY MATRIX\n",
    "\n",
    "Longer strokes will tend to be more different from others, even those that are long, perhaps this is fine, \n",
    "since in the end this is the \"signature\" of the stroke\n",
    "\n",
    "Normalizing to a global max distance. This makes sense, since let's  say a stroke is different from all others, then dont want to help it out by normalizing.\n",
    "\n",
    "NOTE:\n",
    "An issue is that long lines can be penalized. How to deal with this? convert to spline?\n",
    "\n",
    "\n",
    "Technical:\n",
    "More compact extraction of stroks, compatible easily with probedat, e..g, code to flatten that?\n",
    "Why min stroke length filter not working?\n",
    "\n",
    "\n",
    "Other thoughts;\n",
    "### TO DO:\n",
    "\n",
    "1) add columns for length, angle, and circularity?\n",
    "\n",
    "2) Still issue, hausdorff is a bit brittle, if stroke are a bit shifted, etc. Change to either: splines, that distance that allows affine transformation, \n",
    "\n",
    "3) Note that this is probably a bigger issue for clustering than for scoring, since scoring is relative.\n",
    "\n",
    "\n",
    "## Other to do:\n",
    "1. filter no trials w timeout error. or other indication that I did it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (datset comparison using GMM?)\n",
    "\n",
    "1. fit model using training data, see how well predict held-out training and test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAKING STOCK\n",
    "\n",
    "TO DO:\n",
    "1. come upw ith general purpose normalization for distances, so that each column is in range of around 0 to 1.\n",
    "(could also apply this to the clustering code, although not needed since therye can normalize relatrive to entire dataset)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
