{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nDerived from analysis_line2_multsession..\\nHere meant to be general (e.g., lines5 also).\\nthis eventually should replace lines2 code.\\n\\nTHIS IS GOOD CODE - lots of stuff.\\n\\nAnALYSIS focusing on datapoint = trial\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Derived from analysis_line2_multsession..\n",
    "Here meant to be general (e.g., lines5 also).\n",
    "this eventually should replace lines2 code.\n",
    "\n",
    "THIS IS GOOD CODE - lots of stuff.\n",
    "\n",
    "AnALYSIS focusing on datapoint = trial\n",
    "\n",
    "[OBSOLETE CODE] - this all in analysis_mem2\n",
    "[USEFUL HERE - scratch notes and todo list below]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/code/python/drawmonkey\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: need to not overwrite strokes_all_task, because then the orders saved will stop being accurate. Modify\n"
     ]
    }
   ],
   "source": [
    "from tools.utils import * \n",
    "from tools.plots import *\n",
    "from tools.analy import *\n",
    "from tools.calc import *\n",
    "from tools.analyplot import *\n",
    "from tools.preprocess import *\n",
    "from tools.dayanalysis import *\n",
    "from analysis.line2 import *\n",
    "from analysis.modelexpt import *\n",
    "\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACROSS-DAY ANALYSIS (MULTI ANIMAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: this is all moved to analysis_mem2. (combinimg with task model code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expt = \"lines5\"\n",
    "# # max_strokenum = 2 # for single stroke plots\n",
    "# thingstoplot = [\"alltrials\", \"egtrials\"]\n",
    "# # thingstoplot = [\"egtrials\"]\n",
    "\n",
    "# def plotalltrials(PROBEDATthis, fdlist, stage, datelist, tasklist):\n",
    "#     tasklist = sorted(set([P[\"unique_task_name\"] for P in PROBEDATthis if P[\"task_stagecategory\"]==stage]))\n",
    "#     if len(tasklist)>100:\n",
    "#         assert False, \"why so many tasks for this stage?\"\n",
    "\n",
    "#     # -- Plot 2d grid, separated by days\n",
    "#     CAT1 = [\"date\", datelist]\n",
    "#     CAT2 = [\"unique_task_name\", tasklist]\n",
    "#     fdlist = None\n",
    "\n",
    "#     # == 1) All behavior trials, all strokes overlaid\n",
    "#     plotargs = {\"zoom\":True, \"plotver\":\"order\", \"markersize\":4, \"alpha\":0.25}\n",
    "#     # fdlist = [P[\"filedata\"][0]() for P in PROBEDATthis]\n",
    "#     # fdlist = [FD[P[\"ii\"]][\"fd\"] for P in PROBEDATthis]\n",
    "\n",
    "#     fig = plotTrial2dGrid(PROBEDATthis, fdlist = fdlist, cat1 = CAT1, cat2 = CAT2, ver=\"beh\", plotargs=plotargs);\n",
    "#     fig.savefig(f\"{SAVEDIR}/alltrials_datebycategory_beh_{stage}.pdf\")\n",
    "#     fig = plotTrial2dGrid(PROBEDATthis, fdlist = fdlist, cat1 = CAT1, cat2 = CAT2, ver=\"task\", plotargs=plotargs);\n",
    "#     fig.savefig(f\"{SAVEDIR}/alltrials_datebycategory_task_{stage}.pdf\")\n",
    "\n",
    "#     # == 2) Split by stroke number (one plot for each stroke)\n",
    "#     if False:\n",
    "#         plotargs = {\"zoom\":True, \"plotver\":\"order\", \"markersize\":3, \"alpha\":0.2}\n",
    "#         strokenums_to_plot_alone=list(range(max_strokenum+1))\n",
    "#         overlay_stroke_mean=False\n",
    "\n",
    "#         fig = plotTrial2dGrid(PROBEDATthis, fdlist = fdlist, cat1 = CAT1, cat2 = CAT2, ver=\"behtask\", \n",
    "#                               plotargs=plotargs, strokenums_to_plot_alone=strokenums_to_plot_alone, \n",
    "#                              overlay_stroke_mean = overlay_stroke_mean);\n",
    "#         fig.savefig(f\"{SAVEDIR}/alltrials_datebycategory_eachstroke_beh_{stage}.pdf\")\n",
    "\n",
    "\n",
    "#     # == 3) All strokes (faint) and overlay average\n",
    "#     if False:\n",
    "#         plotargs = {\"zoom\":True, \"plotver\":\"order\", \"markersize\":2, \"alpha\":0.15}\n",
    "\n",
    "#         overlay_stroke_mean=True\n",
    "#         fig = plotTrial2dGrid(PROBEDATthis, fdlist = fdlist, cat1 = CAT1, cat2 = CAT2, ver=\"beh\", \n",
    "#                               plotargs=plotargs, overlay_stroke_mean=overlay_stroke_mean);\n",
    "#         fig.savefig(f\"{SAVEDIR}/alltrials_datebycategory_strokemeans_{stage}.pdf\")\n",
    "\n",
    "\n",
    "# debug=False\n",
    "\n",
    "# ### actual\n",
    "\n",
    "# # Plot same task across days\n",
    "\n",
    "# # 1) Load data across days\n",
    "# from pythonlib.tools.datetools import getDateList\n",
    "# # expt = \"lines2\"\n",
    "# for animal in [\"Pancho\", \"Red\"]:\n",
    "    \n",
    "#     FD, MD = loadMultDataForExpt(expt, animal, whichdates=\"all\", metadatonly=False)\n",
    "#     PROBEDAT = loadProbeDatWrapper(FD, MD, getnumstrokes=True)\n",
    "\n",
    "#     # saving dir\n",
    "#     sdate = MD[\"sdate\"]\n",
    "#     edate = MD[\"edate\"]\n",
    "#     SAVEDIR = f\"{FD[0]['fd']['params']['figuredir_notebook']}/analysis_modelexpt_multsession/{expt}/multday_{animal}_{sdate}_to_{edate}\"\n",
    "#     import os\n",
    "#     os.makedirs(SAVEDIR, exist_ok=True)\n",
    "#     print(f\"saving at {SAVEDIR}\")\n",
    "\n",
    "#     # get all fixed tasks of a particular kind\n",
    "#     kindlist = set([P[\"kind\"] for P in PROBEDAT if P[\"random_task\"]==False])\n",
    "#     task_per_kind = {}\n",
    "#     for kind in kindlist:\n",
    "#         tasklist = set([P[\"unique_task_name\"] for P in PROBEDAT if P[\"kind\"]==kind])\n",
    "#         task_per_kind[kind]=sorted(tasklist)\n",
    "\n",
    "#     print(\"tasks per kind found\")\n",
    "#     for k, v in task_per_kind.items():\n",
    "#         print(\"----\")\n",
    "#         print(f\"=={k}\")\n",
    "#         [print(vv) for vv in v]\n",
    "\n",
    "\n",
    "#     ## PLOT - all trials, 2d grid sorted by date and task category\n",
    "#     # only keep data for fixed tasks.\n",
    "#     PROBEDATthis = [P for P in PROBEDAT if P[\"random_task\"]==False]\n",
    "#     datelist = sorted(set([P[\"date\"] for P in PROBEDATthis]))\n",
    "#     fdlist = None\n",
    "    \n",
    "#     # for each stage, make a 2d grid plot (date x task)\n",
    "#     if \"alltrials\" in thingstoplot:\n",
    "#         # all categories that have fixed tasks\n",
    "#         stagelist = set([P[\"task_stagecategory\"] for P in PROBEDATthis if P[\"random_task\"]==False])\n",
    "#         for stage in stagelist:\n",
    "#             plotalltrials(PROBEDATthis, fdlist, stage, datelist, tasklist)\n",
    "\n",
    "#     # ==== PLOT ALL TRIALS\n",
    "#     if \"egtrials\" in thingstoplot:\n",
    "#         if debug:\n",
    "#             # making plots for lab meeting..\n",
    "#             tasklist = set([P[\"unique_task_name\"] for P in PROBEDATthis if P[\"random_task\"]==False\n",
    "#                and (P[\"task_stagecategory\"] in [\"LplusL\", \"2linePlusL\", \"3linePlusL\"] or \"linePlusLv2_51\" in P[\"unique_task_name\"])])\n",
    "#         else:\n",
    "#             tasklist = set([P[\"unique_task_name\"] for P in PROBEDATthis if P[\"random_task\"]==False])\n",
    "#         NMAX = 20 # trials to plot, starting from 1st trial int he day\n",
    "#         for task in tasklist:\n",
    "\n",
    "#             PD = [P for P in PROBEDATthis if P[\"random_task\"]==False and P[\"unique_task_name\"]==task]\n",
    "\n",
    "#             for reverse in [False, True]:\n",
    "#                 # -- task presentation num as column\n",
    "#                 for P in PD:\n",
    "#                     P[\"idx_today_uniquetask\"] = None\n",
    "#                 PD, countlist = probeDatIndexWithinDay(PD, task, reverse_order=reverse);\n",
    "\n",
    "#                 # -- how many examples to plot?\n",
    "#                 ntoplot = min((max(countlist), NMAX))\n",
    "\n",
    "#                 # -- Plot 2d grid, separated by days\n",
    "#                 CAT1 = [\"date\", datelist]\n",
    "#                 CAT2 = [\"idx_today_uniquetask\", range(ntoplot)]\n",
    "#                 fdlist = None\n",
    "\n",
    "#                 # == 1) All behavior trials, all strokes overlaid\n",
    "#                 plotargs = {\"zoom\":True, \"plotver\":\"order\", \"markersize\":8, \"alpha\":0.7}\n",
    "#                 plot_task_last_col = True\n",
    "#                 ver = \"beh\"\n",
    "\n",
    "#                 fig = plotTrial2dGrid(PD, fdlist = fdlist, cat1 = CAT1, cat2 = CAT2, ver=ver, \n",
    "#                                       plotargs=plotargs, plot_task_last_col=plot_task_last_col);\n",
    "#                 if reverse:\n",
    "#                     fig.savefig(f\"{SAVEDIR}/egtrials_datebyexample_revchronorder_{task}.pdf\")\n",
    "#                 else:\n",
    "#                     fig.savefig(f\"{SAVEDIR}/egtrials_datebyexample_chronorder_{task}.pdf\")\n",
    "\n",
    "#         plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9/22/20 - what I now think as important plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2) Analyze curvature as a measurement of bendiness\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) In general, use stroke model to assign probabilites for each strok for being of certain class (use strokModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from analysis.line2_strokmodelfits import *\n",
    "# def modelResultsGetter(PROBEDAT, model=\"spatial\", fit_tstamp = \"200922_093340_lines2\"):\n",
    "#     \"\"\" given PROBEDAT, return a function that you can use to pull out model \n",
    "#     results for a given trial/stroke\n",
    "#     - model and fit_tstamp index a particular run of model fitting.\n",
    "#     RETURNS:\n",
    "#     - resultGetter, a function that takes in specific details of expt (down to level\n",
    "#     of strokenum) and extracts, from processed dataframe, model fit results.\n",
    "#     NOTE: can fail silently, in that if dosent find something, will return a None.\n",
    "#     should modify so that is known what should or should not exist.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 1) Load previously saved strok model fits.\n",
    "# #     model = \"spatial\"\n",
    "# #     fit_tstamp = \"200922_093340_lines2\"\n",
    "\n",
    "#     datlist = set([(P[\"animal\"], P[\"session\"], P[\"date\"],  P[\"expt\"]) for P in PROBEDAT])\n",
    "\n",
    "#     # for each combo, load and put in a dict, so that can align trials later.\n",
    "#     MODELDAT = []\n",
    "#     for dat in datlist:\n",
    "#         try:\n",
    "#             strokdat, DF, DF2, fd = \\\n",
    "#                 postProcess(dat[0], dat[1], dat[2], dat[3], fit_tstamp=fit_tstamp, model=model,ploton=False)\n",
    "\n",
    "#             print(f\"** GOOD! Found for this dat: {dat}\")\n",
    "#             MODELDAT.append({\n",
    "#                 \"animal\":dat[0],\n",
    "#                 \"date\":dat[2],\n",
    "#                 \"expt\":dat[3],\n",
    "#                 \"session\":dat[1],\n",
    "#                 \"DF\":DF,\n",
    "#                 \"DF2\":DF2\n",
    "#             })\n",
    "#         except FileNotFoundError as err:\n",
    "#             print(err)\n",
    "#             print('SKIPPING')\n",
    "#             continue\n",
    "\n",
    "    \n",
    "#     def resultGetter(animal, date, expt, session, trial, strok_num):\n",
    "#         \"\"\"function to extract model stats for a given trial/stroke, \n",
    "#         given the MODELDAT listy of dicts\n",
    "#         - returns None if can't find for whatever reason\n",
    "#         By default, extracts the model1/model2 score for the trial, which is \n",
    "#         one df row. could also choose to extract one row for each model.\"\"\"\n",
    "\n",
    "#         for M in MODELDAT:\n",
    "#             if M[\"animal\"]==animal and M[\"date\"]==date and M[\"expt\"]==expt and M[\"session\"]==session:\n",
    "#                 DF = M[\"DF\"]\n",
    "#                 DF2 = M[\"DF2\"]\n",
    "\n",
    "#                 if False:\n",
    "#                     DFthis = DF[(DF[\"trial\"]==trial) & (DF[\"strok_num_0\"]==strok_num)]\n",
    "#                 else:\n",
    "#                     DFthis = DF2[(DF2[\"trial\"]==trial) & (DF2[\"strok_num_0\"]==strok_num)]\n",
    "\n",
    "#                 if len(DFthis)==0:\n",
    "#                     return None\n",
    "#                 else:\n",
    "#                     return DFthis\n",
    "#         if False:\n",
    "#             print(\"DID NOT FIND THIS DATA!\")\n",
    "#         return None\n",
    "    \n",
    "# #     extractDatForStroke(MODELDAT, \"Pancho\", \"200907\", \"lines2\", 1, 10, 1)\n",
    "#     return resultGetter\n",
    "\n",
    "# # resultGetter = modelResultsGetter(PROBEDAT, model=\"spatial\", fit_tstamp = \"200922_093340_lines2\")\n",
    "\n",
    "# # resultGetter(\"Pancho\", \"200907\", \"lines2\", 1, 10, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STROKE STATISTICS - ACROSS ANIMALS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE ANIMAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.datetools import getDateList\n",
    "\n",
    "sdate = 200902\n",
    "edate = 200907\n",
    "datelist = getDateList(sdate, edate)\n",
    "\n",
    "expt = \"lines2\"\n",
    "animal = \"Pancho\"\n",
    "    \n",
    "dattoget = []\n",
    "for d in datelist:\n",
    "    dattoget.append([expt, animal, d])\n",
    "\n",
    "FD = loadMultData(dattoget)\n",
    "\n",
    "# saving dir\n",
    "SAVEDIR = f\"{FD[0]['fd']['params']['figuredir_notebook']}/analysis_line2_090720/multday_{animal}_{sdate}_to_{edate}\"\n",
    "import os\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(f\"saving at {SAVEDIR}\")\n",
    "\n",
    "# ==== Flatten all trials across days x animals\n",
    "# for each trial collect relevant information\n",
    "from analysis.line2 import PROBEDATfromFD\n",
    "\n",
    "PROBEDAT = PROBEDATfromFD(FD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE DEVElOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WAYS TO QUANTIFY VARIABILITY OF STROKES\n",
    "# 1) covariance structure (plto as clouds on eac point)\n",
    "# 2) same, but only onset and offset, which makes thingse asier\n",
    "# 3) resampling\n",
    "# 4) plot x and y separately?\n",
    "# 5) align onto a 1d-axis, which is along the task (difficult to do... prob ignore)\n",
    "\n",
    "# lthere are tasks that are fixed in one set of days but random in other./`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not just motor habit - order often differs (both of stroke and of direction within stroke).\n",
    "\n",
    "# but becomes more and more like motor habit as more practice:\n",
    "# - correalted timecourses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) clean strokes DONE\n",
    "# 2) mean 1st, second, etc DONE\n",
    "# 3) seaprate by stroke num DONE\n",
    "# 4) plot 1st N trials each day DONE\n",
    "# 5) plot N (matched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot one specific task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning - same task over time/days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all cases where same task is done in different contexts:\n",
    "# 1) Same animal, diff training\n",
    "# 2) Diff animal, diff training\n",
    "# 3) Diff animal, same training (might not be any of this)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During 2-stroke, stop after secind stroke?\n",
    "\n",
    "# Trial end after lift > N seconds? Plot timing distryubitnos./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can decode character?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get more stereotyped with practice \n",
    "# seems clear from psychometric tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK ANALYSES TO DO IN SPREADSHEET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structure of variability\n",
    "\n",
    "1. same task, different primitives\n",
    "2. same task, same primitives, different order.\n",
    "3. relates to psychometric functions - what stimulus features drive this variability?\n",
    "4. reduction in variability over experiences.\n",
    "5. motor-level variability, in timing and kinematics\n",
    "\n",
    "[note: all of these maybe addressed by done-button verson, where seems to be more variability\n",
    "- also, variability of number of strokes]\n",
    "\n",
    "IMPoRTANT: if question is what drives structure of variablity, answer might be depends on prior knowledge. Goal of analyses is to see whether structure of variability influenced by this prior knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## motor analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) motor-level invariance:\n",
    "    same stroke different tasks\n",
    "    same bigram strokes diff tasks\n",
    "    \n",
    "    the above, but same task different parses\n",
    "    Goal:\n",
    "        if so, then can do modeling of primitives?\n",
    "        if so, then useful for neural recordings?\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMAIL TO SELF - good outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    A) First analysis just show that is copying task correctly.\n",
    "    - shuffle across task categories. shuffle within task categories.\n",
    "    - better or worse given different models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    B) Second, look at compositional structure\n",
    "    Different analyses to look at structure difference for\n",
    "    compositionality v1 (strokes):\n",
    "\n",
    "    1) Stroke statistics:\n",
    "    - length, straightness, etc.\n",
    "    - bag of strokes, across all tasks, showing that depend on training. compare to models (ground truth (two models) and spline fit).\n",
    "\n",
    "    - [spline fit model] - THINK ABOUT THIS - not obvious if would work, since here is compositionality v1.\n",
    "\n",
    "    - task by task, ask whether beahvior matches model. shuffle tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STROKE STATISTICS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Extract one datapoint for each stroke (flat across trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Load data across days\n",
    "# from pythonlib.tools.datetools import getDateList\n",
    "# from analysis.line2 import PROBEDATfromFD\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# from analysis.line2 import probedat2strokefeats\n",
    "\n",
    "# sdate = 200902\n",
    "# edate = 200907\n",
    "# datelist = getDateList(sdate, edate)\n",
    "\n",
    "# expt = \"lines2\"\n",
    "\n",
    "# # === METADAT ABOUT EXPERIMENT\n",
    "# task_train_test = {\n",
    "# 'probe1_liketrain':\"train\",\n",
    "# 'probe1_nostrokeconstraint':\"train\",\n",
    "# 'probe3':\"test\",\n",
    "# 'probe3_hdpos':\"test\",\n",
    "# 'train':\"train\"}\n",
    "        \n",
    "# matchedstrokes = [0,1] # these strokes are aggregated on each day. expect these to be comaprable across days.\n",
    "\n",
    "# # ==== STROKES MOTOR MODEL PARAMS\n",
    "# strokmodel_kind='spatial'\n",
    "# strokmodel_tstamp = '200922_093340_lines2'\n",
    "\n",
    "# # for animal in [\"Pancho\", \"Red\"]:\n",
    "# for animal in [\"Pancho\"]:\n",
    "    \n",
    "#     dattoget = []\n",
    "#     for d in datelist:\n",
    "#         dattoget.append([expt, animal, d])\n",
    "        \n",
    "#     FD = loadMultData(dattoget)\n",
    "\n",
    "#     # saving dir\n",
    "#     SAVEDIR = f\"{FD[0]['fd']['params']['figuredir_notebook']}/analysis_line2_090720/multday_{animal}_{sdate}_to_{edate}\"\n",
    "#     import os\n",
    "#     os.makedirs(SAVEDIR, exist_ok=True)\n",
    "#     print(f\"saving at {SAVEDIR}\")\n",
    "\n",
    "#     # ==== Flatten all trials across days x animals\n",
    "#     # for each trial collect relevant information\n",
    "#     PROBEDAT = PROBEDATfromFD(FD)\n",
    "    \n",
    "    \n",
    "\n",
    "#     # ==== EXTRACT STROKE MODEL RESULTS\n",
    "#     modResGetter = modelResultsGetter(PROBEDAT, model=strokmodel_kind, \n",
    "#                                       fit_tstamp = strokmodel_tstamp)\n",
    "\n",
    "#     for traintest in [\"train\", \"test\", \"bothtraintest\"]:\n",
    "# #     for traintest in [\"test\"]:\n",
    "#         for only_first_last_trials in [False, True]:\n",
    "#     #         = True # then gets last trial of epoch 1 and first trial of epoch 2\n",
    "\n",
    "#             if only_first_last_trials:\n",
    "#                 # then should get all trials to make sure not miss any\n",
    "#                 from pythonlib.tools.datetools import getDateList\n",
    "#                 DATELIST = getDateList(\"200902\", \"200907\")\n",
    "\n",
    "#                 datecategories = {\n",
    "#                     \"200902\":1, \n",
    "#                     \"200903\":1,\n",
    "#                     \"200904\":2,\n",
    "#                     \"200905\":2,\n",
    "#                     \"200906\":2,\n",
    "#                     \"200907\":2}\n",
    "#             else:\n",
    "#                 DATELIST = [\"200902\", \"200903\", \"200906\", \"200907\"]\n",
    "#                 datecategories = {\n",
    "#                     \"200902\":1, \n",
    "#                     \"200903\":1,\n",
    "#                     \"200906\":2,\n",
    "#                     \"200907\":2}\n",
    "\n",
    "#             only_shared_tasks = False # not needed, since will filter below to make sure in both epochs.\n",
    "#             strokfeats, TASKLIST = probedat2strokefeats(PROBEDAT, DATELIST, only_shared_tasks=only_shared_tasks)\n",
    "\n",
    "#             # ==== add model results to strokfeats\n",
    "#             if False:\n",
    "#                 ## assign model results to each individual stroke\n",
    "#                 # [SCRATCH HERE]\n",
    "#                 for s in strokfeats:\n",
    "\n",
    "#                     s[\"mod_res\"] = modResGetter(animal, date=s[\"date\"], expt=expt, session=s[\"session\"], trial=s[\"trial\"], \n",
    "#                                                 strok_num=s[\"strokenum\"])\n",
    "\n",
    "\n",
    "#                 SF = pd.DataFrame(strokfeats)\n",
    "#                 SF = pd.DataFrame([s for s in strokfeats if s[\"mod_res\"] is None])\n",
    "#                 sns.catplot(x=\"date\", y=\"distance\", data=SF, height=20)\n",
    "\n",
    "#                 SF = pd.DataFrame([s for s in strokfeats if s[\"mod_res\"] is not None])\n",
    "#                 sns.catplot(x=\"date\", y=\"distance\", data=SF, height=20)\n",
    "\n",
    "            \n",
    "#             #### move all below into plotting function\n",
    "#             # === ADD MODEL RESULTS\n",
    "#             k = \"Lstrokeindex\"\n",
    "#             if k==\"Lstrokeindex\":\n",
    "#                 kactual = \"0/(0+1)\"\n",
    "#             for s in strokfeats:\n",
    "#                 mod_res = modResGetter(animal, date=s[\"date\"], expt=expt, session=s[\"session\"], trial=s[\"trial\"], \n",
    "#                                             strok_num=s[\"strokenum\"])\n",
    "#                 if mod_res is not None:\n",
    "#                     s[k] = mod_res[kactual].values[0]\n",
    "#                 else:\n",
    "#                     s[k] = np.nan\n",
    "\n",
    "\n",
    "#             ## CONVERT TO DATAFRAME FOR PLOTTING\n",
    "#             SF = pd.DataFrame(strokfeats)\n",
    "\n",
    "#             ## APPEND columns refelcting experimental structure\n",
    "#             from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "\n",
    "#             # --- aggregate over strokes of a desired index\n",
    "#             F = lambda x:x[\"strokenum\"] in matchedstrokes\n",
    "#             SF = applyFunctionToAllRows(SF, F, newcolname=\"keepstroke\")\n",
    "\n",
    "#             # --- aggregate over strokes of a desired index\n",
    "#             F = lambda x:datecategories[x[\"date\"]]\n",
    "#             SF = applyFunctionToAllRows(SF, F, newcolname=\"epoch\")\n",
    "\n",
    "#             # --- call each task either test or train\n",
    "#             F = lambda x:task_train_test[x[\"task_kind\"]]\n",
    "#             SF = applyFunctionToAllRows(SF, F, newcolname=\"traintest\")\n",
    "\n",
    "\n",
    "#             if traintest in [\"train\", \"test\"]:\n",
    "#                 SF = SF[SF[\"traintest\"]==traintest]\n",
    "#             elif traintest==\"bothtraintest\":\n",
    "#                 SF = SF\n",
    "\n",
    "#             # - only keep tasks that have at least one datapoint in epoch1 and 2\n",
    "#             epochs_to_check = list(set([d for d in datecategories.values()]))\n",
    "#             def F(x, epochs_to_check = epochs_to_check):\n",
    "#                 \"\"\" True if has data for all epochs\"\"\"\n",
    "#                 checks  = []\n",
    "#                 for ep in epochs_to_check:\n",
    "#                     checks.append(ep in x[\"epoch\"].values)\n",
    "#                 return all(checks)\n",
    "#             SF = SF.groupby([\"task\"]).filter(F)\n",
    "\n",
    "#             # == only keep if includes model results\n",
    "#             SF = SF[~np.isnan(SF[k])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             #  ==== ONLY INCLUDE LAST (OF FIRST EPOCH) AND FIRST (OF LAST EPOCH) TRIALS\n",
    "#             if only_first_last_trials:\n",
    "#                 # -- get last trial for first epoch\n",
    "#                 tmp = SF[SF[\"epoch\"]==1]\n",
    "#                 tmp = tmp[tmp.groupby([\"task\", \"epoch\"])[\"datetime\"].transform(max) == tmp[\"datetime\"]]\n",
    "\n",
    "\n",
    "#                 # -- get first trial of last epoch\n",
    "#                 tmp2 = SF[SF[\"epoch\"]==2]\n",
    "#                 tmp2= tmp2[tmp2.groupby([\"task\", \"epoch\"])[\"datetime\"].transform(min) == tmp2[\"datetime\"]]\n",
    "\n",
    "\n",
    "#                 # -- combine in a new dataframe\n",
    "#                 SF = pd.concat([tmp, tmp2])\n",
    "\n",
    "#             # === MAKE SAVE DIRECTORY\n",
    "#             if only_first_last_trials:\n",
    "#                 SAVEDIRTHIS = f\"{SAVEDIR}/strokefeatures_firstlasttrials_{traintest}\"\n",
    "#                 import os \n",
    "#                 os.makedirs(SAVEDIRTHIS, exist_ok=True)\n",
    "#             else:\n",
    "#                 SAVEDIRTHIS = f\"{SAVEDIR}/strokefeatures_alltrials_{traintest}\"\n",
    "#                 import os \n",
    "#                 os.makedirs(SAVEDIRTHIS, exist_ok=True)    \n",
    "\n",
    "\n",
    "#             # --- plot date for each task\n",
    "#             #             from pythonlib.tools.snstools import rotateLabel\n",
    "#             fig = plt.figure(figsize=(15,10))\n",
    "#             ax = sns.scatterplot(data=SF, x=\"date\", y=\"task\", hue=\"epoch\")\n",
    "#             if only_first_last_trials:\n",
    "#                 plt.title(\"last trial (first epoch) and first trial (last epoch)\")                  \n",
    "#             else:\n",
    "#                 plt.title(\"all trials\")\n",
    "#             # ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "#             fig.savefig(f\"{SAVEDIRTHIS}/overview_timeline.pdf\")\n",
    "\n",
    "#             # reget new tasklist\n",
    "#             TASKLIST = sorted(set(SF[\"task\"].values))\n",
    "\n",
    "#             # =========== PLOT - one plot per task\n",
    "#             for task in TASKLIST:\n",
    "#                 SFthis = SF.loc[SF[\"task\"]==task]\n",
    "#             #     SF = pd.DataFrame([s for s in strokfeats if s[\"task\"]==task])\n",
    "\n",
    "#                 # -- PLOT\n",
    "#                 fig = sns.pairplot(SFthis, vars = [\"strokenum\", \"circularity\", \"distance\", k, \"epoch\"], hue=\"date\")\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-1.pdf\")\n",
    "#                 fig = sns.pairplot(SFthis, vars = [\"strokenum\", \"circularity\", k, \"distance\"], hue=\"epoch\")\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-2.pdf\")\n",
    "#                 fig = sns.catplot(data=SFthis, x=\"epoch\", y=\"distance\", col=\"strokenum\", hue=\"date\", jitter=True, aspect=0.5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-3.pdf\")\n",
    "#                 fig = sns.catplot(data=SFthis, x=\"epoch\", y=\"circularity\", col=\"strokenum\", hue=\"date\", jitter=True, aspect=0.5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-4.pdf\")\n",
    "#                 fig = sns.catplot(data=SFthis, x=\"epoch\", y=k, col=\"strokenum\", hue=\"date\", jitter=True, aspect=0.5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-5.pdf\")\n",
    "\n",
    "#                 # -- PLOT, aggregating over first N strokes.\n",
    "#                 SF2 = SFthis.loc[SFthis[\"keepstroke\"]==True]\n",
    "#                 fig = sns.pairplot(SF2, vars = [\"circularity\", \"distance\", k, \"epoch\"], hue=\"date\")\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-aggregNstrokes-1.pdf\")\n",
    "#                 fig = sns.pairplot(SF2, vars = [\"circularity\", \"distance\",  k], hue=\"epoch\")\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-aggregNstrokes-2.pdf\")\n",
    "#                 fig = sns.catplot(data=SF2, x=\"epoch\", y=\"distance\", hue=\"date\", jitter=True, aspect=0.5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-aggregNstrokes-3.pdf\")\n",
    "#                 fig = sns.catplot(data=SF2, x=\"epoch\", y=\"circularity\", hue=\"date\", jitter=True, aspect=0.5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-aggregNstrokes-4.pdf\")\n",
    "#                 fig = sns.catplot(data=SF2, x=\"epoch\", y=k, hue=\"date\", jitter=True, aspect=0.5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/pairplot_{task}-aggregNstrokes-5.pdf\")\n",
    "\n",
    "#                 plt.close(\"all\")\n",
    "\n",
    "\n",
    "#             ## ==== Summary across tasks\n",
    "#             # aggregate: for each task, get one value for epoch 1, one value for epoch 2\n",
    "#             # (aggreagte over stroke and days)\n",
    "\n",
    "#             # -- 1) Do aggregation\n",
    "#             from pythonlib.tools.pandastools import aggregGeneral\n",
    "#             group = [\"task\", \"epoch\"]\n",
    "#             values = [\"circularity\", \"distance\", k]\n",
    "#             SFagg = SF.loc[SF[\"keepstroke\"]==True]\n",
    "#             SFagg = aggregGeneral(SFagg, group, values, aggmethod=[\"mean\", \"median\"])\n",
    "\n",
    "#             # -- 2) Plot\n",
    "#             for y in [\"distance_median\", \"circularity_median\", f\"{k}_median\"]:\n",
    "#                 from pythonlib.tools.snstools import rotateLabel\n",
    "\n",
    "#                 fig = sns.catplot(x =\"task\", y=y, data=SFagg, hue=\"epoch\", aspect=3)\n",
    "#                 rotateLabel(fig)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/summary_aggregStrokesDates-{y}-1.pdf\")\n",
    "\n",
    "#             #     sns.catplot(data=SFagg, x=\"epoch\", y=y)\n",
    "#             #     sns.catplot(data=SFagg, x=\"epoch\", y=y, kind=\"point\")\n",
    "#                 fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "#                 plt.subplot(121)\n",
    "#                 for task in set(SFagg[\"task\"]):\n",
    "#                     sns.lineplot(data=SFagg.loc[SFagg[\"task\"]==task], x=\"epoch\", y=y, color=\"k\", alpha=0.5)\n",
    "#                 sns.lineplot(data=SFagg, x=\"epoch\", y=y)\n",
    "\n",
    "#                 plt.subplot(122)\n",
    "#                 Y = SFagg.pivot(index=\"task\", columns=\"epoch\", values=y)\n",
    "#                 Y = pd.DataFrame(Y.to_records())\n",
    "#             #         fig = plt.figure(figsize=(5,5))\n",
    "#                 sns.scatterplot(data =Y, x=\"1\", y=\"2\")\n",
    "#                 plt.xlabel(\"epoch\")\n",
    "#                 plt.ylabel(\"epoch\")\n",
    "\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/summary_aggregStrokesDates-{y}-2.pdf\")\n",
    "\n",
    "#                 # --\n",
    "#                 fig = sns.pairplot(SFagg, vars = [\"circularity_median\", \"distance_median\", f\"{k}_median\"], hue=\"epoch\", height=5)\n",
    "#                 fig.savefig(f\"{SAVEDIRTHIS}/summary_aggregStrokesDates-{y}-3.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot metadat across days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for animal in [\"Pancho\", \"Red\"]:\n",
    "    \n",
    "#     dattoget = []\n",
    "#     for d in datelist:\n",
    "#         dattoget.append([expt, animal, d])\n",
    "        \n",
    "#     FD = loadMultData(dattoget)\n",
    "\n",
    "#     # saving dir\n",
    "#     SAVEDIR = f\"{FD[0]['fd']['params']['figuredir_notebook']}/analysis_line2_090720/multday_{animal}_{sdate}_to_{edate}\"\n",
    "#     import os\n",
    "#     os.makedirs(SAVEDIR, exist_ok=True)\n",
    "#     print(f\"saving at {SAVEDIR}\")\n",
    "\n",
    "#     # ==== Flatten all trials across days x animals\n",
    "#     # for each trial collect relevant information\n",
    "#     PROBEDAT = PROBEDATfromFD(FD)\n",
    "\n",
    "#     # then should get all trials to make sure not miss any\n",
    "#     from pythonlib.tools.datetools import getDateList\n",
    "#     DATELIST = getDateList(\"200902\", \"200907\")\n",
    "\n",
    "#     datecategories = {\n",
    "#         \"200902\":1, \n",
    "#         \"200903\":1,\n",
    "#         \"200904\":2,\n",
    "#         \"200905\":2,\n",
    "#         \"200906\":2,\n",
    "#         \"200907\":2}\n",
    "\n",
    "#     only_shared_tasks = False # not needed, since will filter below to make sure in both epochs.\n",
    "\n",
    "#     task_train_test = {\n",
    "#     'probe1_liketrain':\"train\",\n",
    "#     'probe1_nostrokeconstraint':\"train\",\n",
    "#     'probe3':\"test\",\n",
    "#     'probe3_hdpos':\"test\",\n",
    "#     'train':\"train\"}\n",
    "\n",
    "#     matchedstrokes = [0,1] # these strokes are aggregated on each day. expect these to be comaprable across days.\n",
    "\n",
    "#     only_shared_tasks = False # not needed, since will filter below to make sure in both epochs.\n",
    "#     strokfeats, TASKLIST = probedat2strokefeats(PROBEDAT, DATELIST, only_shared_tasks=only_shared_tasks)\n",
    "\n",
    "#     ## CONVERT TO DATAFRAME FOR PLOTTING\n",
    "#     SF = pd.DataFrame(strokfeats)\n",
    "\n",
    "#     ## APPEND columns refelcting experimental structure\n",
    "#     from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "\n",
    "#     # --- aggregate over strokes of a desired index\n",
    "#     F = lambda x:x[\"strokenum\"] in matchedstrokes\n",
    "#     SF = applyFunctionToAllRows(SF, F, newcolname=\"keepstroke\")\n",
    "\n",
    "#     # --- aggregate over strokes of a desired index\n",
    "#     F = lambda x:datecategories[x[\"date\"]]\n",
    "#     SF = applyFunctionToAllRows(SF, F, newcolname=\"epoch\")\n",
    "\n",
    "#     # --- call each task either test or train\n",
    "#     F = lambda x:task_train_test[x[\"task_kind\"]]\n",
    "#     SF = applyFunctionToAllRows(SF, F, newcolname=\"traintest\")\n",
    "\n",
    "\n",
    "\n",
    "#     fig1 = sns.catplot(x=\"date\", y=\"task_category\", hue=\"random_task\", data=SF, aspect=3, row_order=sorted(set(SF[\"task_category\"])))\n",
    "#     fig2 = sns.catplot(x=\"date\", y=\"task_category\", hue=\"random_task\", row=\"traintest\", data=SF, aspect=3)\n",
    "\n",
    "#     # for fixed tasks only\n",
    "#     # sns.catplot(x=\"date\", y=\"task\", hue=\"task_category\", row=\"traintest\", data=SF[SF[\"random_task\"]==False], \n",
    "#     #             height=10, aspect=1, row_order=sorted(set(SF[\"task\"])))\n",
    "#     fig3 = sns.catplot(x=\"date\", y=\"task\", hue=\"task_category\", row=\"traintest\", data=SF[SF[\"random_task\"]==False], \n",
    "#                 height=10, aspect=1)\n",
    "    \n",
    "#     fig1.savefig(f\"{SAVEDIR}/overview-1.pdf\")\n",
    "#     fig2.savefig(f\"{SAVEDIR}/overview-2.pdf\")\n",
    "#     fig3.savefig(f\"{SAVEDIR}/overview-3.pdf\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # == 1) For each day, plot tasks sorted by category.\n",
    "\n",
    "# for date in DATELIST:\n",
    "#     print(f\"======= {date}\")\n",
    "#     traintaskcats = sorted(set([P[\"task_stagecategory\"] for P in PROBEDAT if P[\"date\"]==date]))\n",
    "#     for cat in traintaskcats:\n",
    "#         print(f\"--- {cat}\")\n",
    "#         for RANDOM in [True, False]:\n",
    "#             tasknames = sorted(set([P[\"unique_task_name\"] for P in PROBEDAT\n",
    "#                               if P[\"date\"]==date\n",
    "#                               and P[\"random_task\"]==RANDOM\n",
    "#                                    and P[\"task_stagecategory\"]==cat]))\n",
    "#             if len(tasknames)==0:\n",
    "#                 continue\n",
    "#             if RANDOM:\n",
    "#                 print(\"-RANDOM\")\n",
    "#             else:\n",
    "#                 print(\"-FIXED\")\n",
    "#             if len(tasknames)>15:\n",
    "#                 print(f\"found {len(tasknames)} tasks, eg {tasknames[0]}\")\n",
    "#             else:\n",
    "#                 print(tasknames)\n",
    "# #         assert False\n",
    "                          \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Plot all tasks (no behavior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN PROGRESS - not sure if this is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************** PLOT ALL FIXED TASKS (collect across days)\n",
    "for TRAINTEST in [\"train\", \"test\"]:\n",
    "\n",
    "    # then plot all\n",
    "    tasknames = sorted(set([P[\"unique_task_name\"] for P in PROBEDAT\n",
    "                      if P[\"random_task\"]==False\n",
    "                            and task_train_test[P[\"kind\"]]==TRAINTEST]))\n",
    "\n",
    "    # get one index per taskname\n",
    "    fdlist = []\n",
    "    triallist =[]\n",
    "    titlelist = []\n",
    "    for task in tasknames:\n",
    "        fdlist.append([P[\"filedata\"] for P in PROBEDAT\n",
    "                        if P[\"unique_task_name\"]==task][0])\n",
    "        triallist.append([P[\"trial\"] for P in PROBEDAT\n",
    "                        if P[\"unique_task_name\"]==task][0])\n",
    "        titlelist.append(task)\n",
    "    print(titlelist)\n",
    "\n",
    "    fig = plotMultTrialsSimple(fdlist, trials_list=triallist, rand_subset=None, \n",
    "                               empty_title=False, zoom=True, plot_fix=True, alpha=1, titles=titlelist,\n",
    "                        plotargs={\"plot_task_stimulus\":True, \n",
    "                                \"plot_drawing_behavior\":False, \"nakedplot\":True,\n",
    "                               })\n",
    "    fig.savefig(f\"{SAVEDIR}/alltasks_fixed_alldays_{TRAINTEST}.pdf\")\n",
    "\n",
    "    \n",
    "    \n",
    "# *** FOR EACH DAY, PLOT SUBSET OF RANDOM TASKS.\n",
    "TRAINTEST = \"train\"\n",
    "for date in DATELIST:\n",
    "    print(f\"======= {date}\")\n",
    "    traintaskcats = sorted(set([P[\"task_stagecategory\"] for P in PROBEDAT \n",
    "                                if P[\"date\"]==date\n",
    "                               and P[\"random_task\"]==True\n",
    "                               and task_train_test[P[\"kind\"]]==TRAINTEST]))\n",
    "    for cat in traintaskcats:\n",
    "        print(f\"--- {cat}\")\n",
    "        \n",
    "        # then just plot example tasks\n",
    "        fdlist = [P[\"filedata\"] for P in PROBEDAT\n",
    "                          if P[\"date\"]==date\n",
    "                          and P[\"random_task\"]==True\n",
    "                        and P[\"task_stagecategory\"]==cat\n",
    "                 and task_train_test[P[\"kind\"]]==TRAINTEST]\n",
    "        triallist = [P[\"trial\"] for P in PROBEDAT\n",
    "                          if P[\"date\"]==date\n",
    "                          and P[\"random_task\"]==True\n",
    "                        and P[\"task_stagecategory\"]==cat\n",
    "                 and task_train_test[P[\"kind\"]]==TRAINTEST]\n",
    "        titlelist = [P[\"unique_task_name\"] for P in PROBEDAT\n",
    "                          if P[\"date\"]==date\n",
    "                          and P[\"random_task\"]==True\n",
    "                        and P[\"task_stagecategory\"]==cat\n",
    "                 and task_train_test[P[\"kind\"]]==TRAINTEST]\n",
    "\n",
    "        Nrand = 60\n",
    "        fig = plotMultTrialsSimple(fdlist, trials_list=triallist, rand_subset=Nrand, \n",
    "                                   empty_title=False, zoom=True, plot_fix=True, alpha=1, titles=titlelist,\n",
    "                            plotargs={\"plot_task_stimulus\":True, \n",
    "                                    \"plot_drawing_behavior\":False, \"nakedplot\":True,\n",
    "                                   })\n",
    "        fig.savefig(f\"{SAVEDIR}/alltasks-random-{date}-{cat}-{TRAINTEST}.pdf\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FOR EACH TASK, PLOT THE DISTRIBUTIONS OF FEATURES, COMPARING TWO DAYS\n",
    "\n",
    "# DATE1 = \"200903\"\n",
    "# DATE2 = \"200907\"\n",
    "# TASKlIST = \"F_1-protype\"\n",
    "\n",
    "# # --- get flattened list of all stroks\n",
    "# DAT = []\n",
    "# for P in PROBEDAT:\n",
    "#     if P[\"date\"] in [DATE1, DATE2] and P[\"unique_task_name\"]==TASK:\n",
    "#         DAT.append(\n",
    "#             {\n",
    "#                 \"date\":str(P[\"date\"]),\n",
    "#                 \"strokes\":getTrialsStrokesByPeanuts(P[\"filedata\"], P[\"trial\"])\n",
    "#             })\n",
    "\n",
    "# ##############################\n",
    "# strokesfeatures = strokeFeatures([D[\"strokes\"] for D in DAT])\n",
    "# for sf, D in zip(strokesfeatures, DAT):\n",
    "#     D[\"features\"] = sf\n",
    "    \n",
    "# strokfeats = flattenByStrok(DAT)\n",
    "# strokfeats[0]\n",
    "\n",
    "\n",
    "# # --- Plot distributions\n",
    "# SF = pd.DataFrame(strokfeats)\n",
    "# sns.pairplot(SF, vars = [\"strokenum\", \"circularity\", \"distance\"], hue=\"date\", kind=\"reg\")\n",
    "# sns.pairplot(SF, vars = [\"strokenum\", \"circularity\", \"distance\"], hue=\"date\")\n",
    "\n",
    "# sns.catplot(data=SF, x=\"date\", y=\"distance\", hue=\"strokenum\", jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strokefeats2title(strokfeats):\n",
    "    \"\"\"strokfeats is a list of dicts.\n",
    "    title is string, each row is a list element\"\"\"\n",
    "    sfeat = strokfeats[0]\n",
    "    s = \"\"\n",
    "    for i, sfeat in enumerate(strokfeats):\n",
    "        s=f\"{s}\\n[{i+1}]\"\n",
    "        for k, v in sfeat.items():\n",
    "            if k!=\"strokenum\":\n",
    "                s=f\"{s}-{k[:3]}\"\n",
    "                s=f\"{s}({v:.2f})\"\n",
    "        #     s+=v\n",
    "    return s\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PLOT TRAILS STROKES ALONG WITH THEIR FEATURES\n",
    "\n",
    "idxlist = [random.randrange(1, len(PROBEDAT)) for _ in range(20)]\n",
    "\n",
    "# 1) collect features\n",
    "# strokeslist = [getTrialsStrokesByPeanuts(PROBEDAT[i][\"filedata\"], PROBEDAT[i][\"trial\"]) for i in idxlist]\n",
    "# strokfeats = strokeFeatures(strokeslist)\n",
    "\n",
    "# 2) plot\n",
    "titles = []\n",
    "filedatas = []\n",
    "trialslist = []\n",
    "for i in idxlist:\n",
    "    strokeslist = [getTrialsStrokesByPeanuts(PROBEDAT[i][\"filedata\"],PROBEDAT[i][\"trial\"])]\n",
    "    strokfeats = strokeFeatures(strokeslist)[0]\n",
    "    \n",
    "    titles.append(strokefeats2title(strokfeats))\n",
    "    filedatas.append(PROBEDAT[i][\"filedata\"])\n",
    "    trialslist.append(PROBEDAT[i][\"trial\"])\n",
    "    \n",
    "plotMultTrialsSimple(filedatas, trialslist, titles=titles, zoom=True, strokes_ver=\"peanuts\");\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokeFeatures(strokeslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute distribution of angle bends per stroke\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    2a) Cluster strokes:\n",
    "    a) using statistics above\n",
    "    b) pairwise distance matrix;\n",
    "    show that there are lines and Ls as two distinct clusters.\n",
    "\n",
    "\n",
    "    2) Categories strokes\n",
    "    - for each stroke, categorize based on the clustering model above.\n",
    "    [ Or do it in a supervised way?]\n",
    "    -- goal: 2d plot (line weight vs. L-weight, probabilistic).\n",
    "\n",
    "    3) Model-based analysis - assigning entire parse a score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW - OLD SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD ALL SESSIONS FOR A DAY\n",
    "# A = [(\"lines1\", \"Red\", 200831),\n",
    "#  (\"lines1\", \"Pancho\", 200831),\n",
    "#  (\"ESC1\", \"Red\", 200830),\n",
    "#  (\"ESC1\", \"Pancho\", 200830)]\n",
    "A = [(\"lines2\", \"Red\", 200907),\n",
    " (\"lines2\", \"Pancho\", 200907)]\n",
    "\n",
    "for (expt, animal, date) in A:\n",
    "\n",
    "    # expt = \"lines1\"\n",
    "    # animal = \"Red\"\n",
    "    # date = 200831\n",
    "\n",
    "    # expt = \"ESC1\"\n",
    "    # animal = \"Red\"\n",
    "    # date = 200830\n",
    "\n",
    "    # simple, just try many sessions...\n",
    "    fdsessions = []\n",
    "    FD = {}\n",
    "    N = 12\n",
    "    for session in range(10):\n",
    "        fd = loadSingleData(animal, date, expt, session, resave_as_dict=False, load_resaved_data=True, \n",
    "                          resave_overwrite=False)\n",
    "        if fd is not None:\n",
    "            print(f\"appending fd for sess {session}\")\n",
    "            fdsessions.append({\n",
    "                \"session\": session,\n",
    "                \"fd\":fd})\n",
    "            FD[session] = fd\n",
    "            if session==N-1:\n",
    "                assert False, \"got the end and still found.. you need to search for even more sessions...\"\n",
    "\n",
    "            SAVEDIR = f\"{fd['params']['figuredir_notebook']}/probes/{animal}_{date}\"\n",
    "            import os\n",
    "            os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "\n",
    "    print(\"--- SUMMARY\")\n",
    "    for f in fdsessions:\n",
    "        print(f\"session: {f['session']}, ntrials: {f['fd']['params']['n_trials']}\")\n",
    "\n",
    "\n",
    "    # === categorize all trials based on task/probe, etc\n",
    "    probedat = []\n",
    "    ct = 0\n",
    "    for sess, fd in FD.items():\n",
    "        for t in getIndsTrials(fd):\n",
    "            if getTrialsFixationSuccess(fd, t):\n",
    "                probe = getTrialsTaskProbeInfo(fd, t)\n",
    "                task = getTrialsTask(fd, t)\n",
    "                \n",
    "#                 print(probe)\n",
    "                \n",
    "                if probe[\"prototype\"]==0 and len(probe[\"saved_setnum\"])==0 and probe[\"resynthesized\"]==0:\n",
    "                    # then this is new random task sampled each block.\n",
    "                    randomtask = True\n",
    "                else:\n",
    "                    randomtask = False\n",
    "\n",
    "                if probe[\"probe\"]==0:\n",
    "                    kind = \"train\"\n",
    "                else:\n",
    "                    if probe[\"feedback_ver\"]==\"same_as_task\" and randomtask==False:\n",
    "                        if probe[\"constraints_to_skip\"]=={}:\n",
    "                            kind = \"probe1_liketrain\"\n",
    "                        elif \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                            kind = \"probe1_nostrokeconstraint\"\n",
    "                    elif probe[\"feedback_ver\"]==\"same_as_task\" and randomtask==True and probe[\"constraints_to_skip\"]=={}:\n",
    "                        kind = \"probe2_liketrain\"\n",
    "                    elif probe[\"feedback_ver\"]==\"same_as_task\" and randomtask==True and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                        kind = \"probe2_nostrokeconstraint\"\n",
    "                    elif probe[\"feedback_ver\"] in [\"thresh_active\", \"mid_reward\"] and randomtask==False and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                        kind = \"probe3\"\n",
    "                    elif probe[\"feedback_ver\"] in [\"same_except_model\"] and randomtask==False and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                        kind = \"probe3_hdpos\"\n",
    "                    elif probe[\"feedback_ver\"] in [\"thresh_active\", \"mid_reward\"] and randomtask==True and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                        kind = \"probe4\"\n",
    "                    else:\n",
    "                        print(probe)\n",
    "                        assert False, \"what kind is this?\"\n",
    "\n",
    "                probedat.append({\n",
    "                    \"session\":sess,\n",
    "                    \"trial\":t,\n",
    "                    \"trial_day\":ct,\n",
    "                    \"kind\":kind,\n",
    "                    \"taskname\": probe[\"unique_name\"],\n",
    "                    \"stage\":task[\"stage\"],\n",
    "                    \"block\":getTrialsBlock(FD[sess], t),\n",
    "                    \"prototype\":probe[\"prototype\"],\n",
    "                    \"constraints_to_skip\":probe[\"constraints_to_skip\"]})\n",
    "                ct+=1\n",
    "\n",
    "\n",
    "    # == for each category, list names of all tasks\n",
    "    kindlist = set([p[\"kind\"] for p in probedat])\n",
    "    print(\"probe kinds -- trials\");\n",
    "    for kind in kindlist:\n",
    "        print(\" \")\n",
    "        print(kind)\n",
    "        trials = [p[\"trial\"] for p in probedat if p[\"kind\"]==kind]\n",
    "        tasknames = [p[\"taskname\"] for p in probedat if p[\"kind\"]==kind]\n",
    "    #     print(trials)\n",
    "        print(set(tasknames))\n",
    "        plt.figure()\n",
    "        plt.plot(trials, tasknames)\n",
    "\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    dframe = pd.DataFrame(probedat)\n",
    "\n",
    "    # sns.scatterplot(x=\"trial\", y=\"taskname\", data=dframe, hue=\"kind\")\n",
    "    fig, axes = plt.subplots(5, 1, sharex=True, squeeze=False, figsize=(28, 10))\n",
    "\n",
    "    sns.scatterplot(x=\"trial_day\", y=\"kind\", data=dframe, hue=\"kind\", ax=axes[0][0])\n",
    "    sns.scatterplot(x=\"trial_day\", y=\"stage\", data=dframe, hue=\"kind\", ax=axes[1][0])\n",
    "    sns.scatterplot(x=\"trial_day\", y=\"stage\", data=dframe, hue=\"prototype\", ax=axes[2][0])\n",
    "    sns.lineplot(x=\"trial_day\", y=\"session\", data=dframe, ax=axes[3][0])\n",
    "    sns.lineplot(x=\"trial_day\", y=\"block\", data=dframe, ax=axes[4][0])\n",
    "\n",
    "    fig.savefig(f\"{SAVEDIR}/overviewAllTrials.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "    stagelist = set([p[\"stage\"] for p in probedat])\n",
    "    sesslist = set([p[\"session\"] for p in probedat])    \n",
    "    kindlist = set([p[\"kind\"] for p in probedat])\n",
    "\n",
    "    ## PLOT PROBE TASKS OVER THE ENTIRE DAY\n",
    "    maxtrialsplot = 80\n",
    "\n",
    "    for kind in kindlist:\n",
    "        for stage in stagelist:\n",
    "            for s in sesslist:\n",
    "                trialsthis = [p[\"trial\"] for p in probedat if p[\"session\"]==s and p[\"kind\"]==kind and p[\"stage\"]==stage]\n",
    "                fd = FD[s]\n",
    "                print(f\"-- for session {s}, kind {kind}, stage {stage}; trials:\")\n",
    "                print(trialsthis)\n",
    "\n",
    "                if len(trialsthis)>0:\n",
    "                    if len(trialsthis)>maxtrialsplot:\n",
    "                        trialsthis = sorted(random.sample(trialsthis, maxtrialsplot))                        \n",
    "                        r = None\n",
    "                    else:\n",
    "                        r = None\n",
    "                    titles = []\n",
    "                    for t in trialsthis:\n",
    "                        mscore = getTrialsBehEvaluation(fd, t)[\"output\"][\"modelscore\"][\"value\"][0][0]\n",
    "                        bscore = getTrialsBehEvaluation(fd, t)[\"beh_multiplier\"][0][0]                                               \n",
    "                        titles.append(f\"{t},bk{getTrialsBlock(fd, t)},{getTrialsTask(fd, t)['str']}\\nmsco{mscore:.2f},bsco{bscore:.2f}\")\n",
    "\n",
    "#                         titles = [f\"{t},bk{getTrialsBlock(fd, t)}{getTrialsTask(fd, t)['str']}\\nmscore{mscore}\" for t in trialsthis]\n",
    "                    # plot\n",
    "                    \n",
    "                    # construct titles\n",
    "                    \n",
    "                    fig1 = plotMultTrialsSimple(fd, trialsthis, zoom=True, strokes_ver=\"peanuts\", plot_fix=True,\n",
    "                                            plotver=\"strokes\", rand_subset = r, titles=titles)\n",
    "\n",
    "                    scores = [getTrialsScoreRecomputed(fd, t, normalize=True) for t in trialsthis]\n",
    "                    scores_compos = [getTrialsScoreRecomputed(fd, t, ver=\"DTW_min\", normalize=True) for t in trialsthis]\n",
    "                    scores_compos2 = [getTrialsScoreRecomputed(fd, t, ver=\"DTW_min_minus_max\", normalize=True) for t in trialsthis]\n",
    "\n",
    "                    # == plot quick scores\n",
    "                    fig2 = plt.figure(figsize=(10, 12))\n",
    "\n",
    "                    plt.subplot(311)\n",
    "                    plt.title(f\"session {s}, kind {kind}, stage {stage}\")\n",
    "                    plt.plot(trialsthis, scores, \"ok\", label=\"pts\")\n",
    "    #                 plt.plot(trialsthis, scores_compos, \"or\", label=\"compositonal\")\n",
    "    #                 plt.plot(trialsthis, scores_compos2, \"og\", label=\"compositonal_min_minus_max\")\n",
    "                    plt.ylabel(\"score (pts) (norm HD, high is good)\")\n",
    "                    plt.ylim([-0.2, 1])\n",
    "                    plt.legend()\n",
    "\n",
    "                    plt.subplot(312)\n",
    "                    plt.title(f\"session {s}, kind {kind}, stage {stage}\")\n",
    "    #                 plt.plot(trialsthis, scores, \"ok\", label=\"pts\")\n",
    "                    plt.plot(trialsthis, scores_compos, \"or\", label=\"compositonal\")\n",
    "    #                 plt.plot(trialsthis, scores_compos2, \"og\", label=\"compositonal_min_minus_max\")\n",
    "                    plt.ylabel(\"score (compositonal) (norm HD, high is good)\")\n",
    "                    plt.ylim([-0.5, 1])\n",
    "                    plt.legend()\n",
    "\n",
    "                    plt.subplot(313)\n",
    "                    plt.title(f\"session {s}, kind {kind}, stage {stage}\")\n",
    "    #                 plt.plot(trialsthis, scores, \"ok\", label=\"pts\")\n",
    "    #                 plt.plot(trialsthis, scores_compos, \"or\", label=\"compositonal\")\n",
    "                    plt.plot(trialsthis, scores_compos2, \"og\", label=\"compositonal_min_minus_max\")\n",
    "                    plt.ylabel(\"score (compositonal_min_minus_max) (norm HD, high is good)\")\n",
    "                    #     plt.ylim([-0.2, 1])\n",
    "                    plt.legend()\n",
    "\n",
    "    #                 plt.subplot(212)\n",
    "    #                 s1 = (scores - np.mean(scores))/np.std(scores)\n",
    "    #                 s2 = (scores_compos - np.mean(scores_compos))/np.std(scores_compos)\n",
    "    #                 s3 = (scores_compos2 - np.mean(scores_compos2))/np.std(scores_compos2)\n",
    "    #                 plt.plot(trialsthis, s1, \"ok\", label=\"pts\")\n",
    "    #                 plt.plot(trialsthis, s2, \"or\", label=\"compositonal\")\n",
    "    #                 plt.plot(trialsthis, s3, \"og\", label=\"compositonal_min_minus_max\")\n",
    "    #                 plt.title(\"z-scored\")\n",
    "    #                 plt.ylabel(\"score (recomputed) (norm HD, high is good)\")\n",
    "    #                 plt.ylim([-3, 3])\n",
    "    #                 plt.legend()\n",
    "\n",
    "                    # save\n",
    "                    fig1.savefig(f\"{SAVEDIR}/trialsByProbeKind_{kind}-{stage}-sess{s}-fig1.pdf\")\n",
    "                    fig2.savefig(f\"{SAVEDIR}/trialsByProbeKind_{kind}-{stage}-sess{s}-fig2.pdf\")\n",
    "    #                 fig2.savefig(f\"{SAVEDIR}/trialsByProbeKind_sess{s}-{kind}-{stage}-fig2.pdf\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTrialsTask(fd, t)[\"savedTaskSet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = \"lines2\"\n",
    "animal = \"Pancho\"\n",
    "date = 200904\n",
    "\n",
    "fdsessions = []\n",
    "FD = {}\n",
    "N = 12\n",
    "for session in range(10):\n",
    "    fd = loadSingleData(animal, date, expt, session, resave_as_dict=False, load_resaved_data=True, \n",
    "                      resave_overwrite=False)\n",
    "    if fd is not None:\n",
    "        print(f\"appending fd for sess {session}\")\n",
    "        fdsessions.append({\n",
    "            \"session\": session,\n",
    "            \"fd\":fd})\n",
    "        FD[session] = fd\n",
    "        if session==N-1:\n",
    "            assert False, \"got the end and still found.. you need to search for even more sessions...\"\n",
    "\n",
    "        SAVEDIR = f\"{fd['params']['figuredir_notebook']}/probes/{animal}_{date}\"\n",
    "        import os\n",
    "        os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"--- SUMMARY\")\n",
    "for f in fdsessions:\n",
    "    print(f\"session: {f['session']}, ntrials: {f['fd']['params']['n_trials']}\")\n",
    "\n",
    "\n",
    "# === categorize all trials based on task/probe, etc\n",
    "probedat = []\n",
    "ct = 0\n",
    "for sess, fd in FD.items():\n",
    "    for t in getIndsTrials(fd):\n",
    "        if getTrialsFixationSuccess(fd, t):\n",
    "            probe = getTrialsTaskProbeInfo(fd, t)\n",
    "            task = getTrialsTask(fd, t)\n",
    "\n",
    "            if probe[\"probe\"]==0:\n",
    "                kind = \"train\"\n",
    "            else:\n",
    "                if probe[\"feedback_ver\"]==\"same_as_task\" and probe[\"prototype\"]==1:\n",
    "                    if probe[\"constraints_to_skip\"]=={}:\n",
    "                        kind = \"probe1_liketrain\"\n",
    "                    elif \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                        kind = \"probe1_nostrokeconstraint\"\n",
    "                elif probe[\"feedback_ver\"]==\"same_as_task\" and probe[\"prototype\"]==0 and probe[\"constraints_to_skip\"]=={}:\n",
    "                    kind = \"probe2_liketrain\"\n",
    "                elif probe[\"feedback_ver\"]==\"same_as_task\" and probe[\"prototype\"]==0 and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                    kind = \"probe2_nostrokeconstraint\"\n",
    "                elif probe[\"feedback_ver\"] in [\"thresh_active\", \"mid_reward\"] and probe[\"prototype\"]==1 and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                    kind = \"probe3\"\n",
    "                elif probe[\"feedback_ver\"] in [\"same_except_model\"] and probe[\"prototype\"]==1 and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                    kind = \"probe3_hdpos\"\n",
    "                elif probe[\"feedback_ver\"] in [\"thresh_active\", \"mid_reward\"] and probe[\"prototype\"]==0 and \"strokes\" in probe[\"constraints_to_skip\"].values():\n",
    "                    kind = \"probe4\"\n",
    "                else:\n",
    "                    print(probe)\n",
    "                    assert False, \"what kind is this?\"\n",
    "\n",
    "            probedat.append({\n",
    "                \"session\":sess,\n",
    "                \"trial\":t,\n",
    "                \"trial_day\":ct,\n",
    "                \"kind\":kind,\n",
    "                \"taskname\": probe[\"unique_name\"],\n",
    "                \"stage\":task[\"stage\"],\n",
    "                \"prototype\":probe[\"prototype\"],\n",
    "                \"constraints_to_skip\":probe[\"constraints_to_skip\"]})\n",
    "            ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## for each trial also get online and offline score\n",
    "for p in probedat:\n",
    "    s = p[\"session\"]\n",
    "    t = p[\"trial\"]\n",
    "    \n",
    "    p[\"bk\"] = getTrialsBlock(FD[s], t)\n",
    "    p[\"bq\"] = getTrialsBloque(FD[s], t)\n",
    "    \n",
    "    # score\n",
    "    if getTrialsFixationSuccess(FD[s], t):\n",
    "        p[\"score_model\"] = getTrialsOutcomesWrapper(FD[s], t)[\"beh_evaluation\"][\"output\"][\"modelscore\"][\"value\"][0][0]\n",
    "        p[\"score_hd\"] = getTrialsOutcomesWrapper(FD[s], t)[\"beh_evaluation\"][\"output\"][\"hausdorff\"][\"value\"][0][0]\n",
    "        p[\"score_offline\"] = getTrialsScoreRecomputed(FD[s], t)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dfthis = pd.DataFrame(probedat)\n",
    "dfthis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### import seaborn as sns\n",
    "\n",
    "y = \"score_model\"\n",
    "sns.relplot(x = \"trial\", y=y, hue=\"bk\", data=dfthis, row=\"kind\", kind=\"scatter\", aspect=3)\n",
    "sns.relplot(x = \"trial_day\", y=y, hue=\"bk\", data=dfthis, row=\"kind\", kind=\"scatter\", aspect=3)\n",
    "sns.relplot(x = \"bq\", y=y, hue=\"bk\", data=dfthis, row=\"kind\", kind=\"scatter\", aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### import seaborn as sns\n",
    "\n",
    "y = \"score_model\"\n",
    "sns.catplot(x = \"bk\", y=y, data=dfthis, row=\"kind\", kind=\"point\", aspect=3)\n",
    "# sns.catplot(x = \"bq\", y=y, data=dfthis, col=\"kind\", row=\"bk\", kind=\"point\", aspect=3)\n",
    "sns.catplot(x = \"bq\", y=y, data=dfthis, row=\"kind\", hue=\"bk\", kind=\"point\", aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## COMPUTE COMPOSITIONAL SCORE\n",
    "# [Quick version] DTW score relative to non-DTW score\n",
    "\n",
    "## ==== [testing] stroke based hd\n",
    "from pythonlib.tools.stroketools import distanceDTW\n",
    "t = random.sample(getIndsTrials(fd),1)[0]\n",
    "\n",
    "strokes_beh = getTrialsStrokesByPeanuts(fd, t, replaynum=1)\n",
    "strokes_task = getTrialsTaskAsStrokes(fd, t)\n",
    "\n",
    "for ass in [True, False]:\n",
    "    print(f\"assymetric: {ass}\")\n",
    "    plotTrialSimple(fd, t, zoom=True, plot_fix=False, plotver=\"strokes\", \n",
    "                    use_peanut_params={'replaynum': 1, 'active': True})\n",
    "\n",
    "    print(distanceDTW(strokes_beh, strokes_task[::-1], ver=\"segments\", asymmetric=ass))\n",
    "    print(distanceDTW(strokes_beh, strokes_task, ver=\"segments\", asymmetric=ass))\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot(211)\n",
    "    plotDatStrokes(strokes_beh, ax=ax)\n",
    "    plotDatStrokes(strokes_task[::-1], ax=ax)\n",
    "\n",
    "    ax = plt.subplot(212)\n",
    "    plotDatStrokes(strokes_beh, ax=ax)\n",
    "    plotDatStrokes(strokes_task, ax=ax)\n",
    "\n",
    "# compute minimum score for all permutations of task strokes\n",
    "# make assymetric false, so forced to use all task strokes.\n",
    "print(\"-- all permutations\")\n",
    "from itertools import permutations\n",
    "scores =[]\n",
    "for s in permutations(strokes_task):\n",
    "    print(distanceDTW(strokes_beh, s, ver=\"segments\", asymmetric=False))\n",
    "    scores.append(distanceDTW(strokes_beh, s, ver=\"segments\", asymmetric=False)[0])\n",
    "score = min(scores)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.listtools import permuteRand\n",
    "\n",
    "permuteRand([1,2,3], 6, not_enough_ok=True)\n",
    "from itertools import permutations\n",
    "\n",
    "for i in permutations([1,2,3]):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurestoplot = []\n",
    "for key, val in getTrialsBlockParams(fd, 1)[\"behEval\"][\"beh_eval\"].items():\n",
    "    if val[\"feature\"] ==\"hausdorff\" and val[\"weight\"][0][0]>0:\n",
    "        featurestoplot.append(\"hausdorff\")\n",
    "    if val[\"feature\"] ==\"frac_touched\" and val[\"weight\"][0][0]>0:\n",
    "        featurestoplot.append(\"frac_touched\")\n",
    "featurestoplot.append(\"score_offline\")\n",
    "\n",
    "fig1, fig2 = plotOverview_(df, featurestoplot=featurestoplot)\n",
    "fig1.savefig(f\"{SAVEDIRDAY}/overview1.pdf\")\n",
    "fig2.savefig(f\"{SAVEDIRDAY}/overview2.pdf\")\n",
    "\n",
    "# 2) relationship between reward and factors that go into reward\n",
    "figs = plotReward(df, featurestoplot=featurestoplot)\n",
    "for i, f in enumerate(figs):\n",
    "    f.savefig(f\"{SAVEDIRDAY}/reward_score_{i}.pdf\")\n",
    "\n",
    "# 3) PLOT BEHAVIOR FOR TRIALS SORTED BY SCORE\n",
    "import copy\n",
    "scoretypes = copy.copy(featurestoplot)\n",
    "scoretypes.extend([\"behscore\", \"reward\"])\n",
    "for score_type in scoretypes:\n",
    "    FIGS = plotBehSortedByScore(df, fd, score_type)\n",
    "    for ver, figs in FIGS.items():\n",
    "        for i, f in enumerate(figs):\n",
    "            f.savefig(f\"{SAVEDIRDAY}/trialsSortedByScore_{score_type}_{ver}_{i}_.pdf\")\n",
    "\n",
    "# 4) Plot behavior subsampling in chronological order\n",
    "trials = [t for t in getIndsTrials(fd) if getTrialsFixationSuccess(fd, t)]\n",
    "Nrand = 80\n",
    "fig = plotMultTrialsSimple(fd, trials, zoom=True, strokes_ver=\"peanuts\", plot_fix=False,\n",
    "                        plotver=\"strokes\", rand_subset=Nrand)\n",
    "fig.savefig(f\"{SAVEDIRDAY}/trialsRandomChronOrder.pdf\")\n",
    "\n",
    "# 5) TASK VISUALIZATIONS, SCHEDULE, REPETITION\n",
    "figs = plotTaskSchedules(df)\n",
    "for i, f in enumerate(figs):\n",
    "    f.savefig(f\"{SAVEDIRDAY}/taskSchedule{i}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    animal = \"Pancho\"\n",
    "    expt = \"pilot\"\n",
    "    date = 200822\n",
    "    session = 1\n",
    "\n",
    "    fd = loadSingleData(animal, date, expt, session, resave_as_dict=False, load_resaved_data=True, \n",
    "                              resave_overwrite=False)\n",
    "\n",
    "    ## ==== [testing] stroke based hd\n",
    "    from pythonlib.tools.stroketools import distanceDTW\n",
    "    t = random.sample(getIndsTrials(fd),1)[0]\n",
    "\n",
    "    for ass in [True, False]:\n",
    "        print(f\"assymetric: {ass}\")\n",
    "        plotTrialSimple(fd, t, zoom=True, plot_fix=False, plotver=\"strokes\", \n",
    "                        use_peanut_params={'replaynum': 1, 'active': True})\n",
    "\n",
    "        strokes_beh = getTrialsStrokesByPeanuts(fd, t, replaynum=1)\n",
    "        strokes_task = getTrialsTaskAsStrokes(fd, t)\n",
    "        print(distanceDTW(strokes_beh, strokes_task[::-1], ver=\"segments\", asymmetric=ass))\n",
    "        print(distanceDTW(strokes_beh, strokes_task, ver=\"segments\", asymmetric=ass))\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax = plt.subplot(211)\n",
    "        plotDatStrokes(strokes_beh, ax=ax)\n",
    "        plotDatStrokes(strokes_task[::-1], ax=ax)\n",
    "\n",
    "        ax = plt.subplot(212)\n",
    "        plotDatStrokes(strokes_beh, ax=ax)\n",
    "        plotDatStrokes(strokes_task, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==== plot scoring separated by task type\n",
    "\n",
    "df = extractSessionDf(fd)\n",
    "\n",
    "# === add note about what probe type this is\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "(1) get all permutations\n",
    "(2) normalize by num strokes.\n",
    "(3) systematic - compare to old version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
