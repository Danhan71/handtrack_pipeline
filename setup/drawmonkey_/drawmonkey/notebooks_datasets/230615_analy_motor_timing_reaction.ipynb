{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Related to reaction times, motor timing, etc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6942b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# from tools.utils import * \n",
    "# from tools.plots import *\n",
    "# from tools.analy import *\n",
    "# from tools.calc import *\n",
    "# from tools.analyplot import *\n",
    "# from tools.preprocess import *\n",
    "# from tools.dayanalysis import *\n",
    "\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *\n",
    "import pythonlib\n",
    "from pythonlib.dataset.dataset import load_dataset, load_dataset_daily_helper\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed61740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching using this string:\n",
      "/home/lucast4/code/drawmonkey/expt_metadat/*230105-*Pancho.**\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/home/lucast4/code/drawmonkey/expt_metadat_daily/*230105-*Pancho.**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/home/lucast4/code/drawmonkey/expt_metadat_daily/primsingridfixed1-230105-Pancho.yaml\n",
      "Loading this dataset Pancho primsingridfixed1 230105\n",
      "Searching using this string:\n",
      "/gorilla1/analyses/database/*Pancho-*primsingridfixed1-*230105-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/gorilla1/analyses/database/BEH/*Pancho-*primsingridfixed1-*230105-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/gorilla1/analyses/database/BEH/Pancho-primsingridfixed1-230105-230106_024827\n",
      "Searching using this string:\n",
      "/mnt/Freiwald/kgupta/analyses/database/*Pancho-*primsingridfixed1-*230105-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/mnt/Freiwald/kgupta/analyses/database/BEH/*Pancho-*primsingridfixed1-*230105-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/mnt/Freiwald/kgupta/analyses/database/BEH/Pancho-primsingridfixed1-230105-230106_024827\n",
      "----------------\n",
      "Currently loading dataset pkl: /mnt/Freiwald/kgupta/analyses/database/BEH/Pancho-primsingridfixed1-230105-230106_024827\n",
      ".. Done!\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': '230105', 'edate': '230105', 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'230105': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['primsingridfixed1'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'primsingridfixed1', 'animal': 'Pancho', 'ssess': None, 'esess': None, 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/gorilla1/animals', 'sample_rate': array([500.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 18: 'end', 19: 'FixationRaiseFailWTH', 20: 'go (draw)', 21: 'guide_on_GA', 30: 'DelayWhatIsThis', 40: 'GoWhatIsThis', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 64: 'DragAroundAbort', 65: 'DragAroundFirstAbortNow', 70: 'hotkey_x', 71: 'DAstimevent_firstpres', 72: 'DAstimoff_finibeforepause', 73: 'DAstimoff_fini', 74: 'DAsamp1_visible_change', 75: 'DAnewpnutthisframe', 76: 'DAsound_samp1touched', 78: 'DAsound_gotallink', 80: 'ttl_trialon', 81: 'ttl_trialoff', 91: 'GAstimevent_firstpres', 92: 'GAstimoff_fini', 101: 'fix_square_on', 102: 'fix_square_off', 103: 'fix_square_on_pd', 111: 'photodiode_force_off', 120: 'DAsound_chunk', 121: 'DAsound_strokedone', 122: 'DAsound_chunkupdate', 123: 'DAsound_chunkdone', 124: 'DAsound_firstraise', 131: 'fix_cue_colored_on', 132: 'fix_cue_colored_on_v2', 133: 'fix_cue_colored_off', 134: 'fix_cue_colored_off_v2', 135: 'new_color_cue_off', 200: 'skipped_movie_frame'}, 'screen_hz': 59, 'screen_period': 0.01694915254237288}}\n",
      "Loading BlockParamsByDateSessBlock!\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n",
      "resetting index\n",
      "Updated columns: insummarydates, using Metadats\n",
      "Searching using this string:\n",
      "/gorilla1/analyses/database/TASKS_GENERAL/Pancho-primsingridfixed1-230105-all/*Tasks*pkl\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/gorilla1/analyses/database/TASKS_GENERAL/Pancho-primsingridfixed1-230105-all/Tasks.pkl\n",
      "--- Loading tasks pkl file:  /gorilla1/analyses/database/TASKS_GENERAL/Pancho-primsingridfixed1-230105-all/Tasks.pkl\n",
      "added new column self.Dat[Task]\n",
      "- starting/ending len (grouping params):\n",
      "918\n",
      "918\n",
      "- starting/ending len (getting sequence):\n",
      "918\n",
      "918\n",
      "--- Removing nans\n",
      "start len: 918\n",
      "- num names for each col\n",
      "not removing nans, since columns=[]\n",
      "Reassigned train/test, using key: probe\n",
      "and values:\n",
      "Train =  [0]\n",
      "Test =  [1]\n",
      " \n",
      "New distribution of train/test:\n",
      "train    918\n",
      "Name: monkey_train_or_test, dtype: int64\n",
      "Appended column: los_info\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_SEQUENCE_ALPHA]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "Appended self.Dat[superv_VISUALFB_METH]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_new\n",
      "[taskgroup_reassign_by_mapper], reassigned values in column: taskgroup\n",
      "GROUPING epoch\n",
      "GROUPING_LEVELS ['230105']\n",
      "FEATURE_NAMES ['hdoffline', 'num_strokes', 'circ', 'dist']\n",
      "SCORE_COL_NAMES []\n",
      "appended col to self.Dat:\n",
      "date_epoch\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_concise\n",
      "Append column to self.Dat:  supervision_stage_semantic\n",
      "Extracted into self.Dat[epoch_orig]\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "Running D._behclass_tokens_extract_datsegs\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "stored in self.Dat[BehClass]\n"
     ]
    }
   ],
   "source": [
    "# Load a daily dataset\n",
    "# D = load_dataset_daily_helper(\"Pancho\", \"221023\")\n",
    "# D = load_dataset_daily_helper(\"Pancho\", \"220831\")\n",
    "\n",
    "# D = load_dataset_daily_helper(\"Pancho\", \"221020\")\n",
    "# \n",
    "D = load_dataset_daily_helper(\"Pancho\", \"230105\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main dataset\n",
    "D = load_dataset(\"Diego\", \"gridlinecircleGOOD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49907d85",
   "metadata": {},
   "source": [
    "### 1. GRAMMAR chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "How does gap during across chunks compare to gaps within chunks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e7332",
   "metadata": {},
   "source": [
    "##### Single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05627c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythonlib.dataset.dataset_analy.motortiming import grammarchunks_preprocess_and_plot\n",
    "from pythonlib.dataset.dataset_analy.motortiming import grammarchunks_preprocess_and_plot, gapstrokes_preprocess_extract_strokes_gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = grammarchunks_preprocess_and_plot(D, False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f10b6",
   "metadata": {},
   "source": [
    "##### Iterate over dates and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25412a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Older dates\n",
    "LIST_DATE = [\"220829\",\"220831\", \"220901\", \"220902\", \"220908\", \"220909\"]\n",
    "LIST_DATE = [\"220829\",\"220831\", \"220901\", \"220902\", \"220908\", \"220909\"]\n",
    "\n",
    "# LIST_DATE = [\"220913\", \"220911\", \"220916\", \"220915\", \"220921\", \"220920\", \"220929\", \"220925\", \n",
    "#  \"220928\", \"220926\", \"220930\", \"221001\", \"221014\", \"221002\"]\n",
    "LIST_DATE = [\"220916\", \"220915\", \"220921\", \"220920\", \"220929\", \"220925\", \n",
    " \"220928\", \"220926\", \"220930\", \"221001\", \"221014\", \"221002\"]\n",
    "for DATE in LIST_DATE:\n",
    "    D = load_dataset_daily_helper(\"Pancho\", DATE)    \n",
    "    grammarchunks_preprocess_and_plot(D)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431eaca",
   "metadata": {},
   "source": [
    "### 2. PLOTS of gaps, strokes (not grammar stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e64891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING at:  /gorilla1/analyses/main/motortiming_gapstrokes/Pancho_230105_primsingridfixed1\n",
      "-- Len of D, before applying this param: one_to_one_beh_task_strokes, ... 918\n",
      "after: 740\n",
      "Removing these trials: \n",
      "[]\n",
      "self.Dat starting legnth:  740\n",
      "Modified self.Dat, keeping only the inputted inds\n",
      "self.Dat final legnth:  740\n",
      "Success! all gridloc identical!\n",
      "These are the x and y mappings, gridloc:loc\n",
      "x... {1: 1.7, 0: -1.6}\n",
      "y... {1: 1.7, 0: -1.6}\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "This many strokes extracted:  1985\n",
      "Appended epoch to self.Dat\n",
      "Appended character to self.Dat\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from pythonlib.dataset.dataset_analy.motortiming import grammarchunks_preprocess_and_plot, gapstrokes_preprocess_extract_strokes_gaps\n",
    "DS, SAVEDIR = gapstrokes_preprocess_extract_strokes_gaps(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125135c",
   "metadata": {},
   "source": [
    "##### Overlay stroke and gap durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56f4145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.Dat[\"gap_from_prev_dur_log10\"] = np.log10(DS.Dat[\"gap_from_prev_dur\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a8951c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'savedir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msavedir\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'savedir' is not defined"
     ]
    }
   ],
   "source": [
    "savedir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feaee6a",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a96339ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "1138\n",
      "Plotting for  time_duration\n",
      "Plotting for  time_duration_NORMED\n",
      "Plotting for  time_duration_DIVNORMED\n",
      "1985\n",
      "1138\n",
      "Plotting for  gap_from_prev_dur\n",
      "Plotting for  gap_from_prev_dur_NORMED\n",
      "Plotting for  gap_from_prev_dur_DIVNORMED\n",
      "1985\n",
      "1138\n",
      "Plotting for  gap_from_prev_vel\n",
      "Plotting for  gap_from_prev_vel_NORMED\n",
      "Plotting for  gap_from_prev_vel_DIVNORMED\n",
      "1985\n",
      "1138\n",
      "Plotting for  velocity\n",
      "Plotting for  velocity_NORMED\n",
      "Plotting for  velocity_DIVNORMED\n"
     ]
    }
   ],
   "source": [
    "from pythonlib.dataset.dataset_analy.motortiming import gapstrokes_timing_plot_all\n",
    "\n",
    "# savedir = \"/tmp\"\n",
    "LIST_Y_PLOT = None\n",
    "# LIST_Y_PLOT = [\"time_duration\"];\n",
    "gapstrokes_timing_plot_all(DS, SAVEDIR, LIST_Y_PLOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee750c",
   "metadata": {},
   "source": [
    "##### Iterate over dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.motortiming import gapstrokes_timing_plot_all, gapstrokes_preprocess_extract_strokes_gaps\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62700f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_DATE = [\"220831\", \"220901\", \"220902\", \"220908\", \"220909\", \"230105\",\"230106\", \"230108\", \"230109\", \"230608\", \"230622\", \"230626\", \"230623\"]\n",
    "for DATE in LIST_DATE:\n",
    "    D = load_dataset_daily_helper(\"Pancho\", DATE)\n",
    "    DS, SAVEDIR = gapstrokes_preprocess_extract_strokes_gaps(D)\n",
    "    savedir = f\"{SAVEDIR}/gapstroke_timing\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    gapstrokes_timing_plot_all(DS, savedir)\n",
    "#     except Exception as err:\n",
    "#         print(\"*************** SKIPPING **********\", DATE)\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f71f10",
   "metadata": {},
   "source": [
    "### 3. COMPARING across levels of variablesm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd18dad",
   "metadata": {},
   "source": [
    "##### Comparing probes vs. non-probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a87f945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.motortiming import gapstroke_timing_compare_by_variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04dc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR = \"probe\"\n",
    "VARS_CONTEXT = [\"CTXT_loc_prev\", \"gridloc\", \"epoch\"]\n",
    "n_min = 5\n",
    "\n",
    "params_preprocess = [\"no_supervision\", \"one_to_one_beh_task_strokes\", \"correct_sequencing_binary_score\", \"only_blocks_with_probes\"]\n",
    "# params_preprocess = [\"no_supervision\", \"one_to_one_beh_task_strokes\", \"correct_sequencing_binary_score\", \"only_blocks_with_probes\"]\n",
    "# params_preprocess = [\"no_supervision\", \"one_to_one_beh_task_strokes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ab93d",
   "metadata": {},
   "source": [
    "##### Timing of first gap, is it faster if 2nd stroke follows determinstically from first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c934743",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR = \"strokes01_sameness\"\n",
    "# VARS_CONTEXT = [\"CTXT_loc_prev\", \"gridloc\", \"epoch\"]\n",
    "VARS_CONTEXT = [\"CTXT_shape_prev\", \"shape\", \"CTXT_loc_prev\", \"gridloc\"]\n",
    "n_min = 3\n",
    "\n",
    "params_preprocess = [\"no_supervision\", \"one_to_one_beh_task_strokes\", \"correct_sequencing_binary_score\", \"only_blocks_with_probes\"]\n",
    "# params_preprocess = [\"no_supervision\", \"one_to_one_beh_task_strokes\", \"correct_sequencing_binary_score\", \"only_blocks_with_probes\"]\n",
    "# params_preprocess = [\"no_supervision\", \"one_to_one_beh_task_strokes\"]\n",
    "\n",
    "# PREP\n",
    "D.sequence_strokes_compute_01_sameness_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapstroke_timing_compare_by_variable(D, VAR, VARS_CONTEXT, params_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSOLETE - see D.epochset_extract_wrapper(version = char_seq_same_first_n_strokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ed85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def epochset_extract_common_stroke_index(D, list_stroke_index):\n",
    "#     \"\"\" Group trials so that all trials which have, across epochs,\n",
    "#     (same char, same stroke at the given index) into one group, and\n",
    "#     all others into leftover group\n",
    "#     \"\"\"\n",
    "#     assert isinstance(list_stroke_index, list)\n",
    "#     Dcopy = D.copy()\n",
    "\n",
    "#     # Find chars with same first stroke but diff seceond stroke across epcods.\n",
    "#     Dcopy.sequence_char_taskclass_assign_char_seq(sequence_keep_these_indices=list_stroke_index)\n",
    "\n",
    "#     # First, keep only chars with same first stroke across epochs\n",
    "#     Dcopy.epochset_extract_common_epoch_sets(merge_sets_with_only_single_epoch=True)\n",
    "    \n",
    "#     # get trials that have same stroke across epochs.\n",
    "#     epochs_all = tuple(sorted(Dcopy.Dat[\"epoch\"].unique().tolist()))\n",
    "#     trialcodes_keep = Dcopy.Dat[Dcopy.Dat[\"epochset\"]==epochs_all][\"trialcode\"].tolist()\n",
    "    \n",
    "#     return trialcodes_keep\n",
    "\n",
    "# # Get trials that have same first stroke\n",
    "# trialcodes_first = epochset_extract_common_stroke_index(D, [0])\n",
    "\n",
    "# # Get trials that have same second stroke\n",
    "# trialcodes_second = epochset_extract_common_stroke_index(D, [1])\n",
    "\n",
    "# trialcodes_both = [t for t in trialcodes_first if t in trialcodes_second]\n",
    "# trialcodes_first_notsecond = [t for t in trialcodes_first if t not in trialcodes_second]\n",
    "\n",
    "# chars_both = sorted(D.Dat[D.Dat[\"trialcode\"].isin(trialcodes_both)][\"character\"].unique().tolist())\n",
    "# chars_first_notsecond = sorted(D.Dat[D.Dat[\"trialcode\"].isin(trialcodes_first_notsecond)][\"character\"].unique().tolist())\n",
    "\n",
    "# print(\"BOTH\")\n",
    "# for x in chars_both:\n",
    "#     print(x)\n",
    "\n",
    "# print(\"FIRST\")\n",
    "# for x in chars_first_notsecond:\n",
    "#     print(x)\n",
    "\n",
    "# # for each trial assign it a classification\n",
    "# assert len([t for t in trialcodes_both if t in trialcodes_first_notsecond])==0 # - make sure exlcusive\n",
    "\n",
    "# names = []\n",
    "# for ind in range(len(D.Dat)):\n",
    "#     tc = D.Dat.iloc[ind][\"trialcode\"]\n",
    "    \n",
    "#     if tc in trialcodes_both:\n",
    "#         names.append(\"both\")\n",
    "#     elif tc in trialcodes_first_notsecond:\n",
    "#         names.append(\"first_not_second\")\n",
    "#     else:\n",
    "#         names.append(\"neither\")\n",
    "        \n",
    "# D.Dat[\"strokes12_same\"] = names\n",
    "\n",
    "# tmp = D.grouping_get_inner_items(\"character\", \"strokes12_same\")\n",
    "# for val in tmp.values():\n",
    "#     assert len(val)==1, \"a char can only be one...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62277f",
   "metadata": {},
   "source": [
    "### OLDER [just looks at first gap]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d605e4a",
   "metadata": {},
   "source": [
    "##### Extract and compute motor stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GOOD] get sequence context data\n",
    "D.seqcontext_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GOOD] only keep unaborted trials\n",
    "D.preprocessGood(params=[\"one_to_one_beh_task_strokes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_motor_stats = []\n",
    "for ind in range(len(D.Dat)):\n",
    "    motor_dict = D.get_motor_stats(ind)\n",
    "    motor_dict[\"ind_dat\"] = ind\n",
    "    motor_dict[\"trialcode\"] = D.Dat.iloc[ind][\"trialcode\"]\n",
    "    motor_dict[\"epoch\"] = D.Dat.iloc[ind][\"epoch\"]\n",
    "    motor_dict[\"character\"] = D.Dat.iloc[ind][\"character\"]\n",
    "    motor_dict[\"seqc_0_loc\"] = D.Dat.iloc[ind][\"seqc_0_loc\"]\n",
    "    motor_dict[\"seqc_0_shape\"] = D.Dat.iloc[ind][\"seqc_0_shape\"]\n",
    "    motor_dict[\"seqc_0_loc_shape\"] = D.Dat.iloc[ind][\"seqc_0_loc_shape\"]\n",
    "    motor_dict[\"seqc_nstrokes_beh\"] = D.Dat.iloc[ind][\"seqc_nstrokes_beh\"]\n",
    "    motor_dict[\"seqc_nstrokes_task\"] = D.Dat.iloc[ind][\"seqc_nstrokes_task\"]\n",
    "\n",
    "    # get time from go to first touch\n",
    "    motor_dict[\"time_go2firsttouch\"] = motor_dict[\"time_go2raise\"] + motor_dict[\"time_raise2firsttouch\"]\n",
    "    \n",
    "    # gap velocities\n",
    "    motor_dict[\"vel_raise2firsttouch\"] = motor_dict[\"dist_raise2firsttouch\"]/motor_dict[\"time_raise2firsttouch\"]\n",
    "\n",
    "        \n",
    "    # how quickly does he do the first stroke\n",
    "    motor_dict[\"seqc_0_time\"] = motor_dict[\"offs\"][0] - motor_dict[\"ons\"][0] \n",
    "    motor_dict[\"seqc_0_dist\"] = motor_dict[\"dists_stroke\"][0]\n",
    "    motor_dict[\"seqc_0_vel\"] = motor_dict[\"seqc_0_dist\"]/motor_dict[\"seqc_0_time\"]\n",
    "\n",
    "    list_motor_stats.append(motor_dict)\n",
    "\n",
    "import pandas as pd\n",
    "dfmotor = pd.DataFrame(list_motor_stats)\n",
    "\n",
    "# # use velocity instead of time\n",
    "# from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "# def F(x):\n",
    "#     return x[\"dist_raise2firsttouch\"]/x[\"time_raise2firsttouch\"]\n",
    "# dfmotor = applyFunctionToAllRows(dfmotor, F, \"vel_raise2firsttouch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4617e",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4585630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GOOD] remove outliers\n",
    "dfmotor = D.removeOutlierRows([\"time_go2raise\", \"time_raise2firsttouch\"],[0, 97], df=dfmotor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the characters before plotting\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRICT, want at least one trial across each elvel\n",
    "print(dfmotor[\"epoch\"].value_counts())\n",
    "epochs_keep = [\"oneshp_varyloc\", \"oneloc_varyshp\", \"varyloc_varyshp\"]\n",
    "epochs_keep = [\"oneloc_varyshp\", \"varyloc_varyshp\"]\n",
    "\n",
    "dfmotor, dict_df = extract_with_levels_of_conjunction_vars(dfmotor, \"epoch\", [\"character\"],\n",
    "                                       levels_var=epochs_keep, n_min=1)\n",
    "\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dfmotor, [\"character\", \"epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6678bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GOOD] LENIENT, want to have at least n trials..\n",
    "VAR = \"seqc_nstrokes_beh\"\n",
    "VARS_OTHERS = [\"seqc_0_loc_shape\"]\n",
    "n_min_trials = 5\n",
    "print(len(dfmotor))\n",
    "dfmotor, dict_df = extract_with_levels_of_conjunction_vars(dfmotor, VAR, VARS_OTHERS, n_min=n_min_trials, \n",
    "                                        lenient_allow_data_if_has_n_levels=2)\n",
    "print(len(dfmotor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4f85b",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for y in [\"time_go2raise\", \"time_raise2firsttouch\", \"time_go2firsttouch\", \"dist_raise2firsttouch\"]:\n",
    "    sns.catplot(data=dfmotor, x=\"epoch\", y=y, kind=\"boxen\")\n",
    "    sns.catplot(data=dfmotor, x=\"epoch\", y=y, kind=\"point\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ae931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of time vs. dist\n",
    "sns.pairplot(data=dfmotor, vars=[\"time_go2firsttouch\", \"dist_raise2firsttouch\"], hue=\"epoch\", diag_kind=\"hist\", \n",
    "            height=3, plot_kws={\"alpha\":0.8, \"marker\":\".\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f0b2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [GOOD] Dissociate by location and shape of first reach\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "# HUE = \"epoch\"\n",
    "HUE = \"seqc_nstrokes_beh\"\n",
    "%matplotlib inline\n",
    "for y in [\"time_go2raise\", \"time_raise2firsttouch\", \"time_go2firsttouch\", \n",
    "          \"dist_raise2firsttouch\", \"vel_raise2firsttouch\", \"seqc_0_time\", \"seqc_0_dist\", \"seqc_0_vel\"]:\n",
    "\n",
    "    fig = sns.catplot(data=dfmotor, x=\"seqc_0_loc_shape\", y=y, hue=HUE, jitter=True, alpha=0.3, aspect=2)\n",
    "    rotateLabel(fig)\n",
    "    \n",
    "    fig = sns.catplot(data=dfmotor, x=\"seqc_0_loc_shape\", y=y, hue=HUE, kind=\"point\", ci=68, aspect=2)\n",
    "    rotateLabel(fig)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
