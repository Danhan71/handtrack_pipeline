{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1/24/23 - \n",
    "GOOD - collecting all timecourse plots here, from:\n",
    "- original (dataset summary)\n",
    "- dataset.plots\n",
    "- characters\n",
    "- grammar\n",
    "\n",
    "--> all in module:\n",
    "dataset.learning.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "further-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# from tools.utils import * \n",
    "# from tools.plots import *\n",
    "# from tools.analy import *\n",
    "# from tools.calc import *\n",
    "# from tools.analyplot import *\n",
    "# from tools.preprocess import *\n",
    "# from tools.dayanalysis import *\n",
    "\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *\n",
    "import pythonlib\n",
    "from pythonlib.dataset.dataset import Dataset\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f656b",
   "metadata": {},
   "source": [
    "##### Try loading a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2834d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching using this string:\n",
      "/gorilla1/analyses/database/*Pancho-*charstrokeseqpan2-*null-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/gorilla1/analyses/database/BEH/*Pancho-*charstrokeseqpan2-*null-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "2\n",
      "---\n",
      "/gorilla1/analyses/database/BEH/Pancho-charstrokeseqpan2-null-230119_103344\n",
      "---\n",
      "/gorilla1/analyses/database/BEH/Pancho-charstrokeseqpan2-null-230121_174308\n",
      "Searching using this string:\n",
      "/mnt/Freiwald/kgupta/analyses/database/*Pancho-*charstrokeseqpan2-*null-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "Searching using this string:\n",
      "/mnt/Freiwald/kgupta/analyses/database/BEH/*Pancho-*charstrokeseqpan2-*null-*/*dat*.pkl\n",
      "-- Splitting off dir from fname\n",
      "Found this many paths:\n",
      "0\n",
      "----------------\n",
      "Currently loading dataset pkl: /gorilla1/analyses/database/BEH/Pancho-charstrokeseqpan2-null-230121_174308\n",
      ".. Done!\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': '230117', 'edate': '230120', 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'230117': 1, '230118': 1, '230119': 1, '230120': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['charstrokeseqpan2', 'charstrokeseqpan2b', 'charstrokeseqpan2c', 'charstrokeseqpan2d'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'charstrokeseqpan2', 'animal': 'Pancho', 'ssess': None, 'esess': None, 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/gorilla1/animals', 'sample_rate': array([500.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 18: 'end', 19: 'FixationRaiseFailWTH', 20: 'go (draw)', 21: 'guide_on_GA', 30: 'DelayWhatIsThis', 40: 'GoWhatIsThis', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 64: 'DragAroundAbort', 65: 'DragAroundFirstAbortNow', 70: 'hotkey_x', 71: 'DAstimevent_firstpres', 72: 'DAstimoff_finibeforepause', 73: 'DAstimoff_fini', 74: 'DAsamp1_visible_change', 75: 'DAnewpnutthisframe', 76: 'DAsound_samp1touched', 78: 'DAsound_gotallink', 80: 'ttl_trialon', 81: 'ttl_trialoff', 91: 'GAstimevent_firstpres', 92: 'GAstimoff_fini', 101: 'fix_square_on', 102: 'fix_square_off', 103: 'fix_square_on_pd', 111: 'photodiode_force_off', 120: 'DAsound_chunk', 121: 'DAsound_strokedone', 122: 'DAsound_chunkupdate', 123: 'DAsound_chunkdone', 124: 'DAsound_firstraise', 131: 'fix_cue_colored_on', 132: 'fix_cue_colored_on_v2', 133: 'fix_cue_colored_off', 134: 'fix_cue_colored_off_v2', 135: 'new_color_cue_off', 200: 'skipped_movie_frame'}, 'screen_hz': 59, 'screen_period': 0.01694915254237288}}\n",
      "Loading BlockParamsByDateSessBlock!\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n",
      "resetting index\n",
      "Updated columns: insummarydates, using Metadats\n",
      "Searching using this string:\n",
      "/gorilla1/analyses/database/TASKS_GENERAL/Pancho-charstrokeseqpan2-null-all/*Tasks*pkl\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/gorilla1/analyses/database/TASKS_GENERAL/Pancho-charstrokeseqpan2-null-all/Tasks.pkl\n",
      "--- Loading tasks pkl file:  /gorilla1/analyses/database/TASKS_GENERAL/Pancho-charstrokeseqpan2-null-all/Tasks.pkl\n",
      "added new column self.Dat[Task]\n",
      "- starting/ending len (grouping params):\n",
      "3251\n",
      "3251\n",
      "- starting/ending len (getting sequence):\n",
      "3251\n",
      "3251\n",
      "--- Removing nans\n",
      "start len: 3251\n",
      "- num names for each col\n",
      "not removing nans, since columns=[]\n",
      "Reassigned train/test, using key: probe\n",
      "and values:\n",
      "Train =  [0]\n",
      "Test =  [1]\n",
      " \n",
      "New distribution of train/test:\n",
      "train    2879\n",
      "test      372\n",
      "Name: monkey_train_or_test, dtype: int64\n",
      "Appended column: los_info\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_SEQUENCE_ALPHA]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "Appended self.Dat[superv_VISUALFB_METH]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_new\n",
      "[taskgroup_reassign_by_mapper], reassigned values in column: taskgroup\n",
      "GROUPING epoch\n",
      "GROUPING_LEVELS ['null']\n",
      "FEATURE_NAMES ['hdoffline', 'num_strokes', 'circ', 'dist']\n",
      "SCORE_COL_NAMES []\n",
      "appended col to self.Dat:\n",
      "date_epoch\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_concise\n"
     ]
    }
   ],
   "source": [
    "from pythonlib.dataset.dataset_preprocess.general import get_rulelist\n",
    "\n",
    "### DAILY\n",
    "expt = \"charstrokeseqpan2\" #run for chunkbyshape1, chunkbyshape2\n",
    "animal = \"Pancho\"\n",
    "D = Dataset([])\n",
    "# rulelist = get_rulelist(animal, expt)\n",
    "rulelist = [\"null\"]\n",
    "\n",
    "D.load_dataset_helper(animal, expt, ver=\"mult\", rule=rulelist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b833f7",
   "metadata": {},
   "source": [
    "### [OPTIONAL] extract domain-specific stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35922f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING at:  /gorilla1/analyses/main/character_strokiness/Pancho-charstrokeseqpan2-null\n",
      "stored in self.Dat[BehClass]\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "Removing these trials: \n",
      "[1499]\n",
      "self.Dat starting legnth:  3250\n",
      "Modified self.Dat, keeping only the inputted inds\n",
      "self.Dat final legnth:  3250\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "This many strokes extracted:  8360\n",
      "Appended character to self.Dat\n",
      "staritng legnth:  8360\n",
      "final legnth:                                                   Stroke  \\\n",
      "0     <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "1     <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "2     <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "3     <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "4     <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "...                                                 ...   \n",
      "7708  <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "7709  <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "7710  <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "7711  <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "7712  <pythonlib.behavior.strokeclass.StrokeClass ob...   \n",
      "\n",
      "                                                 datseg  circularity  \\\n",
      "0     {'shape': 'squiggle3-3-2-1', 'shape_oriented':...     0.758865   \n",
      "1     {'shape': 'squiggle3-3-2-1', 'shape_oriented':...     0.592948   \n",
      "2     {'shape': 'Lcentered-4-3-0', 'shape_oriented':...     0.298333   \n",
      "3     {'shape': 'V-2-4-0', 'shape_oriented': 'V-2-4-...     0.038203   \n",
      "4     {'shape': 'arcdeep-4-1-0', 'shape_oriented': '...     0.556530   \n",
      "...                                                 ...          ...   \n",
      "7708  {'shape': 'squiggle3-3-2-1', 'shape_oriented':...     0.057153   \n",
      "7709  {'shape': 'Lcentered-4-3-0', 'shape_oriented':...     0.545366   \n",
      "7710  {'shape': 'Lcentered-4-2-0', 'shape_oriented':...     0.597684   \n",
      "7711  {'shape': 'Lcentered-4-3-0', 'shape_oriented':...     0.199985   \n",
      "7712  {'shape': 'V-2-4-0', 'shape_oriented': 'V-2-4-...     0.009926   \n",
      "\n",
      "         distcum  displacement     angle  task_kind grid_ver        gridsize  \\\n",
      "0     614.332091    148.137252  3.157584  character   on_rel  rig3_3x3_small   \n",
      "1     277.023620    112.763147  2.959243  character   on_rel  rig3_3x3_small   \n",
      "2     403.477139    283.106584  4.162410  character   on_rel  rig3_3x3_small   \n",
      "3     145.978078    140.401226  1.968331  character   on_rel  rig3_3x3_small   \n",
      "4     347.703323    154.196102  2.017570  character   on_rel  rig3_3x3_small   \n",
      "...          ...           ...       ...        ...      ...             ...   \n",
      "7708  186.223538    175.580369  2.944480  character   on_rel  rig3_3x3_small   \n",
      "7709  442.293991    201.081775  3.719115  character   on_rel  rig3_3x3_small   \n",
      "7710  387.736842    155.992752  3.847342  character   on_rel  rig3_3x3_small   \n",
      "7711  417.231657    333.791505  4.091669  character   on_rel  rig3_3x3_small   \n",
      "7712  152.795770    151.279186  1.916758  character   on_rel  rig3_3x3_small   \n",
      "\n",
      "     dataset_trialcode  ...  \\\n",
      "0          230117-1-33  ...   \n",
      "1          230117-2-50  ...   \n",
      "2          230117-2-50  ...   \n",
      "3          230117-2-50  ...   \n",
      "4          230117-2-51  ...   \n",
      "...                ...  ...   \n",
      "7708      230120-1-897  ...   \n",
      "7709      230120-1-897  ...   \n",
      "7710      230120-1-898  ...   \n",
      "7711      230120-1-898  ...   \n",
      "7712      230120-1-898  ...   \n",
      "\n",
      "                                                   Prim ind_taskstroke_orig  \\\n",
      "0     <pythonlib.primitives.primitiveclass.Primitive...                   1   \n",
      "1     <pythonlib.primitives.primitiveclass.Primitive...                   0   \n",
      "2     <pythonlib.primitives.primitiveclass.Primitive...                   2   \n",
      "3     <pythonlib.primitives.primitiveclass.Primitive...                   1   \n",
      "4     <pythonlib.primitives.primitiveclass.Primitive...                   0   \n",
      "...                                                 ...                 ...   \n",
      "7708  <pythonlib.primitives.primitiveclass.Primitive...                   1   \n",
      "7709  <pythonlib.primitives.primitiveclass.Primitive...                   2   \n",
      "7710  <pythonlib.primitives.primitiveclass.Primitive...                   2   \n",
      "7711  <pythonlib.primitives.primitiveclass.Primitive...                   1   \n",
      "7712  <pythonlib.primitives.primitiveclass.Primitive...                   0   \n",
      "\n",
      "     gridloc  gridloc_x  gridloc_y  rel_from_prev  h_v_move_from_prev  \\\n",
      "0       None        NaN        NaN           None                None   \n",
      "1       None        NaN        NaN           None                None   \n",
      "2       None        NaN        NaN           None                None   \n",
      "3       None        NaN        NaN           None                None   \n",
      "4       None        NaN        NaN           None                None   \n",
      "...      ...        ...        ...            ...                 ...   \n",
      "7708    None        NaN        NaN           None                None   \n",
      "7709    None        NaN        NaN           None                None   \n",
      "7710    None        NaN        NaN           None                None   \n",
      "7711    None        NaN        NaN           None                None   \n",
      "7712    None        NaN        NaN           None                None   \n",
      "\n",
      "                                                  strok  \\\n",
      "0     [[79.02358045478005, 29.06888355319531, 3.776]...   \n",
      "1     [[136.94602752674433, 39.253959617079985, 3.83...   \n",
      "2     [[36.94962235319816, 235.70390095536055, 4.722...   \n",
      "3     [[12.033848073806253, 118.03209647564624, 5.80...   \n",
      "4     [[57.92707493811417, -3.995616091242346, 3.592...   \n",
      "...                                                 ...   \n",
      "7708  [[113.86670723710279, 61.201263280932, 4.44], ...   \n",
      "7709  [[49.87749194917098, 229.1609224734292, 5.206]...   \n",
      "7710  [[7.921676928897534, 122.2756842031264, 4.288]...   \n",
      "7711  [[86.67986290136005, 293.055071559334, 5.388],...   \n",
      "7712  [[-17.015243448596877, 72.05641233454455, 6.52...   \n",
      "\n",
      "                        character           shape_char  \n",
      "0      charstrokeseq-18-28-322507   squiggle3-3-2-1|20  \n",
      "1     charstrokeseq-19-106-091431   squiggle3-3-2-1|88  \n",
      "2     charstrokeseq-19-106-091431   Lcentered-4-3-0|88  \n",
      "3     charstrokeseq-19-106-091431           V-2-4-0|88  \n",
      "4      charstrokeseq-18-65-689956     arcdeep-4-1-0|61  \n",
      "...                           ...                  ...  \n",
      "7708   charstrokeseq-19-54-611613  squiggle3-3-2-1|146  \n",
      "7709   charstrokeseq-19-54-611613  Lcentered-4-3-0|146  \n",
      "7710   charstrokeseq-20-63-599366  Lcentered-4-2-0|231  \n",
      "7711   charstrokeseq-20-63-599366  Lcentered-4-3-0|231  \n",
      "7712   charstrokeseq-20-63-599366          V-2-4-0|231  \n",
      "\n",
      "[7713 rows x 27 columns]\n",
      "Modified self.Dat!\n",
      "Basis set of strokes: ['Lcentered-4-2-0', 'Lcentered-4-3-0', 'Lcentered-4-4-0', 'V-2-1-0', 'V-2-2-0', 'V-2-4-0', 'arcdeep-4-1-0', 'arcdeep-4-2-0', 'arcdeep-4-4-0', 'circle-6-1-0', 'line-8-1-0', 'line-8-2-0', 'line-8-3-0', 'line-8-4-0', 'squiggle3-3-1-0', 'squiggle3-3-2-0', 'squiggle3-3-2-1']\n"
     ]
    }
   ],
   "source": [
    "# Characters\n",
    "from pythonlib.dataset.dataset_analy.characters import pipeline_generate_and_plot_all\n",
    "RES, savedir = pipeline_generate_and_plot_all(D, False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef88ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230119    915\n",
       "230117    819\n",
       "230118    813\n",
       "230120    703\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract subset, for testing\n",
    "D.Dat[\"date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9e9f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.Dat modified!!\n"
     ]
    }
   ],
   "source": [
    "Dall = D.copy()\n",
    "D.filterPandas({\"date\":[\"230117\", \"230120\"]}, \"modify\")\n",
    "D.subsampleTrials(40, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c6415",
   "metadata": {},
   "source": [
    "### Trial-level plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81387a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b933c51",
   "metadata": {},
   "source": [
    "# TIMECOURSE PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0b0e3",
   "metadata": {},
   "source": [
    "##### [GOOD] everything collected here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce37b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: only thing not done is stuff on angles_all..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18055ddd",
   "metadata": {},
   "source": [
    "##### 0. extract scores, scalars one per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2f3c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num nan/total, for angle_overall\n",
      "382 / 3250\n",
      "Num nan/total, for num_strokes\n",
      "0 / 3250\n",
      "Num nan/total, for circ\n",
      "0 / 3250\n",
      "Num nan/total, for dist\n",
      "0 / 3250\n",
      "Added these features:\n",
      "['FEAT_angle_overall', 'FEAT_num_strokes', 'FEAT_circ', 'FEAT_dist']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['FEAT_angle_overall', 'FEAT_num_strokes', 'FEAT_circ', 'FEAT_dist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_extract = [\"angle_overall\", \"num_strokes\", \"circ\", \"dist\"]\n",
    "D.extract_beh_features(features_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add more features, add into extract_beh_features the method for computing your score of interest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fff60f",
   "metadata": {},
   "source": [
    "##### 1. timecourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d33a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14ade40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.plots import plot_timecourse_overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615047f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a) Plot raw score over time, across all trials\n",
    "variable = \"FEAT_dist\"\n",
    "xval = \"tvalfake\"\n",
    "# overlay_mean = \"day\"\n",
    "grouping = None # how to color the dots.\n",
    "grouping_each_panel = []\n",
    "domean=True\n",
    "\n",
    "features_list = [variable]\n",
    "figlist = plot_timecourse_overlaid(D, features_list, xval, grouping, doscatter=True, \n",
    "                                   grouping_each_panel=grouping_each_panel,\n",
    "                                   domean=domean, col_wrap=2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad0ae948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1b) for each character, plots its raw score over time\n",
    "grouping_each_panel = [\"character\"]\n",
    "\n",
    "features_list = [variable]\n",
    "figlist = plot_timecourse_overlaid(D, features_list, xval, grouping, doscatter=True, \n",
    "                                   grouping_each_panel=grouping_each_panel,\n",
    "                                   domean=domean, col_wrap=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4c44d",
   "metadata": {},
   "source": [
    "##### 2. Line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa0b12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2a) Summarize scores across unique characters (each char gets its own line), \n",
    "# split into seaprate subplots for each task set\n",
    "\n",
    "from pythonlib.tools.snstools import plotgood_lineplot\n",
    "\n",
    "yval = \"FEAT_dist\" # x variable\n",
    "xval = \"epoch\" # y variable\n",
    "line_grouping = \"character\" # each level of this grouping var gets its own line\n",
    "include_scatter=False # whether to include scatterplot of raw data\n",
    "color_single = \"k\" # how to color lines\n",
    "lines_add_ci = False # \n",
    "rowvar = \"task_stagecategory\"\n",
    "colvar = None\n",
    "col_wrap = 2\n",
    "# relplot_kw = {\"row\":rowvar, \"col\":colvar}\n",
    "# relplot_kw = {\"row\":rowvar, \"col\":colvar}\n",
    "\n",
    "\n",
    "# y = \"beh_multiplier\"\n",
    "# fig = relplotOverlaid(D.Dat, \"character\", \"k\",\n",
    "#                data=D.Dat, x=\"epoch\", y=y, col=\"taskgroup\", row=\"task_stagecategory\", \n",
    "#         hue=\"character\", kind=\"line\")\n",
    "\n",
    "\n",
    "g = plotgood_lineplot(D.Dat, xval, yval, line_grouping, include_scatter, color_single=color_single, \n",
    "                      rowvar = rowvar, colvar=colvar, lines_add_ci=lines_add_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b) Same, but no error bars, and overlaying scatter of each datapt\n",
    "\n",
    "from pythonlib.tools.snstools import plotgood_lineplot\n",
    "\n",
    "include_scatter=True # whether to include scatterplot of raw data\n",
    "color_single = None # how to color lines\n",
    "\n",
    "g = plotgood_lineplot(D.Dat, xval, yval, line_grouping, include_scatter, color_single=color_single, \n",
    "                      rowvar = rowvar, colvar=colvar, lines_add_ci=lines_add_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d44747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c) Lines, showing scores across blocks\n",
    "# 2b) Same, but no error bars, and overlaying scatter of each datapt\n",
    "\n",
    "from pythonlib.tools.snstools import plotgood_lineplot\n",
    "\n",
    "xval = \"block\" # y variable\n",
    "line_grouping = \"character\" # each level of this grouping var gets its own line\n",
    "include_scatter= False # whether to include scatterplot of raw data\n",
    "color_single = \"k\" # how to color lines\n",
    "aspect = 2 # to stretch it \n",
    "\n",
    "\n",
    "g = plotgood_lineplot(D.Dat, xval, yval, line_grouping, include_scatter, color_single=color_single, \n",
    "                      rowvar = rowvar, colvar=colvar, lines_add_ci=lines_add_ci, aspect=aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ca40b",
   "metadata": {},
   "source": [
    "##### 3. catplots, one for each epoch, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc48c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - point plot\n",
    "x = \"epoch\"\n",
    "y = \"FEAT_dist\" # x variable\n",
    "hue = \"epoch\"\n",
    "col = \"task_stagecategory\"\n",
    "kind = \"point\"\n",
    "fig = sns.catplot(data=D.Dat, x=x, y=y, hue=hue, col=col,kind=kind)\n",
    "\n",
    "# - plot each datpt\n",
    "fig = sns.catplot(data=D.Dat, x=x, y=y, hue=hue, col=col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd78bc7",
   "metadata": {},
   "source": [
    "##### THings still need to incorporate into timecourse plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93520fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add: \n",
    "# analysis_TEMPLATE, search for timecourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "### old: histogram plots\n",
    "assert False, \"incorporate these into above\"\n",
    "\n",
    "\n",
    "for dset in [\"test\", \"test_G2\", \"test_G3\"]:\n",
    "    ######### [EXTRACT TEST TASKS]\n",
    "    # --- DEFAULT, get all test tasks\n",
    "    F = {\"insummarydates\":[True], \n",
    "         \"online_abort\":[None], \n",
    "         \"random_task\":[False],\n",
    "         \"monkey_train_or_test\":[\"test\"]}\n",
    "    if dset==\"test\":\n",
    "        F[\"monkey_train_or_test\"] = [\"test\"]\n",
    "    elif dset==\"test_G2\":\n",
    "        F[\"taskgroup\"] = [\"G2\"]\n",
    "    elif dset==\"test_G3\":\n",
    "        F[\"taskgroup\"] = [\"G3\"]\n",
    "    else:\n",
    "        print(dset)\n",
    "        assert False\n",
    "    Dtest = D.filterPandas(F, \"dataset\")\n",
    "    print(\"New lenght:\")\n",
    "    print(len(Dtest.Dat))\n",
    "\n",
    "    # Custom savedir based on Filter\n",
    "    SDIR = f\"{SDIR_MAIN}/{D.make_fig_savedir_suffix(F)}\"\n",
    "    print(SDIR)\n",
    "\n",
    "    os.makedirs(SDIR, exist_ok=True)\n",
    "\n",
    "    ####### [EXTRACT FEATURES]\n",
    "    # from pythonlib.tools.vectools import get_angle, angle_diff, unit_vector\n",
    "    feature_list_names = Dtest.extract_beh_features()\n",
    "\n",
    "    if False:\n",
    "        # Seems to mess up downstream code\n",
    "        from math import pi\n",
    "\n",
    "        Dthis = Dtest\n",
    "        # === more complex features\n",
    "        angles_all = Dthis.Dat[\"FEAT_angle_overall\"]\n",
    "        num_angle_bins = 4\n",
    "\n",
    "        # bin angles\n",
    "        bins = np.linspace(0, 2*pi, num_angle_bins+1)\n",
    "        angles_all_binned = [np.digitize(a, bins) for a in angles_all]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(angles_all, angles_all_binned, 'ok')\n",
    "\n",
    "        # assign bin to a label\n",
    "        # binnames = {1: \"L->R\", 2:\"R->L\", 3:\"R->L\", 4:\"L->R\", 5:\"undefined\"}\n",
    "        binnames = {1: 0, 2:1, 3:1, 4:0, 5:np.nan}\n",
    "        angles_named = [binnames[b] for b in angles_all_binned]\n",
    "\n",
    "        # assign back\n",
    "        Dthis.Dat[\"FEAT_angle_overall_named\"] = angles_named\n",
    "\n",
    "        # chekc\n",
    "        Dthis.Dat[\"FEAT_angle_overall_named\"].value_counts()\n",
    "        feature_list_names.append(\"FEAT_angle_overall_named\")\n",
    "\n",
    "    ##### [GROUP INTO DIFFERENT \"MONKEY_PRIOR\" IN FLEXIBLE MANNER]\n",
    "    # --- INPUT\n",
    "    if expt in [\"lines5\"]:\n",
    "        monkey_prior_groupby = [\"epoch\"]\n",
    "        if animal==\"Pancho\":\n",
    "            monkey_prior_levelnames = {\n",
    "                \"[1]\":\"lines\",\n",
    "                \"[2]\":\"L\"}\n",
    "        elif animal==\"Red\":\n",
    "            monkey_prior_levelnames = {\n",
    "                \"[1]\":\"L\",\n",
    "                \"[2]\":\"lines\"}                \n",
    "        else:\n",
    "            assert False\n",
    "    elif expt in [\"biasdir8\"]:\n",
    "        monkey_prior_groupby = [\"block\"]\n",
    "        monkey_prior_levelnames = {\n",
    "            \"[2]\":\"baseline\",\n",
    "            \"[8]\":\"left_to_right\",\n",
    "            \"[14]\":\"right_to_left\"}\n",
    "    elif expt in [\"biasdir3\", \"biasdir4\"]:\n",
    "        monkey_prior_groupby = [\"block\"]\n",
    "        monkey_prior_levelnames = {\n",
    "            \"[2]\":\"baseline\",\n",
    "            \"[5]\":\"left_to_right\",\n",
    "            \"[8]\":\"right_to_left\"}\n",
    "    else:\n",
    "        print(expt)\n",
    "        assert False\n",
    "\n",
    "    # ----- RUN\n",
    "    # 1) Group by monkey prior variables\n",
    "    Dtest.grouping_append_col(monkey_prior_groupby, \"monkey_prior\")\n",
    "    # 2) Rename monkey prior to generic string\n",
    "    from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "    def F(x):\n",
    "        if x[\"monkey_prior\"] in monkey_prior_levelnames.keys():\n",
    "            return monkey_prior_levelnames[x[\"monkey_prior\"]]\n",
    "        else:\n",
    "            print(x[\"monkey_prior\"])\n",
    "            print(monkey_prior_levelnames.keys())\n",
    "            return \"NOT_DEFINED\"\n",
    "    Dtest.Dat = applyFunctionToAllRows(Dtest.Dat, F, \"monkey_prior_name\")\n",
    "    # Make sure all trials have been assigned a name\n",
    "    print(\"-- Final assigment of trials to monkey prior\")\n",
    "    print(Dtest.Dat[\"monkey_prior_name\"].value_counts())\n",
    "    if any(Dtest.Dat[\"monkey_prior_name\"]==\"NOT_DEFINED\"):\n",
    "        assert False\n",
    "\n",
    "    savedir_this = f\"{SDIR}/figures\"\n",
    "    os.makedirs(savedir_this, exist_ok=True)\n",
    "\n",
    "    ######################### [PLOTS]\n",
    "    from pythonlib.tools.pandastools import pivot_table\n",
    "    from pythonlib.tools.vectools import bin_angle_by_direction, angle_diff\n",
    "    from pythonlib.tools.plottools import plotScatter45, histogramMult, rose_plot\n",
    "\n",
    "    # values=[\"FEAT_angle_overall\", \"FEAT_num_strokes\"]\n",
    "    values = feature_list_names\n",
    "    aggfunc_list = [\"mean\"]\n",
    "    group=\"monkey_prior_name\"\n",
    "    if \"biasdir\" in expt:\n",
    "        group_levels = list(monkey_prior_levelnames.values())[1:]\n",
    "    else:\n",
    "        group_levels = list(monkey_prior_levelnames.values())\n",
    "    print(group_levels)\n",
    "    # savedir_this = \"/tmp\"\n",
    "    features_to_ignore = [\"FEAT_angle_overall_named\"]\n",
    "    for aggfunc in aggfunc_list:\n",
    "\n",
    "        if aggfunc==\"mode\":\n",
    "            assert False, \"not coded\"\n",
    "            from scipy.stats import mode\n",
    "            F = lambda x: mode(x)\n",
    "        elif aggfunc==\"rounded_mean\":\n",
    "            F = lambda x: np.round(np.mean(x))\n",
    "        else:\n",
    "            F = lambda x: np.nanmean(x)\n",
    "        df = pivot_table(Dtest.Dat, index=[\"unique_task_name\"], columns=[group], \n",
    "                         values = values, aggfunc=F)\n",
    "\n",
    "        # Remove nans\n",
    "        print(\"Before dropping nan\")\n",
    "        print(len(df))\n",
    "        df = df.dropna()\n",
    "        print(\"After dropping nan\")\n",
    "        print(len(df))\n",
    "\n",
    "\n",
    "        for val in values:\n",
    "            if val in features_to_ignore:\n",
    "                continue\n",
    "            # val = \"val_numstrokes\"\n",
    "\n",
    "            fig, axes = plt.subplots(1,3, figsize=(8, 3))\n",
    "\n",
    "            # SCATTER\n",
    "            ax = axes.flatten()[0]\n",
    "            x1 = df[val][group_levels[0]]\n",
    "            x2 = df[val][group_levels[1]]\n",
    "            plotScatter45(x1, x2, ax, means=True)\n",
    "            ax.set_xlabel(f\"{group_levels[0]}\")\n",
    "            ax.set_ylabel(f\"{group_levels[1]}\")\n",
    "            ax.set_title(val)\n",
    "\n",
    "            # HISTOGRAMS\n",
    "            ax = axes.flatten()[1]\n",
    "            histogramMult([x1, x2], 20, ax=ax)\n",
    "            if savedir_this:\n",
    "                fig.savefig(f\"{savedir_this}/taskagg-scatter_hist-{val}-{aggfunc}.pdf\")\n",
    "\n",
    "            # ANGLES\n",
    "            if val==\"FEAT_angle_overall\":\n",
    "                fig, axes = plt.subplots(1,2, subplot_kw=dict(projection='polar'))\n",
    "\n",
    "                ax = axes.flatten()[0]\n",
    "                rose_plot(ax=ax, angles=x1)\n",
    "                ax.set_title(group_levels[0])\n",
    "\n",
    "                ax = axes.flatten()[1]\n",
    "                rose_plot(ax=ax, angles=x2)\n",
    "                ax.set_title(group_levels[1])\n",
    "                if savedir_this:\n",
    "                    fig.savefig(f\"{savedir_this}/taskagg-angle_rose_plot-{val}-{aggfunc}.pdf\")\n",
    "\n",
    "                # histogram summarizin where l or r.\n",
    "                fig, axes = plt.subplots(1,2, figsize=(8, 3))\n",
    "                ax = axes.flatten()[0]\n",
    "                if False:\n",
    "                    x1 = df[\"FEAT_angle_overall_named\"][group_levels[0]]\n",
    "                    x2 = df[\"FEAT_angle_overall_named\"][group_levels[1]]\n",
    "                    histogramMult([x1, x2], 20, ax=ax)\n",
    "                    if savedir_this:\n",
    "                        fig.savefig(f\"{savedir_this}/taskagg-scatter_hist-{val}-{aggfunc}.pdf\")\n",
    "                x1_dir = bin_angle_by_direction(x1)\n",
    "                x2_dir = bin_angle_by_direction(x2)\n",
    "                histogramMult([x1_dir, x2_dir], 20, ax=ax)\n",
    "                ax.set_xlabel(\"Direction (0=L-->R; 1=R-->L)\")\n",
    "                if savedir_this:\n",
    "                    fig.savefig(f\"{savedir_this}/taskagg-angle_directionsummary-{val}-{aggfunc}.pdf\")\n",
    "\n",
    "    # normalize\n",
    "    def normalize(strokes_vals):\n",
    "        \"\"\" returns same shape as strokes_vals, \n",
    "        but normalized between 0 and 1\"\"\"\n",
    "        # no nan`a\n",
    "        tmp= np.concatenate([x for x in strokes_vals])\n",
    "        tmp = tmp[~np.isnan(tmp)]\n",
    "\n",
    "        xmin = np.percentile(tmp, q=[5])\n",
    "        xmax = np.percentile(tmp, q=[95])\n",
    "        strokes_vals = [(x-xmin)/(xmax-xmin) for x in strokes_vals]\n",
    "        return strokes_vals, xmin, xmax\n",
    "\n",
    "    #### PLOT grid (monkey prior vs unique tasks) - plots one example for each\n",
    "    # Get the tasks showing the strongest effect\n",
    "    # [HERE] getting tasks showing strongest effect, and then plotting those.\n",
    "    var = \"FEAT_circ\"\n",
    "    values = [var]\n",
    "    dfdat = Dtest.Dat\n",
    "    dfdat = dfdat[~dfdat.isna()]\n",
    "    df = pivot_table(dfdat, index=[\"unique_task_name\"], columns=[group], \n",
    "                     values = values)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # get diff\n",
    "    x1 = df[var][group_levels[0]] \n",
    "    x2 = df[var][group_levels[1]]\n",
    "    value_diffs = [angle_diff(xx1, xx2) for xx1, xx2 in zip(x1, x2)]\n",
    "\n",
    "    tmp = [(i, v) for i, v in enumerate(value_diffs)]\n",
    "    inds_sorted = sorted(tmp, key= lambda x: x[1])[::-1]\n",
    "    inds_sorted = [i[0] for i in inds_sorted]\n",
    "    nplot = np.min([10, len(inds_sorted)])\n",
    "    inds_to_plot = inds_sorted[:nplot]\n",
    "\n",
    "    tasklist = df[\"unique_task_name\"].to_list()\n",
    "    tasklist = [tasklist[i] for i in inds_to_plot]\n",
    "\n",
    "    from pythonlib.dataset.plots import plot_beh_grid_grouping_vs_task\n",
    "    row_variable = \"monkey_prior_name\"\n",
    "    for i in range(5):\n",
    "        if expt ==\"lines5\":\n",
    "            # Get normalization function\n",
    "            strokes_list = dfdat[\"strokes_beh\"].values\n",
    "            strokes_circ = [strokeCircularity(strokes) for strokes in strokes_list]\n",
    "            xmin, xmax = normalize(strokes_circ)[1:]\n",
    "            def get_strokes_vals(strokes):\n",
    "                svals = strokeCircularity(strokes)\n",
    "                svals = (svals-xmin)/(xmax-xmin)\n",
    "                svals[np.isnan(svals)] = 0.5 # hack, to fix issue where cant save plot if there is nan.\n",
    "                return svals\n",
    "\n",
    "            def plotfuncbeh(strokes, ax):\n",
    "                svals = get_strokes_vals(strokes)\n",
    "                plotDatStrokesMapColor(strokes, ax, svals, vmin=0, vmax=1.5, cmap=\"jet\", add_stroke_number=False, naked=True)\n",
    "\n",
    "            figb, figt = plot_beh_grid_grouping_vs_task(dfdat, row_variable, tasklist, \n",
    "                                                        plotkwargs={\"strokes_by_order\":True}, plotfuncbeh=plotfuncbeh)\n",
    "        elif \"biasdir\" in expt:\n",
    "            figb, figt = plot_beh_grid_grouping_vs_task(dfdat, row_variable, tasklist, plotkwargs={\"strokes_by_order\":True})\n",
    "        else:\n",
    "            assert False\n",
    "        figb.savefig(f\"{savedir_this}/raw_grids_priorbytask_topKby_{var}_beh_run{i}.pdf\")\n",
    "        figt.savefig(f\"{savedir_this}/raw_grids_priorbytask_topKby_{var}_task_run{i}.pdf\")\n",
    "\n",
    "    # [HERE] plotting random tasks, (not just those with strongests effect as abvove)\n",
    "    for i in range(5):\n",
    "        tasklist = df[\"unique_task_name\"].to_list()\n",
    "        tasklist = random.sample(tasklist, nplot)\n",
    "        if expt ==\"lines5\":\n",
    "            figb, figt = plot_beh_grid_grouping_vs_task(dfdat, row_variable, tasklist, \n",
    "                                                        plotkwargs={\"strokes_by_order\":True}, plotfuncbeh=plotfuncbeh)\n",
    "        elif \"biasdir\" in expt:\n",
    "            figb, figt = plot_beh_grid_grouping_vs_task(dfdat, row_variable, tasklist, plotkwargs={\"strokes_by_order\":True})\n",
    "        else:\n",
    "            assert False\n",
    "        figb.savefig(f\"{savedir_this}/raw_grids_priorbytask_random_beh_run{i}.pdf\")\n",
    "        figt.savefig(f\"{savedir_this}/raw_grids_priorbytask_random_task_run{i}.pdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9435d",
   "metadata": {},
   "source": [
    "#### OLDER STUFF (for timecourses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80720e44",
   "metadata": {},
   "source": [
    "##### Task Model based scoring (ported from somewhere else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exract only fixed tasks\n",
    "if True:\n",
    "    Dthis = D.filterPandas({\"random_task\":[False]}, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889241da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP THIS FOR NOW - needs to assign taskmodel score..\n",
    "\n",
    "# 2) model-based features (task model score)\n",
    "from pythonlib.dataset.dataset_analy.general import taskmodel_assign_score\n",
    "taskmodel_assign_score(Dthis)\n",
    "\n",
    "# model summary score\n",
    "def F(x):\n",
    "    \"\"\"compare two models, retgurns index between -1,1\n",
    "    \"\"\"   \n",
    "    a = x[\"MOD_3line\"]\n",
    "    b = x[\"MOD_linePlusL\"]\n",
    "    return 2*((a/(a+b))-0.5)\n",
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "Dthis.Dat = applyFunctionToAllRows(Dthis.Dat, F, \"modelcomp_offline\")\n",
    "# FEATURE_NAMES = list(set(FEATURE_NAMES+ [\"MOD_3line\", \"MOD_linePlusL\", \"mod2_minus_mod1\", \"modelcomp_offline\"]))\n",
    "FEATURE_NAMES = list(set(FEATURE_NAMES+ [\"MOD_3line\", \"MOD_linePlusL\", \"modelcomp_offline\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3fb004",
   "metadata": {},
   "source": [
    "##### Plots ported directly from taskmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG:\n",
    "# - DONE! basically all ported, and just need to incorporate into simple code below.\n",
    "# - combined with previous histogram plots I started in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.extract_beh_features(FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dthis = D.subsetDataset(range(500))\n",
    "\n",
    "##### Plot timecourse, for each feature\n",
    "# import seaborn as sns\n",
    "# DF = D.Dat\n",
    "# YLIM = [0, 6]\n",
    "# feat = f\"FEAT_{FEATURE_NAMES[1]}\"\n",
    "# row = \"task_stagecategory\"\n",
    "# col= \"taskgroup\"\n",
    "# from pythonlib.tools.snstools import timecourse_overlaid\n",
    "# timecourse_overlaid(DF, feat, row=row, col=col)\n",
    "from pythonlib.dataset.plots import plot_timecourse_overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFthis = D.Dat[:100]\n",
    "YLIM  = None\n",
    "y = \"hdoffline\"\n",
    "ALPHA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### PLOT, one line for each unique task\n",
    "# assert False, \"I done\"\n",
    "\n",
    "# def plotEachUniqueTaskGrouped(DF,  valstoplot, SAVEDIR):\n",
    "#     # === ONE LINE PER UNIQUE TASK\n",
    "#     from pythonlib.tools.pandastools import aggregGeneral\n",
    "#     from pythonlib.tools.pandastools import filterGroupsSoNoGapsInData\n",
    "    \n",
    "#     DF = DF[DF[\"keepforsummary\"]==True]\n",
    "\n",
    "#     # aggregate over unique tasks\n",
    "#     values = valstoplot\n",
    "#     # DFsummary = aggregGeneral(DF, [\"unique_task_name\", \"epoch\", \"taskgroup\"], values, nonnumercols=[\"task_stagecategory\"], aggmethod=[\"median\"])\n",
    "#     # DFsummaryBlock = aggregGeneral(DF, [\"unique_task_name\", \"epoch\", \"block\", \"taskgroup\"], values, nonnumercols=[\"task_stagecategory\"], aggmethod=[\"median\"])\n",
    "#     DFsummary = aggregGeneral(DF, [\"unique_task_name\", \"epoch\", \"taskgroup\"], values, nonnumercols=[\"task_stagecategory\"], aggmethod=[\"mean\"])\n",
    "#     DFsummaryBlock = aggregGeneral(DF, [\"unique_task_name\", \"epoch\", \"block\", \"taskgroup\"], values, nonnumercols=[\"task_stagecategory\"], aggmethod=[\"mean\"])\n",
    "\n",
    "#     # == only keep cases that have data for all epochs.\n",
    "#     values_to_check = list(set(DF[\"epoch\"].values))\n",
    "#     # values_to_check = [1,2] old version, more general is to do the above.\n",
    "#     colname = \"epoch\"\n",
    "#     group = \"unique_task_name\"\n",
    "#     DFsummary = filterGroupsSoNoGapsInData(DFsummary, group, colname, values_to_check)\n",
    "#     DFsummaryBlock = filterGroupsSoNoGapsInData(DFsummaryBlock, group, colname, values_to_check)\n",
    "\n",
    "#     if len(DFsummaryBlock)>0:\n",
    "#         # === PLOT\n",
    "#         for y in values:\n",
    "#             from pythonlib.tools.snstools import relplotOverlaid\n",
    "#             fig = relplotOverlaid(DFsummaryBlock, \"unique_task_name\", \"k\",\n",
    "#                            data=DFsummaryBlock, x=\"block\", y=y, col=\"taskgroup\", row=\"task_stagecategory\", \n",
    "#                     hue=\"unique_task_name\", kind=\"line\")\n",
    "#             fig.savefig(f\"{SAVEDIR}/summarypaired-{y}-groupbyblock-1.pdf\")\n",
    "\n",
    "\n",
    "#             # === separate by blokks\n",
    "#             fig = sns.catplot(data=DFsummaryBlock, x=\"block\", y=y, col=\"taskgroup\", row=\"task_stagecategory\",  \n",
    "#                 kind=\"point\")\n",
    "#             fig.savefig(f\"{SAVEDIR}/summarypaired-{y}-groupbyblock-2.pdf\")\n",
    "\n",
    "#     if len(DFsummary)>0:\n",
    "#         # === PLOT\n",
    "#         for y in values:\n",
    "#             from pythonlib.tools.snstools import relplotOverlaid\n",
    "#             fig = relplotOverlaid(DFsummary, \"unique_task_name\", \"k\",\n",
    "#                            data=DFsummary, x=\"epoch\", y=y, col=\"taskgroup\", row=\"task_stagecategory\", \n",
    "#                     hue=\"unique_task_name\", kind=\"line\")\n",
    "#             fig.savefig(f\"{SAVEDIR}/summarypaired-{y}-1.pdf\")\n",
    "\n",
    "#             fig = sns.catplot(data=DFsummary, x=\"epoch\", y=y, col=\"taskgroup\", row=\"task_stagecategory\",  kind=\"point\")\n",
    "#             fig.savefig(f\"{SAVEDIR}/summarypaired-{y}-2.pdf\")\n",
    "#     else:\n",
    "#         print(\"Skipping\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
