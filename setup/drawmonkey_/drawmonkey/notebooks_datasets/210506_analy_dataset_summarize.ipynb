{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-extraction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:20:28.368870250Z",
     "start_time": "2024-04-22T22:20:28.305559366Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" generically summarize learning-related effects.\n",
    "Here is like a condensed version of the task-scoring plots previously coded (for lines5\n",
    "mainly).\n",
    "Goal here is to simplify, main plots, quicker code (working with datasets)\n",
    "And potentially flexibly combine with models later on.4\n",
    "in epoch 1 and 2)\n",
    "\n",
    "LOGGING PROGRESS FOR PORTING FROM analysis_TEMPLATE (Probedat)\n",
    "- behavior plots: DONE [main useful ones. not yet separate by block. see README.md]\n",
    "- scoring: DONE [except separating by block] \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531f401fc5c663f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:20:28.372695506Z",
     "start_time": "2024-04-22T22:20:28.306551275Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-championship",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:20:28.453140479Z",
     "start_time": "2024-04-22T22:20:28.317143682Z"
    }
   },
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# from tools.utils import * \n",
    "# from tools.plots import *\n",
    "# from tools.analy import *\n",
    "# from tools.calc import *\n",
    "# from tools.analyplot import *\n",
    "# from tools.preprocess import *\n",
    "# from tools.dayanalysis import *\n",
    "\n",
    "from pythonlib.drawmodel.analysis import *\n",
    "from pythonlib.tools.stroketools import *\n",
    "import pythonlib\n",
    "from pythonlib.dataset.dataset import load_dataset_notdaily_helper, load_dataset_daily_helper\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f656b",
   "metadata": {},
   "source": [
    "##### Try loading a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11943dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:21:42.253853196Z",
     "start_time": "2024-04-22T22:20:28.335722479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a daily dataset\n",
    "\n",
    "# animal = \"Diego\"\n",
    "# DATE = \"240523\"\n",
    "\n",
    "# animal = \"Diego\"\n",
    "# DATE = \"230817\"\n",
    "\n",
    "# animal = \"Pancho\"\n",
    "# DATE = \"240523\"\n",
    "\n",
    "# animal = \"Pancho\"\n",
    "# DATE = \"230726\"\n",
    "\n",
    "animal = \"Diego\"\n",
    "DATE = \"240603\"\n",
    "\n",
    "# animal = \"Pancho\"\n",
    "# DATE = \"240524\"\n",
    " \n",
    "D = load_dataset_daily_helper(animal, DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b66589",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.extract_beh_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"FEAT_num_strokes_task\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat.groupby([\"task_kind\", \"FEAT_num_strokes_task\"]).size().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_shapes_extract_unique_alltrials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af547321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether rotated prims got correct \"NOVEL\" shape semantic assignemnet.\n",
    "\n",
    "# - extract tokens\n",
    "df = D.tokens_extract_variables_as_dataframe([\"tforms_extra_exist\", \"shape_semantic\"], \"beh_using_task_data\")\n",
    "df.groupby([\"tforms_extra_exist\", \"shape_semantic\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a120c20",
   "metadata": {},
   "source": [
    "### Mapping from blocks to shape sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g.,, complexvar, or primsingrid (Dolnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495dd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.extract_beh_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import preprocess_dataset_to_datstrokes\n",
    "DS = preprocess_dataset_to_datstrokes(D, \"all_no_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c269a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DS.dataset_append_column(\"block\")\n",
    "DS.dataset_append_column(\"epoch\")\n",
    "DS.dataset_append_column(\"task_kind\")\n",
    "DS.dataset_append_column(\"FEAT_num_strokes_task\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a147f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap, extract_with_levels_of_var_good\n",
    "df, _ = extract_with_levels_of_var_good(DS.Dat, [\"block\"], n_min_per_var=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DS.Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouping_plot_n_samples_conjunction_heatmap(df, \"block\", \"shape\", [\"task_kind\", \"FEAT_num_strokes_task\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouping_plot_n_samples_conjunction_heatmap(df, \"block\", \"shape\", [\"FEAT_num_strokes_task\", \"epoch\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouping_plot_n_samples_conjunction_heatmap(df, \"shape\", \"FEAT_num_strokes_task\", [\"epoch\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouping_plot_n_samples_conjunction_heatmap(df, \"block\", \"shape\", [\"epoch\", \"FEAT_num_strokes_task\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52c49d",
   "metadata": {},
   "source": [
    "# [GOOD] Psycho var, auto detect all kinds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e8afe",
   "metadata": {},
   "source": [
    "##### Older devo here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd352e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get graph represnetation of each char\n",
    "\n",
    "# Extract base prims for each char\n",
    "ind = 403\n",
    "ind2 = 404\n",
    "# D.Dat[\"\"]\n",
    "list_shloc1 = D.taskclass_shapes_loc_configuration_extract(ind, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "list_shloc2 = D.taskclass_shapes_loc_configuration_extract(ind2, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "\n",
    "D.plotMultTrials2([ind, ind2])\n",
    "D.plotMultTrials2([ind, ind2], \"strokes_task\")\n",
    "\n",
    "\n",
    "print(list_shloc1)\n",
    "print(list_shloc2)\n",
    "# 2) Find related chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890aee4",
   "metadata": {},
   "source": [
    "##### Good code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import psychogood_make_task_template_to_find_psycho_variants, psychogood_extract_psycho_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a9b73",
   "metadata": {},
   "source": [
    "##### Helper to write params for each psycho group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7064f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to manually enter params. See psychometric_singleprims for example PARAMS\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a58fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import psychogood_find_tasks_in_this_psycho_group_wrapper_manual_helper\n",
    "example_los_1 = (\"singleprims_psycho\", 8, 37)\n",
    "example_los_2 = (\"singleprims_psycho\", 8, 39)\n",
    "psycho_params_try = {\n",
    "    \"psycho_ver\":\"extra_tforms_each_prim\",\n",
    "    \"idx_prim\": [0,1],\n",
    "    \"tform_key\": \"th\"\n",
    "}\n",
    "\n",
    "psychogood_find_tasks_in_this_psycho_group_wrapper_manual_helper(D, example_los_1, example_los_2, psycho_params_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it here\n",
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import psychogood_find_tasks_in_this_psycho_group_wrapper\n",
    "los_within = (\"singleprims_psycho\", 5, 19)\n",
    "psycho_params = {\n",
    "    \"psycho_ver\":\"extra_tforms_each_prim\",\n",
    "    \"idx_prim\": 0, # the substroke index\n",
    "    \"tform_key\": \"sx\" # scale x\n",
    "}\n",
    "\n",
    "dfres_within = psychogood_find_tasks_in_this_psycho_group_wrapper(D, los_within, psycho_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3c049",
   "metadata": {},
   "source": [
    "##### Run here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c412105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import psychogood_preprocess_wrapper\n",
    "\n",
    "DFRES, PARAMS, los_allowed_to_miss = psychogood_preprocess_wrapper(D, PLOT=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07491316",
   "metadata": {},
   "source": [
    "# Debugging (prims in grid analy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.prims_in_grid import preprocess_dataset\n",
    "preprocess_dataset(D, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.seqcontext_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"seqc_0_shape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_shapes_loc_configuration_assign_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc23737",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"taskconfig_shp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.extract_beh_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.snstools import rotateLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import stringify_values\n",
    "df = stringify_values(D.Dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d467fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = sns.catplot(data=df, x=\"taskconfig_shp\", y=\"seqc_0_loc\", col=\"taskconfig_loc\", alpha=0.1)\n",
    "fig = sns.catplot(data=df, x=\"taskconfig_shp\", y=\"seqc_0_loc\", col=\"taskconfig_loc\", kind=\"violin\")\n",
    "\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap\n",
    "fig = grouping_plot_n_samples_conjunction_heatmap(df, \"seqc_0_loc\", \"taskconfig_shp\", [\"taskconfig_loc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import plot_subplots_heatmap\n",
    "plot_subplots_heatmap(df, \"seqc_0_loc\", \"taskconfig_shp\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc963b53",
   "metadata": {},
   "source": [
    "# Microstim (single prims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ecd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.microstim import plot_all_wrapper\n",
    "plot_all_wrapper(D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d56380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a08260ef6d32b239",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Clustering angle onsets (circular cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novel prims, structured morphing (e..g,, enlongate one arm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05652bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.extra_tform_params_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = D.Dat.iloc[100][\"Task\"]\n",
    "T.check_prims_extra_params_exist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D.taskclass_extract_prims_extra_params_tforms(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23683e2",
   "metadata": {},
   "source": [
    "# Check if prim is base prim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c62576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5875c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches shape semantic\n",
    "# no extra tforms or morphs\n",
    "# matches a base prim from database\n",
    "\n",
    "D.shapesemantic_classify_novel_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52fed5",
   "metadata": {},
   "source": [
    "# Novel prims, continuosu morphing between a pair of prims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c725f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import preprocess_structured_morph\n",
    "DS, DSmorphsets, map_morph_set_idx_to_shapes, map_shape_to_base_prims, map_base_prims_to_morphed_shape, SAVEDIR = preprocess_structured_morph(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import plot_overview_structured_morph\n",
    "\n",
    "plot_overview_structured_morph(D, DS, DSmorphsets, map_morph_set_idx_to_shapes, SAVEDIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225152a2",
   "metadata": {},
   "source": [
    "# Novel prims (psychometric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.extract_beh_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e85494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of num task strokes\n",
    "D.Dat[\"FEAT_num_strokes_task\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_shapes_extract_unique_alltrials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa12d4",
   "metadata": {},
   "source": [
    "##### Redefine prims based on the entire task (character), for cases where single prims are actually constructed using multiple subsegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10401445",
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a567b",
   "metadata": {},
   "source": [
    "\n",
    "##### Run novel prims analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously was for luca 230508_analy_primitiveness...\n",
    "from pythonlib.dataset.dataset_analy.novel_singleprims import preprocess_and_plot\n",
    "\n",
    "# plot_methods = (\"tls\",)\n",
    "# DS, SAVEDIR, dfres, grouping = preprocess_and_plot(D, PLOT=True, plot_methods=plot_methods)\n",
    "DS, SAVEDIR, dfres, grouping = preprocess_and_plot(D, PLOT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onset angle, variability\n",
    "DS.Dat[\"angle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b723548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfthis = DS.Dat\n",
    "dfthis = dfthis.sort_values(\"shape_is_novel\")\n",
    "fig = sns.catplot(data=dfthis, x=\"shape\", y=\"angle\", hue=\"shape_is_novel\", aspect=3, alpha=0.4)\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b921df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.shapesemantic_label_and_novel_append()\n",
    "DS.distgood_compute_beh_task_strok_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c186cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.Dat[\"stroke_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e821114",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfthis = DS.Dat\n",
    "dfthis = dfthis.sort_values(\"shape_is_novel\")\n",
    "fig = sns.catplot(data=dfthis, x=\"shape\", y=\"angle\", hue=\"gridloc\", aspect=3, alpha=0.4)\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84708e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfthis = DS.Dat\n",
    "dfthis = dfthis.sort_values(\"shape_is_novel\")\n",
    "fig = sns.catplot(data=dfthis, x=\"shape\", y=\"dist_beh_task_strok\", hue=\"gridloc\", aspect=4, alpha=0.4, height=3)\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857b0ef",
   "metadata": {},
   "source": [
    "# Psychometric single prim - rotated shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651753b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_psycho = \"angle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bfb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, for each token, extract variables that reflect the psycho variable/param.\n",
    "token_ver = \"task\"\n",
    "for i, row in D.Dat.iterrows():\n",
    "    # for each shape get its concrete params\n",
    "    Tk = D.taskclass_tokens_extract_wrapper(i, token_ver, return_as_tokensclass=True)\n",
    "    Tk.features_extract_wrapper([\"loc_on\", \"angle\"], angle_twind=[0, 2])\n",
    "df = D.tokens_extract_variables_as_dataframe([\"shape\", \"loc_on\", \"angle\", \"Prim\", \"gridloc\"], token_ver)\n",
    "\n",
    "# Extract the original shape, which should have been overwritten in rprepovessing, but is useufl as a category\n",
    "# to anchor the variations.\n",
    "list_shape_orig = []\n",
    "for P in df[\"Prim\"]:\n",
    "    list_shape_orig.append(P.shape_oriented())\n",
    "df[\"shape_orig\"] = list_shape_orig\n",
    "\n",
    "# For each shape_orig, get an ordered indices for angle. m\n",
    "col = var_psycho\n",
    "var_psycho_unique = f\"{var_psycho}_unique\"\n",
    "var_psycho_str = f\"{var_psycho}_str\"\n",
    "var_psycho_idx = f\"{var_psycho}_idx_within_shapeorig\"\n",
    "\n",
    "unique_values, indices, map_index_to_value = find_unique_values_with_indices(df, col, \n",
    "    append_column_with_unique_values_colname=var_psycho_unique)\n",
    "df[var_psycho_str] = [f\"{a:.2f}\" for a in df[f\"{var_psycho}_unique\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all shapes which dont have extra tform\n",
    "base_shapes = []\n",
    "for ind in range(len(D.Dat)):\n",
    "    tforms = D.taskclass_extract_prims_extra_params_tforms(ind)\n",
    "    tform_first_stroke = tforms[0]\n",
    "    if len(tform_first_stroke)==0:\n",
    "        base_shapes.append(D.taskclass_shapes_extract(ind)[0])\n",
    "base_shapes = list(set(base_shapes))\n",
    "\n",
    "df[\"is_base_shape\"] = df[\"shape\"].isin(base_shapes)\n",
    "\n",
    "# For each shape_orig, find its one base shape\n",
    "from pythonlib.tools.pandastools import find_unique_values_with_indices\n",
    "\n",
    "map_shape_orig_to_angle_base = {}\n",
    "for grp in df.groupby([\"shape_orig\"]):\n",
    "    shape_orig = grp[0][0]\n",
    "    dfthis = df[(df[\"shape_orig\"] == shape_orig) & (df[\"is_base_shape\"]==True)]\n",
    "    dfthis = grp[1][(grp[1][\"is_base_shape\"]==True)]\n",
    "\n",
    "    # angle_base = dfthis[\"angle\"].unique()\n",
    "    # angle_base\n",
    "    unique_values, _, _ = find_unique_values_with_indices(dfthis, \"angle\")\n",
    "    assert len(unique_values)==1, \"This means there are multiple trials without tform, which are thus called base prims, for this shape_orig\"\n",
    "\n",
    "    angle_base = unique_values[0]\n",
    "\n",
    "    map_shape_orig_to_angle_base[shape_orig] = angle_base\n",
    "\n",
    "# Map the base angle to each shape_orig\n",
    "df[\"angle_base\"] = df[\"shape_orig\"].map(map_shape_orig_to_angle_base)\n",
    "\n",
    "# Calculate the relative angle\n",
    "df[\"angle_rel_base\"] = df[\"angle\"] - df[\"angle_base\"]\n",
    "\n",
    "# Adjust angles that are negative\n",
    "df.loc[df[\"angle_rel_base\"] < 0, \"angle_rel_base\"] += 2 * pi\n",
    "col_psycho_index = f\"{var_psycho}_rel_base\"\n",
    "unique_values, indices, map_index_to_value = find_unique_values_with_indices(df, col_psycho_index, \n",
    "    append_column_with_unique_values_colname=var_psycho_unique)\n",
    "df[var_psycho_str] = [f\"{a:.2f}\" for a in df[f\"{var_psycho}_unique\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af58f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import preprocess, plot_overview, preprocess_and_plot\n",
    "\n",
    "# GOOD - wrapper\n",
    "preprocess_and_plot(D, \"angle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.psychometric_singleprims import preprocess, plot_overview, preprocess_and_plot\n",
    "\n",
    "# GOOD - wrapper\n",
    "preprocess_and_plot(D, \"angle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ff798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.plotshape_multshapes_egstrokes(n_examples_total_per_shape=10, ver_behtask=\"task\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd32d7c",
   "metadata": {},
   "source": [
    "### Novel prims, only keep if has consistent motor across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import preprocess_dataset_to_datstrokes\n",
    "DS = preprocess_dataset_to_datstrokes(D, version=\"all_no_clean\")\n",
    "# DS = preprocess_dataset_to_datstrokes(D, version=\"singleprim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_savedir = \"/tmp/Diego-240516\"\n",
    "os.makedirs(plot_savedir)\n",
    "# shapes_good, shapes_bad, map_shape_to_list_aligns, dfres, MIN_FRAC_ALIGNED, MIN_SELFSIM_SCORE= DS.clean_shapes_strokes_aligned_consistantly(plot_savedir=plot_savedir,\n",
    "#                                              use_min_learned_shapes_to_set_min_selfsim_score=True)\n",
    "\n",
    "shapes_good, shapes_bad, map_shape_to_list_aligns, dfres, MIN_FRAC_ALIGNED, MIN_SELFSIM_SCORE= DS.clean_shapes_strokes_aligned_consistantly_novel_prims(plot_savedir=plot_savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.expttools import writeStringsToFile, writeDictToTxtFlattened\n",
    "\n",
    "plot_savedir = \"/tmp\"\n",
    "writeStringsToFile(f\"{plot_savedir}/shapes_good.txt\", shapes_good)\n",
    "writeStringsToFile(f\"{plot_savedir}/shapes_bad.txt\", shapes_bad)\n",
    "\n",
    "writeDictToTxtFlattened({\n",
    "    \"map_shape_to_list_aligns\":map_shape_to_list_aligns,\n",
    "    \"MIN_FRAC_ALIGNED\":MIN_FRAC_ALIGNED,\n",
    "    \"MIN_SELFSIM_SCORE\":MIN_SELFSIM_SCORE\n",
    "}, f\"{plot_savedir}/params.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SELFSIM_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"sdafsadfdsafdsafdsafsdaf2314-8943  \"\n",
    "sum([ord(ss) for ss in s])\n",
    "np.product([ord(ss) for ss in s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.product([ord(ss) for ss in s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.product(np.diff([ord(ss) for ss in s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bfb02",
   "metadata": {},
   "source": [
    "##### Plot the good and bad shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24227d6d563ee4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b864b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9f3cd7ead5974",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.taskclass_tokens_extract_wrapper(1, \"beh_using_beh_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e9a08ca7feb41",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.taskclass_tokens_extract_wrapper(1, \"beh_using_task_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2617f0c2e59e4c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Tk = D.taskclass_tokens_extract_wrapper(100, \"beh_using_beh_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb223915cb2f43",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.tokens_generate_replacement_clear_derived_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3bc05fb8d751e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import params_getter_raster_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94314ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a main dataset\n",
    "animal = \"Diego\"\n",
    "expt = \"gridlinecircleGOOD\"\n",
    "rulelist = None\n",
    "D = load_dataset(animal, expt, rulelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc05223d8ba8d42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dc = D.copy()\n",
    "Dc.preprocessGood(params=[\"no_supervision\"])\n",
    "# Dc.Dat = Dc.Dat[(Dc.Dat[\"supervision_online\"]==False) | (Dc.Dat[\"superv_COLOR_METHOD\"]==\"solid_sequence_mask\")].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651b00daedcf435",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56b6c8f06de769",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3dc232a665138a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.preprocessGood(params=[\"sanity_gridloc_identical\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9a3f48fa6c1a5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.taskclass_shapes_loc_configuration_extract(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89e5febf2d57eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff3960ae13a20d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epoch_superv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33a111729ad3e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[col for col in D.Dat.columns.tolist() if \"superv\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11931e8e39192808",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grouping_print_conjunctions_summary_good([\"epochtest\", \"epoch_superv\", \"supervision_online\", \"supervision_stage_new\", \"superv_SEQUENCE_SUP\", \"superv_COLOR_METHOD\", \"INSTRUCTION_COLOR\"], PRINT=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7a82f",
   "metadata": {},
   "source": [
    "# Substrokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load substrokes (previously computed and saved)\n",
    "from pythonlib.dataset.substrokes import load_presaved_using_pipeline\n",
    "DSsubs, Dsubs = load_presaved_using_pipeline(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"INSTRUCTION_COLOR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract/compute features of each substroke\n",
    "from pythonlib.dataset.substrokes import features_motor_extract_and_bin\n",
    "SAVEDIR = D.make_savedir_for_analysis_figures_BETTER(\"substrokes_preprocess\")\n",
    "plot_save_dir = f\"{SAVEDIR}/plots_during_anova_params\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)\n",
    "\n",
    "# Extract motor variables (DS)\n",
    "features_motor_extract_and_bin(DSsubs, plot_save_dir=plot_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda91f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.substrokes import features_motor_extract_and_bin\n",
    "assert params[\"datasetstrokes_extract_to_prune_stroke_and_get_features\"] is None, \"they would overwrite each other\"\n",
    "\n",
    "# Save in substrokes preprocess folder.\n",
    "if save_substroke_preprocess_figures: # Takes too long\n",
    "    SAVEDIR = D.make_savedir_for_analysis_figures_BETTER(\"substrokes_preprocess\")\n",
    "    plot_save_dir = f\"{SAVEDIR}/plots_during_anova_params\"\n",
    "    os.makedirs(plot_save_dir, exist_ok=True)\n",
    "else:\n",
    "    plot_save_dir = None\n",
    "\n",
    "# from pythonlib.tools.expttools import writeDictToTxt\n",
    "\n",
    "# Extract motor variables (DS)\n",
    "features_motor_extract_and_bin(DS, plot_save_dir=plot_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ade96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de753082d1b99e63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [NEURAL] Apply dataset preprocess (As in Snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65c5a6892e64c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dc.grammarparses_syntax_role_append_to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1230a8eb5f12175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:25:06.713866337Z",
     "start_time": "2024-04-22T22:21:42.223799416Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import dataset_apply_params\n",
    "\n",
    "DS = None\n",
    "# ANALY_VER = \"singleprim\"\n",
    "# ANALY_VER = \"rulesw\"\n",
    "ANALY_VER = \"rulesingle\"\n",
    "# ANALY_VER = \"charstrokes\"\n",
    "animal = D.animals()[0]\n",
    "date = D.dates()[0]\n",
    "Dc = D.copy()\n",
    "Dc, DS, params = dataset_apply_params(Dc, DS, ANALY_VER, animal, date) # prune it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76065799e5ad762e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.snippets import datasetstrokes_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73659f6aa014f3b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS = datasetstrokes_extract(D, \"all_no_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3d981f6410545",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"CTXT_locoffclust_next\" in DS.Dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dbe941d5bdf5d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.tokens_cluster_touch_onset_loc_across_all_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f64710900120de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = Dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3675020890bdc41",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.supervision_epochs_extract_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1084cc40abe57",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epoch_orig\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b05235ed14181",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rulestrings_exist_in_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a817a08910a01b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rules_extract_info()[\"ruledict_for_each_rule\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865877a6d05f53a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Auto get params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ecf2fe9e10961",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epoch_orig\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce5310fd6ca92f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9eaa08a6a7727",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"syntax_concrete\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb71f7aa420ca4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# D.grammarparses_syntax_concrete_append_column()\n",
    "# \n",
    "# # For each sequence kind (e.g. shapes) split into concrete variations (classes).\n",
    "# # savedir_preprocess = D.make_savedir_for_analysis_figures_BETTER(\"preprocess_general\")\n",
    "# savedir_preprocess = \"/tmp\"\n",
    "# sdir = f\"{savedir_preprocess}/seqcontext_behorder_cluster_concrete_variation\"\n",
    "# os.makedirs(sdir, exist_ok=True)\n",
    "# D.seqcontext_behorder_cluster_concrete_variation(SAVEDIR=sdir,\n",
    "#                                  LIST_VAR_BEHORDER=[\"behseq_shapes\", \"behseq_locs\",\n",
    "#                                                     \"behseq_locs_x\", \"behseq_locs_diff\", \"behseq_locs_diff_x\"])\n",
    "# \n",
    "# # Add column \"epoch_rand\", which collects random + color instruction\n",
    "# print(\" *** RUNNING: grammarparses_rules_random_sequence()\")\n",
    "# D.grammarparses_rules_random_sequence(PRINT=True)\n",
    "\n",
    "# Further bin trials based on variation in gap duration --> longer gaps means difference in preSMA state space?\n",
    "sdir = f\"{savedir_preprocess}/grammarparses_chunk_transitions_gaps_extract_batch\"\n",
    "os.makedirs(sdir, exist_ok=True)\n",
    "D.grammarparses_chunk_transitions_gaps_extract_batch(plot_savedir=sdir)\n",
    "\n",
    "# For each token, assign a new key called \"syntax role\" -- good.\n",
    "D.grammarparses_syntax_role_append_to_tokens()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb33097a13d21f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_syntax_epochset_quick_classify_same_diff_motor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a49854edecc60",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epochset\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9534742718e1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grouping_print_conjunctions_summary_good([\"epochset\", \"epochset_diff_motor\"], PRINT=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e6206730fd38b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Clustering loc and shape variations (behseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd5c56d98fbb7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LIST_VAR_BEHORDER = [\"behseq_shapes\", \"behseq_locs\", \"behseq_locs_diff\"]\n",
    "Dc.seqcontext_behseq_cluster_concrete_variation(SAVEDIR=\"/tmp\", LIST_VAR_BEHORDER=LIST_VAR_BEHORDER, groupby=\"FEAT_num_strokes_task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f83d8cc1b52528",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dc.seqcontext_extract_locations_in_beh_order_append_column(x_or_y_only=None, colname=\"behseq_locs\", abbrev_string_code=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf078a1aa8ae0b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Dc.Dat[\"behseq_locs\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa0e99deee7de9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Dc.Dat[\"behseq_locs\"].value_counts().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899c4282b0a0df2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "len(x)/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628aa87715a936e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dd20e690db9e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065e407e5060ee1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(x[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420a8170c348ce3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1b91704523fea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_n_clust = len(Dc.Dat)/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa92c564dd4afcd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Dc.Dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ebc602acb4a0d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Good, generalized, definitions of syntax role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef3e8deff475bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"syntax_concrete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79badb00d1ec7ca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_syntax_role_append_to_tokens()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9f81ed6be72c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad7ec4921b0a5b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e0aadbb5f0f5d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import preprocess_dataset_to_datstrokes\n",
    "DS = preprocess_dataset_to_datstrokes(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382a0824af7dd18",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.print_n_samples_per_combo_grouping([\"epoch\", \"syntax_role\", \"chunk_rank\", \"shape\", \"chunk_within_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45ed518cfb92ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = Dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a525f111d2b1284",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### New way to define epochset that is less messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45922c7dd024313f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.epochset_extract_matching_motor_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a681e3f1a9fd615c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### QUick assessment of good extraction of rule/grammar based infomration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf1de656671f0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epoch_orig_rand_seq\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bb779862a4cb4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rules_extract_info()[\"ruledict_for_each_rule\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543702911b5f7fb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rules_random_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf64ca4836dbee6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rules_shape_AnBmCk() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6110ed0372203",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "D.supervision_reassign_epoch_rule_by_sequence_mask_supervision()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d31ed5ec01bc7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape_rules = D.grammarparses_rules_involving_shapes(return_as_epoch_orig=True)\n",
    "\n",
    "D.Dat[\"INSTRUCTION_COLOR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be621851df103e7d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rules_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46de11ac6716443",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epochset\"] = D.Dat[\"epochset_shape\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f037f8e97046e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_rules_epochs_superv_summarize_wrapper(PRINT=True, include_epochset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44bce8925ee0b8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items\n",
    "# Get trials under each epoch\n",
    "vars = [\"epoch\", \"epoch_orig\", \"epoch_rand\", \"INSTRUCTION_COLOR\", \"epoch_orig_rand_seq\", \"epoch_is_AnBmCk\"]\n",
    "grpdict = D.grouping_print_conjunctions_summary_good(vars, PRINT=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce506e0c620b5a79",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items\n",
    "# Get trials under each epoch\n",
    "vars = [\"epochset\", \"epoch\", \"epoch_orig\", \"INSTRUCTION_COLOR\", \"epoch_rand\", \"epoch_is_AnBmCk\"]\n",
    "grpdict = D.grouping_print_conjunctions_summary_good(vars, PRINT=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989db676e503e66",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items\n",
    "# Get trials under each epoch\n",
    "vars = [\"epoch_rand\"]\n",
    "grpdict = D.grouping_print_conjunctions_summary_good(vars, PRINT=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8289487df89eae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.extract_beh_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47689fc8e95a2aae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"syntax_concrete\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1f18bcdfe9e14",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"syntax_concrete\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396dcdc750091d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get trials under each epoch\n",
    "vars = [\"taskcat_by_rule\", \"syntax_concrete\", \"epoch\"]\n",
    "grpdict = D.grouping_print_conjunctions_summary_good(vars, PRINT=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543ea204b24693e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get trials under each epoch\n",
    "vars = [\"epochset\", \"epoch\", \"FEAT_num_strokes_task\", \"taskcat_by_rule\", \"syntax_concrete\"]\n",
    "grpdict = D.grouping_print_conjunctions_summary_good(vars, PRINT=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63997a0b54d3cc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot an example trial for each epoch\n",
    "grpdict = D.grouping_get_inner_items(\"epoch\")\n",
    "for grp, inds in grpdict.items():\n",
    "    print(\" ++++++++++++++++++++++ \", grp, len(inds))\n",
    "    ind = inds[0]\n",
    "    D.grammarparses_print_plot_summarize(ind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9d0fb04295c78",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Good -- checking individual trials, taskcat_by_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843b7bdea0eec21",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecccaf117e1fa77",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick a single trial, and print and plot it here\n",
    "ind = 10\n",
    "D.grammarparses_print_plot_summarize(ind)\n",
    "# GD = D.grammarparses_grammardict_return(ind, True)\n",
    "# GD.ParsesGenerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf74340cce15439",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GD.ChunksListClassAll = {}\n",
    "GD.ParsesGenerated = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cfb1638e7f943",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GD.parses_generate(\"ss-rank-ZlA1\", DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e433b644be9a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"taskcat_by_rule\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2448fd39c4e334",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each taskcat_by_rule, split into extremes based on low-level features.\n",
    "# - ie based on either locaiton or shape or direction of transitions.\n",
    "# - to do so, first clasify each trial by shape, loc, and direction seuqence. \n",
    "# - then split into extremes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3fa8d4733fd86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.seqcontext_behorder_cluster_concrete_variation(SAVEDIR=\"/tmp\", LIST_VAR_BEHORDER=[\"behseq_shapes\", \"behseq_locs\", \n",
    "                                                                                    \"behseq_locs_x\", \"behseq_locs_diff\", \"behseq_locs_diff_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567e7eadafffd8d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"behseq_locs_clust\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6e873068ab798",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(self.Dat[f\"{var_behorder}_clust\"].isin([\"empty\"]))==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cebe2d8a23ba15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Breaking out all the steps in grammar parses chunks extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e35691f1471bd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.preprocessGood(params=[\"one_to_one_beh_task_strokes\", \"correct_sequencing_binary_score\"])\n",
    "\n",
    "D.grammarparses_successbinary_score_wrapper()\n",
    "for i in range(len(D.Dat)):\n",
    "    D.grammarparses_taskclass_tokens_assign_chunk_state_each_stroke(i)\n",
    "\n",
    "D.grammarparses_classify_tasks_categorize_based_on_rule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4b774661efff6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Random string (randstr) using color_rank --> combine into a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ab670ff0e058b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_epochorig_to_israndseq = D.grammarparses_rules_random_sequence(PRINT=True)\n",
    "map_epochorig_to_israndseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c8d7a3505879",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vars = [\"epoch_orig_rand_seq\", \"INSTRUCTION_COLOR\", \"epoch_orig\", \"epoch\"]\n",
    "grpdict = D.grouping_print_conjunctions_summary_good(vars, PRINT=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5a39141231ea8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch_orig in D.Dat[\"epoch_orig\"].unique():\n",
    "    print(epoch_orig, \" -- \", ruledict_for_each_rule[epoch_orig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79458f5bfad38a52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"epoch\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46582cac316e8323",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Timing between and across chunks, grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5329419579784",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. get gap durations\n",
    "strokes = []\n",
    "gaps = []\n",
    "for i in range(len(D.Dat)):\n",
    "    stroke_durations, gap_durations = D.strokes_durations_gaps(i)\n",
    "    strokes.append(tuple(stroke_durations))\n",
    "    gaps.append(tuple(gap_durations))\n",
    "D.Dat[\"durations_strokes\"] = strokes\n",
    "D.Dat[\"durations_gaps\"] = gaps\n",
    "    \n",
    "# 2. determine if gaps are between chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591858b712ad428",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(grpdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b465ed08d48e75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf01e388770ab84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syntax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85434f5bdedb2e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var = \"behseq_locs_diff_x\" \n",
    "grpdict = D.grouping_print_conjunctions_summary_good([\"epoch\", \"taskcat_by_rule\", var], n_min=3)\n",
    "# grpdict = D.grouping_print_conjunctions_summary_good([\"epoch\", \"taskcat_by_rule\"], n_min=5)\n",
    "\n",
    "PLOT_EACH_TRIAL = True\n",
    "ncols = 4\n",
    "SIZE = 4\n",
    "nrows = int(np.ceil(len(grpdict)/ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize = (ncols*SIZE, nrows*SIZE), sharex=False, sharey=False)\n",
    "for ax, (grp, inds) in zip(axes.flatten(), grpdict.items()):\n",
    "    gaps = np.stack(D.Dat.iloc[inds][\"durations_gaps\"])\n",
    "    x = range(gaps.shape[1])\n",
    "    # fig, ax = plt.subplots()\n",
    "    if PLOT_EACH_TRIAL:\n",
    "        for g in gaps:\n",
    "            ax.plot(x, g, \"-ok\", alpha=0.1)\n",
    "    # overlay mean\n",
    "    ymean = np.mean(gaps,axis=0)\n",
    "    ax.plot(x, ymean, \"-sr\", alpha=1, linewidth=2)\n",
    "        \n",
    "    # annotate x axis with sahpe labels\n",
    "    syntax = grp[1][0]\n",
    "    shape_labels = [\"A\" for _ in range(syntax[0])] + [\"B\" for _ in range(syntax[1])] + [\"C\" for _ in range(syntax[2])]\n",
    "    xcoords = np.arange(len(shape_labels))\n",
    "    xcoords = xcoords - 0.5\n",
    "    ax.set_xticks(xcoords, labels=shape_labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ax.axhline(0)    \n",
    "    ax.set_title(grp, fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605b7352247d68f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Classify trials into \"fast\" and \"slow\" in transitioning across chunk gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a5f3e454f2e55",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_syntax_concrete_append_column()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3696ef97a95dfc7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_classify_tasks_syntax_based_on_rule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92697967e0b8c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_epoch_orig_to_list_syntax = D.grammarparses_classify_tasks_syntax_based_on_rule()\n",
    "map_epoch_orig_to_list_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41215c0851fcb78e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"syntax_concrete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975770fe277def45",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"taskcat_by_rule\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd87a9ca792a450",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfgaps = D.grammarparses_chunk_transitions_gaps_extract_batch(plot_savedir=\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ba1647f25e343",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars\n",
    "plot_savedir = \"/tmp\"\n",
    "dfgaps_this, dict_dfthis = extract_with_levels_of_conjunction_vars(dfgaps, \"gap_dur_bin\", [\"epoch\", \"behseq_locs\", \"behseq_shapes\"],\n",
    "                        n_min_across_all_levs_var=2, lenient_allow_data_if_has_n_levels=2,\n",
    "                        prune_levels_with_low_n=True, plot_counts_heatmap_savepath=f\"{plot_savedir}/epoch-behseq_locs_behseq_shapes-counts.pdf\")\n",
    "fig = sns.catplot(data=dfgaps_this, x=\"index_gap\", y=\"gap_dur\", col=\"ep_sy_sh_lo\", col_wrap=4, alpha=0.4,\n",
    "            hue=\"gap_dur_bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766dfb22bfd5fada",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfgaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85c4e5132ec498",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "grpdict = grouping_append_and_return_inner_items_good(dfgaps, [\"epoch\", \"syntax\", \"behseq_shapes\", \"behseq_locs\", \"index_gap\"])\n",
    "for grp, inds in grpdict.items():\n",
    "    print(grp, len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d7ed8c83533c2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=dfgaps, x=\"gap_chunk_rank_str\", y=\"gap_dur\", hue=\"gap_dur_bin\", col=\"epoch\", \n",
    "            col_wrap=5, alpha=0.2)\n",
    "\n",
    "sns.catplot(data=dfgaps, x=\"gap_chunk_rank_str\", y=\"gap_dur\", hue=\"gap_dur_bin\", col=\"epoch\", \n",
    "            col_wrap=5, kind=\"point\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113d022052c4b18",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "##### AnBm vs. DIRECTIOn - Slower during chunk transitions, if it is early in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246edbe25d8f91a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_dfthis.keys()\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars\n",
    "dfgaps_this, dict_dfthis = extract_with_levels_of_conjunction_vars(dfgaps, \"epoch\", [\"behseq_locs\", \"behseq_shapes\"], \n",
    "                                        n_min_across_all_levs_var=3, lenient_allow_data_if_has_n_levels=2,\n",
    "                                        prune_levels_with_low_n=True, plot_counts_heatmap_savepath=\"/tmp/test.pdf\")\n",
    "# sns.catplot(data=dfgaps_this, x=\"index_gap\", y=\"gap_dur\", hue=\"epoch\", col=\"sh_lo\", col_wrap=5, height=4)\n",
    "sns.catplot(data=dfgaps_this, x=\"index_gap\", y=\"gap_dur\", hue=\"epoch\", col=\"syntax\", col_wrap=5, height=4)\n",
    "sns.catplot(data=dfgaps_this, x=\"index_gap\", y=\"gap_dur\", hue=\"epoch\", col=\"syntax\", col_wrap=5, height=4,\n",
    "            kind=\"point\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7feeda428241b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Chunk gaps are slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5abd87df96ef27",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Various plots\n",
    "\n",
    "# 1) Are chunk gaps slower?\n",
    "sns.catplot(data=dfgaps, x=\"gap_chunk_rank_str\", y=\"gap_dur\", hue=\"gap_dur_bin\", col=\"epoch_syntax\", \n",
    "            col_wrap=5, alpha=0.1)\n",
    "sns.catplot(data=dfgaps, x=\"gap_chunk_rank_str\", y=\"gap_dur\", hue=\"gap_dur_bin\", col=\"epoch_syntax\", \n",
    "            col_wrap=5, kind=\"point\")\n",
    "\n",
    "# sns.catplot(data=dfgaps, x=\"ep_sy_sh_lo\", y=\"gap_dur\", hue=\"gap_chunk_rank_str\", col=\"gap_dur_bin\", \n",
    "#             col_wrap=5, alpha=0.1)\n",
    "\n",
    "# sns.catplot(data=dfgaps, x=\"ep_sy_sh_lo\", y=\"gap_dur\", hue=\"gap_dur_bin\", col=\"gap_chunk_rank_str\", \n",
    "#             col_wrap=5, kind=\"point\", aspect=2)\n",
    "\n",
    "\n",
    "# sns.catplot(data=dfgaps, x=\"gap_chunk_rank_str\", y=\"gap_dur\", hue=\"epoch\", kind=\"point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a037351eb847f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Assign back to D.Dat --> whether chunk transition is slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc427ca77970cec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Grammar - chunks, chunk_rank, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7cc48322be680",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Etract, for each trial, its sequence of tokens (e.g., AAABBB...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2e418f878073a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This should be sequence of shapes, not of chunk_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff31e9183620b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.modeling.discrete import tasks_categorize_based_on_rule_mult\n",
    "tasks_categorize_based_on_rule_mult(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525dfc00c2fa44ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"taskcat_by_rule\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7cdaa56b9201f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grpdict = D.grouping_get_inner_items(\"taskcat_by_rule\")\n",
    "for grp, inds in grpdict.items():\n",
    "    print(grp, \" === \",  inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32709dc9cac78250",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_print_plot_summarize(37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e48ec7af18f90",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### For (AB)n, with order not prescribed (can do AB or BA), classify beh based on order taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b54f0ed0b1a29e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 100\n",
    "shapes = D.seqcontext_extract_shapes_in_beh_order(i, abbrev_string_code=True)\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c88408061ec76",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.seqcontext_extract_shapes_in_beh_order_append_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5eca8700774bea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"behseq_shapes\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc11a0153a2b09",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### RUle switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72229ff00a458d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_successbinary_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a207d9bd4f15c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import dataset_apply_params\n",
    "\n",
    "DS = None\n",
    "ANALY_VER = \"rulesw\"\n",
    "animal = D.animals()[0]\n",
    "date = D.dates()[0]\n",
    "D, DS, params = dataset_apply_params(D, DS, ANALY_VER, animal, date) # prune it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2b5c4d2de8cf1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.Dat[\"taskcat_by_rule\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445f09ece87ed6b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_classify_tasks_categorize_based_on_rule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f4321350eaa60",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9cf3e38194957",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "grpdict = grouping_append_and_return_inner_items_good(D.Dat, [\"epoch_color\", \"taskcat_by_rule\"])\n",
    "for grp, inds in grpdict.items():\n",
    "    print(grp, \" --- \", inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ca90c4963bb85",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.grammarparses_print_plot_summarize(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a4106f6a2ee5d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Print conjunctions related to rule days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2880fddb511b655",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print for each stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e2b491da80ca9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)\n",
    "DS.dataset_append_column(\"epochset\")\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "savepath = \"/tmp/test.txt\"\n",
    "grouping_print_n_samples(DS.Dat, [\"epochset\", \"epoch\", \"chunk_rank\", \"chunk_within_rank\", \"shape\"], save_as=\"txt\", savepath=savepath)\n",
    "grouping_print_n_samples(DS.Dat, [\"epoch\", \"chunk_rank\", \"shape\"], save_as=\"txt\", savepath=savepath)\n",
    "grouping_print_n_samples(DS.Dat, [\"shape\", \"epoch\", \"chunk_rank\"], save_as=\"txt\", savepath=savepath)\n",
    "grouping_print_n_samples(DS.Dat, [\"epoch\", \"chunk_rank\", \"chunk_within_rank\",\"shape\"], save_as=\"txt\", savepath=savepath)\n",
    "\n",
    "# Also plot examples of shapes.\n",
    "DS.plotshape_row_col_vs_othervar(\"epoch\", n_examples_per_sublot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6670f0801dc83fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect information - (epoch, chunk_rank, shape)\n",
    "outdict = grouping_print_n_samples(DS.Dat, [\"epoch\", \"shape\", \"chunk_rank\"], save_as=\"txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ba5e151563975",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RES = []\n",
    "RES.append({\n",
    "    \"ANALY_VER\":ANALY_VER,\n",
    "    \"animal\":animal,\n",
    "    \"date\":date,\n",
    "    \"outdict\":outdict\n",
    "})\n",
    "RES.append({\n",
    "\"ANALY_VER\":ANALY_VER,\n",
    "\"animal\":animal,\n",
    "\"date\":date,\n",
    "\"outdict\":outdict\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54f3f0c3611d0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad78749cccecea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for this in RES:\n",
    "    lines.append((this[\"ANALY_VER\"], this[\"animal\"], this[\"date\"]))\n",
    "    lines.extend([f\"  {str(k)} : {v}\" for k, v in this[\"outdict\"].items()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b279a1531b6166",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.expttools import writeDictToTxt, writeDictToTxtFlattened, writeStringsToFile\n",
    "writeDictToTxtFlattened(RESDICT, \"/tmp/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7adb5cc7cde0e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writeStringsToFile(\"/tmp/test.txt\", lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe293e7a6794b8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35735c23469b349",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Rule single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693742754849939",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import dataset_apply_params\n",
    "\n",
    "DS = None\n",
    "ANALY_VER = \"rulesingle\"\n",
    "animal = D.animals()[0]\n",
    "date = D.dates()[0]\n",
    "D, DS, params = dataset_apply_params(D, DS, ANALY_VER, animal, date) # prune it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bf29f226364a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(D.Dat)):\n",
    "    D.grammarparses_taskclass_tokens_assign_chunk_state_each_stroke(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ed1f6de8943e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4c09682374f8a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Third, extract variables to strokes\n",
    "DS.context_chunks_assign_columns()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c281509de14f62a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_count_n_samples, grouping_print_n_samples\n",
    "grouping_print_n_samples(DS.Dat, [\"chunk_rank\", \"shape\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9aefd",
   "metadata": {},
   "source": [
    "##### cue-stim flipping order ... defining as epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 102\n",
    "D.blockparams_extract_single_taskparams(ind)[\"fix_tp\"][\"flip_cue_image_order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aada9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD: extracting, and running sanity check\n",
    "D.cue_extract_cuestim_order_flipped()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"CUE_csflipped\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) get grouping.\n",
    "grouping_vars = [\"epoch\", \"CUE_csflipped\"]\n",
    "D.supervision_reassign_epoch_byvars(grouping_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa03833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define epoch based on cue-stim order\n",
    "\n",
    "D.Dat[\"epoch_superv\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"supervision_stage_concise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"supervision_stage_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3854dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"supervision_stage_semantic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3904710e25a9649",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b13941",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"epoch_superv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"epoch_rule_tasksequencer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26cfb9",
   "metadata": {},
   "source": [
    "##### Reward distribution for each block/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0149f27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.catplot(data=D.Dat, x=\"block\", y=\"rew_total\", row=\"epoch_superv\", aspect=2.5, jitter=True, alpha=0.3)\n",
    "sns.catplot(data=D.Dat, x=\"block\", y=\"rew_total\", hue=\"epoch_superv\", aspect=2.5, jitter=True, alpha=0.5,\n",
    "           row=\"session\")\n",
    "sns.catplot(data=D.Dat, x=\"block\", y=\"rew_total\", hue=\"epoch_superv\", aspect=2.5, kind=\"boxen\",\n",
    "            row=\"session\")\n",
    "sns.catplot(data=D.Dat, x=\"block\", y=\"rew_total\", hue=\"epoch_superv\", aspect=2.5, kind=\"point\",\n",
    "            row=\"session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16e5e9",
   "metadata": {},
   "source": [
    "##### Pulling out tasksequencer information from TaskClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d801d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 100\n",
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "\n",
    "TT = D.taskclass_extract_ml2(ind)\n",
    "O = D.taskclass_extract_objectclass(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97154de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.ml2_tasksequencer_params_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbeb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_extract_tasksequencer_params(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7f0337b02b668",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c361ac6c",
   "metadata": {},
   "source": [
    "##### Checking got all distributions of orders for slotscoldiego1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good - moved to summary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.sequence_char_taskclass_assign_char_seq()\n",
    "\n",
    "D.Dat[\"aborted\"]\n",
    "\n",
    "D.Dat[\"char_seq\"].value_counts()\n",
    "D.grouping_print_n_samples([\"aborted\", \"epoch_superv\", \"char_seq\"], savepath=\"/tmp/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf6aa8",
   "metadata": {},
   "source": [
    "### [Grammar GOOD] Plotting all tasks with \"same beh\" (e.g., useful for color rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.grammar import pipeline_generate_and_plot_all, plot_counts_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5dfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh, _ = pipeline_generate_and_plot_all(D, doplots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4faabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh.DatLong[\"epochset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e98298",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh.DatLong[\"success_binary_quick\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_counts_heatmap(bmh.DatLong, \"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7915b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(bmh.DatLong, [\"epochset\", \"epoch_superv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_print_n_samples(bmh.DatLong, [\"epochset\", \"epoch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500c019",
   "metadata": {},
   "source": [
    "##### Redo all plots, using only successful trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781fb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "682906dc",
   "metadata": {},
   "source": [
    "### CLASSIFYING EACH TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways: (1) image [e.g., n circles. or if circles are separated by lines] (2) correct sequence (e.g., same first stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e11053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be398c1b",
   "metadata": {},
   "source": [
    "##### [Grammar] splitting to get (same first stroke, diff 2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c934192",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.epochset_apply_sequence_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8177ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.behclass_preprocess_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grammarmatlab_extract_beh_and_task(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d98841",
   "metadata": {},
   "source": [
    "##### Define epochsets best way, first by charseq, then by char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bafbcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.epochset_apply_sequence_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb09596",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grouping_get_inner_items(\"epochset\", \"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grouping_get_inner_items(\"epochset\", \"task_kind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grouping_get_inner_items(\"epochset\", \"taskgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grouping_get_inner_items(\"taskgroup\", \"epochset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.grammar import preprocess_dataset_matlabrule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e914d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh  = preprocess_dataset_matlabrule(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7da8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"superv_SEQUENCE_SUP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c271a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh.DatLong[\"epoch_superv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aebb1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bmh.plot_score_cross_prior_model_splitby_v2(split_by=\"epochset\", savedir=\"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c4a9fb50c4ad4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Character tasks - checking plots, char labels, and tokens etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79247f8f8ae8cc02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import dataset_apply_params\n",
    "\n",
    "DS = None\n",
    "# ANALY_VER = \"singleprim\"\n",
    "# ANALY_VER = \"rulesw\"\n",
    "# ANALY_VER = \"rulesingle\"\n",
    "ANALY_VER = \"charstrokes\"\n",
    "animal = D.animals()[0]\n",
    "date = D.dates()[0]\n",
    "Dc = D.copy()\n",
    "Dc, DS, params = dataset_apply_params(Dc, DS, ANALY_VER, animal, date) # prune it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca636191159bc50e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(Dc.Dat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d334febb43a3c24",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63b5fa393583eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dc.TokensStrokesBeh_OriginalKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0982e59fe77d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6159af29b025a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.dataset_extract_strokeslength_list_ind_here(682, \"stroke_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0f940d57bfa5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.Dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279f44e26e79fa1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.plotcheck_compare_to_dataset(nplot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664bd610c00cf05",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.plotcheck_compare_to_dataset(nplot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713832562960fb42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.plotshape_multshapes_egstrokes(key_subplots=\"center_binned\", n_examples_total_per_shape=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb21008630378b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.plotshape_multshapes_egstrokes(key_subplots=\"shape_semantic\", n_examples_total_per_shape=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e10702e16d646",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.plotshape_multshapes_egstrokes();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9b863069e103c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Older stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd799398",
   "metadata": {},
   "source": [
    "##### Based on image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f3114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_interest=\"line-8-3-0\"\n",
    "for ind in range(len(D.Dat)):\n",
    "    T = D.Dat.iloc[ind][\"Task\"]\n",
    "    res = shapes_has_separated_cases_of_this_shape(T, shape_of_interest=shape_of_interest, \n",
    "                                                   ploton=False, shape_key=\"shape\")\n",
    "    \n",
    "    print(ind, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out a single example and plot\n",
    "from pythonlib.drawmodel.task_features import shapes_has_separated_cases_of_this_shape\n",
    "\n",
    "ind = 0\n",
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "if False:\n",
    "    D.grammarmatlab_extract_beh_and_task(ind, True)\n",
    "shapes_has_separated_cases_of_this_shape(T, shape_of_interest=shape_of_interest, ploton=True, shape_key=\"shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee470a",
   "metadata": {},
   "source": [
    "##### NEW VERSION - good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83165d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.drawmodel.task_features import shapes_has_separated_cases_of_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127deb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_same=\"line-8-3-0\"\n",
    "list_shape_diff=None\n",
    "\n",
    "for ind in range(len(D.Dat)):\n",
    "    T = D.Dat.iloc[ind][\"Task\"]\n",
    "    \n",
    "    shape_same=\"line-8-4-0\"\n",
    "#     list_shape_diff=[\"line-8-3-0\", \"line-8-3-0\"]\n",
    "    list_shape_diff=[\"line-8-3-0\"]\n",
    "    res1 = shapes_has_separated_cases_of_shape(T, shape_same=shape_same, list_shape_diff=list_shape_diff)\n",
    "    \n",
    "    shape_same=\"line-8-4-0\"\n",
    "    list_shape_diff=[\"V-2-4-0\"]\n",
    "    res2 = shapes_has_separated_cases_of_shape(T, shape_same=shape_same, list_shape_diff=list_shape_diff)\n",
    "    \n",
    "    print(ind, res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1599a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind = 451\n",
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "shapes_has_separated_cases_of_shape(T, ploton=True, DEBUG=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f34729",
   "metadata": {},
   "source": [
    "##### Tried using graph, but this did not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ae977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# generate iterable of edges between each token\n",
    "list_edge = []\n",
    "for i in range(len(Tok.Tokens)):\n",
    "    for j in range(len(Tok.Tokens)):\n",
    "        if not i==j:\n",
    "            t1 = Tok.Tokens[i]\n",
    "            t2 = Tok.Tokens[j]\n",
    "            d = Tok.featurepair_dist(i, j, ver=\"concrete\")\n",
    "            edge = (i, j, {\"weight\":d})\n",
    "            print(edge)\n",
    "            list_edge.append(edge)\n",
    "\n",
    "H = nx.Graph(list_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(H, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the shortest path \n",
    "nx.shortest_path(H, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf84da",
   "metadata": {},
   "source": [
    "##### Classify task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.preprocessGood(params=[\"remove_baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ruledict[\"categ\"]==\"ss\" and ruledict[\"subcat\"]==\"rankdir\":\n",
    "    # AnBm... fixed direction within eachshape\n",
    "    ruledict[\"params\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4d4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STOPPED - below considers the epoch of each trial, so that a shape is only considered\n",
    "# separated if it is separated by a shape that comes after it in the sequence. But this complicates things,\n",
    "# since sequence differs by epoch. Instead, just go by image.\n",
    "\n",
    "# Test each shape in the order it needs to be done given the rule.\n",
    "list_shapes_today = D.taskclass_shapes_extract_unique_alltrials() # get list of shapes that exist today.\n",
    "\n",
    "\n",
    "\n",
    "for ind in range(len(D.Dat)):\n",
    "#     ind = 101\n",
    "    epoch = D.Dat.iloc[ind][\"epoch\"]\n",
    "\n",
    "    ruledict = D.grammarparses_rules_extract_info()[\"ruledict_for_each_rule\"][epoch]\n",
    "\n",
    "    shapes_ordered = [sh for sh in ruledict[\"params_good\"][0] if sh in list_shapes_today]\n",
    "    T = D.Dat.iloc[ind][\"Task\"]\n",
    "    Tok = D.taskclass_tokens_extract_wrapper(ind, \"task\", return_as_tokensclass=True)\n",
    "    shapes_this_trial = [t[\"shape\"] for t in Tok.Tokens]\n",
    "\n",
    "    dict_task_category = {}\n",
    "\n",
    "    for i, shape in enumerate(shapes_ordered):\n",
    "\n",
    "        # shape doesnt exist\n",
    "        if shape not in shapes_this_trial:\n",
    "            cat = \"not_exist\"\n",
    "        else:\n",
    "            if shapes_has_separated_cases_of_shape(T, shape_same=shape, list_shape_diff=shapes_ordered[i+1:]):\n",
    "                # shape exists, with no gap\n",
    "                cat = \"separated\"\n",
    "            else:\n",
    "                cat = \"not_separated\"\n",
    "\n",
    "            # shape eixsts, and has gap\n",
    "        dict_task_category[shape] = cat\n",
    "        \n",
    "        # Give this trial a single code.\n",
    "        trialcode = \n",
    "        \n",
    "    print(ind, dict_task_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0df59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskfeatures_category_by(method=\"shape_repeat\", params=None,\n",
    "        colname=\"taskfeat_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"taskfeat_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1) abbreviate list_trial_code\n",
    "# 2) also get n,m,k\n",
    "# 3) incorporate into grammar plots.\n",
    "list_trial_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912fc61c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind = 691\n",
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "shapes_has_separated_cases_of_shape(T, ploton=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/tmp/test.txt\"\n",
    "D.grouping_print_n_samples([\"aborted\", \"character\", \"epoch\"], savepath = path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e5a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"test\" + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68837ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb750c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.listtools import sort_mixed_type\n",
    "\n",
    "x = ['start', 'end', [[2]], [[None]], [1,2], (1,2), (99, 99)]\n",
    "sort_mixed_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['start', 'end', [[None]], [[2]], [1,2], (1,2), (99, 99), [np.array([1])], {\"test\":[1]}]\n",
    "sort_mixed_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(True, (float, int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be389a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562f0d3",
   "metadata": {},
   "source": [
    "### DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c415e99",
   "metadata": {},
   "source": [
    "##### Stroke color during draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afec078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE! \n",
    "D.supervision_semantic_string_append()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010f6e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# list_draw = []\n",
    "# list_guide = []\n",
    "# for ind in range(len(D.Dat)):\n",
    "#     draw_colored_strokes = D.Dat.iloc[ind][\"supervision_params\"][\"draw_colored_strokes\"]\n",
    "#     guide_colored_strokes = D.Dat.iloc[ind][\"supervision_params\"][\"guide_colored_strokes\"]\n",
    "#     list_draw.append(draw_colored_strokes)\n",
    "#     list_guide.append(guide_colored_strokes)\n",
    "#     block = D.Dat.iloc[ind][\"block\"]\n",
    "#     print(\"---\")\n",
    "#     print(block, ind)\n",
    "#     print(D.supervision_extract_params(ind)[\"COLOR_ITEMS_FADE_TO_DEFAULT\"])\n",
    "#     print(D.supervision_extract_params(ind)[\"COLOR_ITEMS_FADE_TO_DEFAULT_LIST\"])\n",
    "#     print(D.supervision_extract_params(ind)[\"COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR\"])\n",
    "        \n",
    "# D.Dat[\"superv_COLORCUE_STROKES_DRAW\"] = list_draw\n",
    "# D.Dat[\"superv_COLORCUE_STROKES_GUIDE\"] = list_guide\n",
    "\n",
    "# from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "# grouping_print_n_samples(D.Dat, [\"superv_COLORCUE_STROKES_DRAW\", \"superv_COLORCUE_STROKES_GUIDE\", \"block\"])\n",
    "\n",
    "ind = 100\n",
    "prms = D.supervision_extract_params(ind)\n",
    "prms[\"COLOR_ON\"]\n",
    "prms[\"COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR\"]\n",
    "\n",
    "\n",
    "D.Dat[\"supervision_stage_concise\"]\n",
    "\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "\n",
    "# grouping_print_n_samples(D.Dat, [\"block\", \"supervision_stage_new\"])\n",
    "# grouping_print_n_samples(D.Dat, [\"supervision_stage_concise\", \"block\"])\n",
    "grouping_print_n_samples(D.Dat, [\"supervision_stage_semantic\", \"supervision_stage_concise\", \"block\"])\n",
    "\n",
    "D.supervision_semantic_string_append(\"tmp\")\n",
    "\n",
    "# grouping_print_n_samples(D.Dat, [\"supervision_stage_concise\", \"tmp\"])\n",
    "# grouping_print_n_samples(D.Dat, [\"supervision_stage_concise\", \"superv_SEQUENCE_SUP\"])\n",
    "grouping_print_n_samples(D.Dat, [\"tmp\", \"supervision_stage_new\"])\n",
    "\n",
    "D.Dat[\"superv_SEQUENCE_SUP\"]==\"off\"\n",
    "\n",
    "ind = 100\n",
    "D.supervision_extract_params(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05833562",
   "metadata": {},
   "source": [
    "##### Testing gridloc_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69565e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.behclass_tokens_extract_datsegs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.behclass_preprocess_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_tokens_extract_wrapper(ind=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d91f2b",
   "metadata": {},
   "source": [
    "#### For PIG, reward vs. n prims (especialyl within a block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe2c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## [OBSOLETE] DONE! moved to prims_in_grid plots\n",
    "%matplotlib inline\n",
    "from pythonlib.tools.plottools import savefig\n",
    "\n",
    "savedir = \"/tmp\"\n",
    "list_blocks = D.Dat[\"block\"].unique().tolist()\n",
    "for block in list_blocks:\n",
    "    dfthis = D.Dat[D.Dat[\"block\"]==block]\n",
    "    if len(dfthis)>20:\n",
    "        # sns.catplot(data=dfthis, x=\"beh_multiplier\", y=\"rew_total\", hue=\"seqc_nstrokes_task\", jitter=True)\n",
    "        fig = sns.pairplot(data=dfthis, vars=[\"beh_multiplier\", \"rew_total\", \"aborted_int\"], \n",
    "                     hue=\"seqc_nstrokes_task\", plot_kws={\"alpha\":0.4}, height=3, aspect=1.5)\n",
    "        savefig(fig, f\"{savedir}/rew_vs_nstrokestask-bk_{block}.pdf\")        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=dfthis, x=\"beh_multiplier\", y=\"rew_total\", hue=\"seqc_nstrokes_task\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224a2fb",
   "metadata": {},
   "source": [
    "#### Debugging fixed order for prot_prims_chunks_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0053156",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind = 200\n",
    "D.sequence_extract_beh_and_task(ind, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = D.grammar_successbinary_score_parses(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce262ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.sequence_score_wrapper(ind, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = D.Dat.iloc[ind][\"trialcode\"]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grammarparses_grammardict_return(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0756c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.ParsesGenerated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561592d",
   "metadata": {},
   "source": [
    "##### PIG, failures, separate depending on reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369504ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grammarmatlab_successbinary_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grammarparsesmatlab_score_wrapper(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b55bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.grammarparsesmatlab_score_wrapper_append()\n",
    "D.Dat[\"grammar_score_string\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dthis = D.copy()\n",
    "Dthis.Dat = Dthis.Dat[Dthis.Dat[\"task_kind\"] == \"prims_on_grid\"].reset_index(drop=True)\n",
    "Dthis.Dat = Dthis.Dat[Dthis.Dat[\"grammar_score_string\"].isin([\"online_abort_but_sequence_correct_so_far\", \"online_abort_but_sequence_correct_complete\"])].reset_index(drop=True) \n",
    "DSthis = DatStrokes(Dthis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef27d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8688d277",
   "metadata": {},
   "source": [
    "### [Grammar] daily plots for sequential context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.grammar import conjunctions_preprocess, conjunctions_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS, dataset_pruned_for_trial_analysis, params, params_extraction = conjunctions_preprocess(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd83746",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/tmp\"\n",
    "params_anova = params\n",
    "conjunctions_plot(D, DS, savedir, params_anova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc18dfe",
   "metadata": {},
   "source": [
    "##### DEBUGGING below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACTING DATA\n",
    "D.grammarparses_rules_extract_info()[\"ruledict_for_each_rule\"]\n",
    "\n",
    "D.taskclass_tokens_extract_wrapper(100, which_order=\"beh\")\n",
    "\n",
    "ind = 200\n",
    "D.grammarparses_print_plot_summarize(ind)\n",
    "\n",
    "\n",
    "# Get datstrokes, including chunk information\n",
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)\n",
    "\n",
    "D.Dat.iloc[ind][\"success_binary_quick\"]\n",
    "\n",
    "D.grammarparses_grammardict_return(ind, True)\n",
    "\n",
    "D.grammarparses_successbinary_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods for printing/plotting conjunctions\n",
    "\n",
    "# Debug: to get strokes of specific character (LOS).\n",
    "D.taskclass_extract_los_info_append_col()\n",
    "display(D.Dat[\"los_info\"]==(\"dirshape\", 57, 69))\n",
    "DS.dataset_append_column(\"los_info\")\n",
    "\n",
    "DS.Dat[DS.Dat[\"los_info\"]==(\"dirshape\", 57, 69)]\n",
    "\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars\n",
    "from pythonlib.tools.expttools import writeStringsToFile\n",
    "\n",
    "DS.context_define_local_context_motif(1,1)\n",
    "DS.context_chunks_assign_columns()\n",
    "\n",
    "# plot example stroke\n",
    "ind = 1\n",
    "DS.plot_single_overlay_entire_trial(ind)\n",
    "DS.plot_single_overlay_entire_trial(ind, overlay_beh_or_task=\"task\")\n",
    "print(DS.Dat.loc[ind, [\"chunk_diff_from_prev\", \"chunk_n_in_chunk_prev\", 'chunk_rank',\n",
    "       'chunk_within_rank', 'chunk_n_in_chunk']])\n",
    "\n",
    "sdir = \"/tmp/test\"\n",
    "os.makedirs(sdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2326da01",
   "metadata": {},
   "source": [
    "##### Look for specific motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = (DS.Dat[\"gridloc\"]==(1,-1)) & \\\n",
    "(DS.Dat[\"shape\"]==\"line-6-1-0\") & \\\n",
    "(DS.Dat[\"CTXT_locshape_prev\"]==\"[(-1, -1), 'line-6-2-0']\") & \\\n",
    "(DS.Dat[\"CTXT_locshape_next\"]==\"[(-1, 1), 'line-6-1-0']\") & \\\n",
    "(DS.Dat[\"CTXT_prev_this_next\"]==(\"[(-1, -1), 'line-6-2-0']\", (1,-1), \"line-6-1-0\", \"[(-1, 1), 'line-6-1-0']\"))\n",
    "\n",
    "DS.Dat[inds][\"chunk_n_in_chunk\"]\n",
    "# DS.Dat[inds][\"chunk_diff_from_prev\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4961e50",
   "metadata": {},
   "source": [
    "### All daily plots for single prims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737700ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.singleprims import preprocess_dataset\n",
    "from pythonlib.tools.plottools import savefig\n",
    "DS, SAVEDIR = preprocess_dataset(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee946ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import conjunctions_print_plot_all\n",
    "conjunctions_print_plot_all([D], SAVEDIR, \"singleprim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58702e5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_drawings_grid_conjunctions(DS, SAVEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each shape x location, plot rew and abort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"rew_total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72962584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import plot_subplots_heatmap\n",
    "\n",
    "df = D.Dat\n",
    "ZLIMS = [0., None]\n",
    "plot_subplots_heatmap(df, \"seqc_0_shape\", \"seqc_0_loc\", \"rew_total\", \"gridsize\", share_zlim=True, ZLIMS=ZLIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ac0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulate \n",
    "\n",
    "list_sh = df[\"seqc_0_loc\"].unique()\n",
    "list_size = df[\"gridsize\"].unique()\n",
    "list_\n",
    "\n",
    "for sh in list_sh:\n",
    "    for loc in list_loc:\n",
    "        for size in list_size:\n",
    "            df[(df[\"seqc_0_shape\"]==sh) & (df[\"seqc_0_loc\"]==loc) & (df[\"gridsize\"]==size)]b\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import stringify_values\n",
    "df = stringify_values(df)\n",
    "fig = sns.catplot(data=df, x=x, y=yval, hue=\"aborted\", row=\"session\", aspect=3, height=2, jitter=True, alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def80a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"gridsize\"\n",
    "yval = \"rew_total\"\n",
    "for yval in [\"rew_total\", \"beh_multiplier\", \"aborted\"]:\n",
    "\n",
    "    # print(\"Plotting for (block, yval): \", bk, yval)\n",
    "\n",
    "    for x in [\"gridsize\", \"seqc_0_shape\", \"seqc_0_loc\"]:\n",
    "\n",
    "        fig = sns.catplot(data=df, x=x, y=yval, hue=\"aborted\", row=\"session\", aspect=3, height=2, jitter=True, alpha=0.2)\n",
    "        # rotateLabel(fig)\n",
    "        # savefig(fig, f\"{sdir}/block_{bk}-x={x}-yval={yval}-1.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f55d11",
   "metadata": {},
   "source": [
    "##### Check all conjunctions of sequence variables (prep for neural analy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343da76c",
   "metadata": {},
   "source": [
    "##### Prims in grid sequential context, controls (9/13/23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e110f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.metadat.analy.anova_params import _conjunctions_print_plot_all, dataset_apply_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68409c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_VAR = [\n",
    "    \"seqc_2_loc\",\n",
    "    \"seqc_1_loc\",\n",
    "    \"seqc_0_loc\"\n",
    "]\n",
    "\n",
    "LIST_VARS_CONJUNCTION = [\n",
    "    [\"seqc_nstrokes_beh\", \"seqc_0_loc_shape\", \"seqc_1_loc_shape\", \"seqc_2_shape\"],\n",
    "    [\"seqc_nstrokes_beh\", \"seqc_0_loc_shape\", \"seqc_1_shape\", \"seqc_2_loc_shape\"],\n",
    "    [\"seqc_nstrokes_beh\", \"seqc_0_shape\", \"seqc_1_loc_shape\", \"seqc_2_loc_shape\"]\n",
    "]\n",
    "\n",
    "ListD = [D]\n",
    "animal = \"Pancho\"\n",
    "DATE = 230616\n",
    "which_level = \"trial\"\n",
    "ANALY_VER = \"seqcontext\"\n",
    "\n",
    "_, Dpruned, TRIALCODES_KEEP, params, params_extraction = dataset_apply_params(ListD, \n",
    "    animal, DATE, which_level, ANALY_VER)\n",
    "assert len(Dpruned.Dat)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58004794",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print and plot all conjucntions\n",
    "# LIST_VAR = params[\"LIST_VAR\"]\n",
    "# LIST_VARS_CONJUNCTION = params[\"LIST_VARS_CONJUNCTION\"]         \n",
    "\n",
    "_conjunctions_print_plot_all(Dpruned.Dat, LIST_VAR, LIST_VARS_CONJUNCTION, sdir, \n",
    "    params[\"globals_nmin\"], Dpruned) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c04e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cases wb\n",
    "var = \"seqc_0_loc\"\n",
    "vars_others = ['seqc_nstrokes_beh', 'seqc_0_shape', 'seqc_1_loc_shape', 'seqc_2_loc_shape']\n",
    "path = \"/tmp/test\"\n",
    "dfout, dict_dfs = D.grouping_conjunctions_print_variables_save(var, vars_others, path, DF = Dpruned.Dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b04c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"seq_0_shape\"]\n",
    "df[\"seqc_0_shape\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f81fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track what levels found\n",
    "\n",
    "\n",
    "var_extra_1 = \"seqc_0_shape\" # ensure i s \n",
    "\n",
    "RES = []\n",
    "for k, df in dict_dfs.items():\n",
    "    levels_var = df[var].unique()\n",
    "    lev_othervar = k\n",
    "    assert len(df[var_extra_1].unique().tolist())==1\n",
    "    lev_extra_1 = df[var_extra_1].unique().tolist()[0]\n",
    "    \n",
    "    # Save it\n",
    "    RES.append({\n",
    "        \"levels_var\":levels_var,\n",
    "        \"lev_othervar\":lev_othervar,\n",
    "        \"lev_extra_1\":lev_extra_1})\n",
    "    \n",
    "RES\n",
    "import pandas as pd\n",
    "pd.DataFrame(RES)\n",
    "\n",
    "# TODO:\n",
    "# - find is any lev_extra1 that appears across similar levels_var, across 2 t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9be2e6",
   "metadata": {},
   "source": [
    "##### Load the params used for anova analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d93d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythonlib.dataset.dataset_analy.prims_in_grid import conjunctions_print_plot_all\n",
    "from neuralmonkey.metadat.analy.anova_params import conjunctions_print_plot_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunctions_print_plot_all(D, \"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.Dat[\"task_kind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if has single prims at each location\n",
    "\n",
    "### STROKE LEVEL - heatmaps of (shape, location) vs. index\n",
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)\n",
    "\n",
    "sdir = \"/tmp\"\n",
    "for task_kind in [\"prims_single\", \"prims_on_grid\"]:\n",
    "    dfthis = DS.Dat[DS.Dat[\"task_kind\"]==task_kind]\n",
    "    fig = grouping_plot_n_samples_conjunction_heatmap(dfthis, var1=\"shape\", var2=\"gridloc\", vars_others=[\"stroke_index\"])\n",
    "    path = f\"{sdir}/STROKELEVEL-conjunctions_shape_gridloc-task_kind_{task_kind}.pdf\"\n",
    "    savefig(fig, path)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4354cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.Dat[\"stroke_index_fromlast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a3cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ed81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfthis = DS.Dat\n",
    "fig = grouping_plot_n_samples_conjunction_heatmap(dfthis, var1=\"stroke_index\", \n",
    "                                                  var2=\"stroke_index_fromlast\", vars_others=[\"shape\", \"gridloc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a56678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36994116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN progress: Plotting example drawings for each conjucntion that exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1382d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplot = 2\n",
    "for lev_others, dfsub in dict_dfs.items():\n",
    "    print(\"Plotting .. \", lev_others)\n",
    "\n",
    "    trialcodes = dfsub[\"trialcode\"].tolist()\n",
    "\n",
    "    # pick n random\n",
    "    if len(trialcodes)>nplot:\n",
    "        import random\n",
    "        indsplot = sorted(random.sample(range(len(trialcodes)), nplot))\n",
    "    else:\n",
    "        indsplot = range(len(trialcodes))\n",
    "\n",
    "    # Get data\n",
    "    tmp = dfsub[var].to_list()\n",
    "    titles = [tmp[i] for i in indsplot]\n",
    "    tcs = [trialcodes[i] for i in indsplot]\n",
    "\n",
    "    # convert trialcodes to dataset indices\n",
    "    inds_dat_beh = D.Dat[D.Dat[\"trialcode\"].isin(trialcodes)].index.tolist()\n",
    "\n",
    "    if len(inds_dat_beh)==0 or any([x is None for x in inds_dat_beh]):\n",
    "        print(\"trialcodes: \", trialcodes)\n",
    "        print(\"tcs: \", tcs)\n",
    "        print(\"len(dfsub):\", len(dfsub))\n",
    "        print(inds_dat_beh)\n",
    "        assert False\n",
    "\n",
    "    # -- PLOT BEH            \n",
    "    fig, axes, _ = D.plotMultTrials2(inds_dat_beh, \"strokes_beh\", titles=titles)\n",
    "    for ax, tit, tcthis in zip(axes.flatten(), titles, tcs):\n",
    "        # ax.set_title(f\"{var}:{tit}\")\n",
    "        ax.set_ylabel(f\"{tcthis}\")\n",
    "#     fig.savefig(f\"{sdir}/lev_others-{'-'.join([str(x) for x in lev_others])}-BEH.pdf\")\n",
    "\n",
    "    # -- PLOT TASK            \n",
    "    fig, axes, _ = D.plotMultTrials2(inds_dat_beh, \"strokes_task\", titles=titles)\n",
    "    for ax, tit, tcthis in zip(axes.flatten(), titles, tcs):\n",
    "        # ax.set_title(f\"{var}:{tit}\")\n",
    "        ax.set_ylabel(f\"{tcthis}\")\n",
    "#     fig.savefig(f\"{sdir}/lev_others-{'-'.join([str(x) for x in lev_others])}-TASK.pdf\")\n",
    "\n",
    "#     plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62dc90",
   "metadata": {},
   "source": [
    "##### Cause of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf433c29a1d0670",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "DS = DatStrokes(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ac9e0d5f0ab08",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb42114d6d03a4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.Dataset.extract_beh_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901bb9a8789a51c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.Dataset.Dat.iloc[26][\"FEAT_num_strokes_task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a83a1b9ad48028",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS.dataset_append_column(\"aborted\")\n",
    "DS.dataset_append_column(\"FEAT_num_strokes_beh\")\n",
    "DS.dataset_append_column(\"FEAT_num_strokes_task\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c526f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DS.Dat.loc[:, [\"trialcode\", \"aborted\", \"stroke_index_semantic\", \"stroke_index_semantic_tskstks\", \"stroke_index\", \"stroke_index_fromlast\", \"stroke_index_fromlast_tskstks\", \"FEAT_num_strokes_beh\", \"FEAT_num_strokes_task\", \"gap_to_next_angle\", \"gap_to_next_dist\", \"gap_to_next_angle_binned\", \"gap_to_next_dist_binned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7e8b6396ccd6d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inddat = DS._dataset_index(57)\n",
    "DS.Dataset.plotSingleTrial(inddat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71652012",
   "metadata": {},
   "source": [
    "##### Classify each task based on the tasks' config of shapes and/or locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2856e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.behclass_preprocess_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ec22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 300\n",
    "D.taskclass_shapes_loc_configuration_extract(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414eda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_shapes_loc_configuration_assign_column()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9421dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"taskconfig_shploc\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49edc29",
   "metadata": {},
   "source": [
    "##### Checking gridloc is identical over tasks(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.taskclass_get_grid_xy_over_all_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efe09e",
   "metadata": {},
   "source": [
    "### Prims in grid scoring and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37501061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.prims_in_grid import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7279ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp\"\n",
    "DS, SAVEDIR = preprocess_dataset(D, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c59200",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS, SAVEDIR = preprocess_dataset(D, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5439474",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.Dat[\"task_kind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SAVEDIR)\n",
    "plotscore_all(DS, SAVEDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de7458",
   "metadata": {},
   "source": [
    "##### What locations each rank position tends to be done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.nstrokes_task_extract()\n",
    "\n",
    "DS.dataset_replace_dataset(D)\n",
    "DS.dataset_append_column(\"nstrokes_task\")\n",
    "\n",
    "from pythonlib.tools.pandastools import convert_to_2d_dataframe\n",
    "\n",
    "for stroke_index in [0,1,2, 3]:\n",
    "    tk = \"prims_on_grid\"\n",
    "    n = 4\n",
    "    # Prep, for this taskkind\n",
    "    dfthis = DS.Dat[(DS.Dat[\"task_kind\"]==tk) & (DS.Dat[\"nstrokes_task\"]==n) & (DS.Dat[\"stroke_index\"]==stroke_index)]\n",
    "\n",
    "    print(\"start: \", len(DS.Dat))\n",
    "    print(\"end: \", len(dfthis))\n",
    "\n",
    "\n",
    "    list_cat_1 = [0,1]\n",
    "    list_cat_2 = [0,1]\n",
    "    _, fig, _, _ = convert_to_2d_dataframe(dfthis, \"gridloc_y\", \"gridloc_x\", True, \n",
    "                                           agg_method=\"counts\", annotate_heatmap=False,\n",
    "                                          list_cat_1=list_cat_1, list_cat_2=list_cat_2, \n",
    "                                          norm_method=\"all_div\");\n",
    "    \n",
    "    #         fig.savefig(f\"{savedir}/heat2d_location_rank_meanscore.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f154ae",
   "metadata": {},
   "source": [
    "##### Sequential context (conv and divergent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f2410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.prims_in_grid import plot_sequential_context_strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/tmp/test\"\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequential_context_strokes(DS, savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    VER = \"divergent\"\n",
    "    df = DS.Dat\n",
    "    suffix = \"ALLDATA\"\n",
    "\n",
    "    plot_context(df, VER, savedir, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d631af1",
   "metadata": {},
   "source": [
    "##### Plot tasks, sorted by performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75888edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DS.Dat.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "    dict_tasks_scores = D.grouping_get_inner_items(\"character\", \"score_final\")\n",
    "\n",
    "    # sort by score\n",
    "    tmp = [(task, np.mean(scores)) for task, scores in dict_tasks_scores.items()]\n",
    "    tmp = sorted(tmp, key=lambda x: x[1])\n",
    "\n",
    "    # take the top 20 and bottom 20\n",
    "    row_levels = [t[0] for t in tmp]\n",
    "    row_levels_sub = row_levels[:20] + row_levels[-20:]\n",
    "    row_levels_sub = unique_input_order(row_levels_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tasks_scores[\"gridlinecircle-26-215-991384\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079491e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D.Dat[D.Dat[\"character\"]==\"gridlinecircle-26-215-991384\"][\"trialcode\"])\n",
    "print(D.Dat[D.Dat[\"character\"]==\"gridlinecircle-26-215-991384\"][\"score_final\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2051b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.summary import plot_drawings_ordered_by_score\n",
    "plot_drawings_ordered_by_score(D, \"/tmp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3c021",
   "metadata": {},
   "source": [
    "##### Find repeated trials (after failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bda89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d12da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab0760",
   "metadata": {},
   "source": [
    "##### [Devo day preprocessing] rewards for probes and non-probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ca374",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat[\"probe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.Dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plotOverviewScoresRewardsFeatures(\"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab68503",
   "metadata": {},
   "source": [
    "##### For each task, print whether it is on grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f280548",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(len(D.Dat)):\n",
    "    T = D.Dat.iloc[ind][\"Task\"]\n",
    "    print(T.get_grid_ver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b18f8",
   "metadata": {},
   "source": [
    "##### Automatically classify probe tasks (by comparing to train tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.behclass_preprocess_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be56cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_preprocess.probes import taskgroups_assign_each_probe, compute_features_each_probe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366bb13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_features_each_probe(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Novel location-shape combo?\n",
    "\n",
    "# represent each task as set of location-shape combos\n",
    "ind = 100\n",
    "# D.Dat.iloc[ind\n",
    "\n",
    "# D.sequence_extract_beh_and_task(ind, True)\n",
    "\n",
    "D.behclass_extract_beh_and_task(ind, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1887561",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "tokens = T.tokens_generate()\n",
    "set([(t[\"shape\"], t[\"gridloc\"]) for t in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.datseg_motifs import generate_dict_of_all_used_motifs\n",
    "motifs_all_dict = generate_dict_of_all_used_motifs(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_all_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taskgroups_assign_each_probe(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_task_to_taskgroup = taskgroups_assign_each_probe(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_preprocess.general import taskgroup_reassign_by_mapper\n",
    "taskgroup_reassign_by_mapper(D, None, map_task_to_taskgroup, append_probe_status=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1942cc",
   "metadata": {},
   "source": [
    "##### Summary sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29780ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dfGramScore.groupby([\"epoch_superv\", \"taskgroup\"]).size()\n",
    "dfthis = tmp.to_frame()\n",
    "from pythonlib.tools.pandastools import pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c0cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot_table(dfthis, index=[\"epoch_superv\"], columns=[\"neuralbiasdir-ss-5\"], values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import pivot_table, aggregGeneral\n",
    "\n",
    "tmp1 = aggregGeneral(dfGramScore, group=[\"epoch_superv\", \"taskgroup\"], values=[\"block\"], aggmethod=[\"count\"])\n",
    "tmp = pivot_table(tmp1, index=[\"epoch_superv\"], columns=[\"taskgroup\"], values=[\"block\"], aggfunc=\"count\", flatten_col_names=True)\n",
    "# tmp.reset_index(name=\"test\")\n",
    "\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6041e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_csv(\"/tmp/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGramScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']\n",
    "Cols = ['A', 'B', 'C', 'D']\n",
    "df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)\n",
    "\n",
    "sns.heatmap(df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aa451",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.grammar import plot_counts_heatmap\n",
    "\n",
    "plot_counts_heatmap(dfGramScore, \"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84ff4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pivot_table(dfGramScore, index=[\"epoch_superv\"], columns=[\"taskgroup\"], values=[\"block\"], aggfunc=\"count\", flatten_col_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa04176",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46add953",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dfGramScore.groupby([\"epoch_superv\", \"taskgroup\", \"character\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.expttools import writeDictToYaml\n",
    "\n",
    "# writeDictToYaml(tmp.to_dict(), \"/tmp/test.yaml\")\n",
    "\n",
    "for k, v in tmp.to_dict().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGramScore.groupby([\"epoch_superv\", \"taskgroup\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.grammar import \\\n",
    "    preprocess_dataset, plot_performance_all, plot_performance_static_summary, plot_performance_timecourse\n",
    "dfGramScore, list_blockset, SDIR = preprocess_dataset(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9dec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0878deb5",
   "metadata": {},
   "source": [
    "##### Finding trials where missing data (are they all fixation errors?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df62ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print indices where there is gap in trial\n",
    "np.argwhere(np.diff(D.Dat[\"trial\"])!=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print actual trial for this index, and then go to raw data and confirm that is fixation error\n",
    "# DONE: for grammardir4 (looked at like 10 indices)\n",
    "ind = 1543\n",
    "print(D.Dat.iloc[ind-1:ind+2][\"trial\"])\n",
    "print(D.Dat.iloc[ind-1:ind+2][\"date_sess\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a071be",
   "metadata": {},
   "source": [
    "##### Fixation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did this for priminvar3h (12/18/22) when randomly varied fixation location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.sketchpad_fixation_plot_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each trial based on fixation location\n",
    "D.sketchpad_fixation_append_as_string()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbdd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import DatStrokes\n",
    "\n",
    "DS = DatStrokes(D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert origin to string\n",
    "DS.dataset_append_column(\"origin_string\")\n",
    "\n",
    "# take just first stroke\n",
    "df = DS.Dat[DS.Dat[\"stroke_index\"]==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f31bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.print_n_samples_per_combo_grouping([\"origin_string\", \"gridloc\", \"shape_oriented\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb7fe6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groupings = DS.grouping_append_and_return_inner_items([\"shape_oriented\", \"gridloc\", \"origin_string\"])\n",
    "for k, v in groupings.items():\n",
    "    print(k, ' ---------- ',  len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abf45b",
   "metadata": {},
   "source": [
    "##### Define new epochs based on origin (fixation location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107f51a",
   "metadata": {},
   "source": [
    "##### Plots using loc on clust (not just gridloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fecd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.Dat[\"loc_on_clust\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee218e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.singleprims import preprocess_dataset\n",
    "preprocess_dataset(D, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21f6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "natural-integer",
   "metadata": {},
   "source": [
    "## Simple summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-packaging",
   "metadata": {},
   "source": [
    "#### Plot behavior (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed744e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.summary import plotall_summary\n",
    "\n",
    "\n",
    "animal = \"Pancho\"\n",
    "expt = \"grammardircolor2\"\n",
    "rulelist = [\"220928\"]\n",
    "plotall_summary(animal, expt, rulelist, \"main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d29718",
   "metadata": {},
   "outputs": [],
   "source": [
    "D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MOre detailed, one of the inner plots\n",
    "# (for debugging)\n",
    "from pythonlib.dataset.dataset_analy.summary import plot_summary_drawing_examplegrid\n",
    "SAVEDIR_FIGS = \"/tmp\"\n",
    "from pythonlib.dataset.dataset_analy.summary import plot_summary_drawing_examplegrid\n",
    "# plot_summary_drawing_examplegrid(Dthis, SAVEDIR_FIGS, subfolder, \n",
    "#                  yaxis_ver=\"date_epoch\", how_to_split_files = \"task_stagecategory\")\n",
    "# for traintest in [\"test\", \"train\"]:\n",
    "list_supstage = D.Dat[\"supervision_stage_concise\"].unique().tolist()\n",
    "for supstage in list_supstage:\n",
    "    Dthis = D.filterPandas({\"random_task\":[False], \"supervision_stage_concise\":[supstage]}, \"dataset\")\n",
    "\n",
    "    # Check if plot is large. if so, split into multiple plots.\n",
    "\n",
    "    plot_summary_drawing_examplegrid(Dthis, SAVEDIR_FIGS, subfolder=f\"{supstage}\", \n",
    "                     yaxis_ver=\"date_epoch\", how_to_split_files = \"taskgroup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab46080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32c109a8",
   "metadata": {},
   "source": [
    "##### [IN PROGRESS] Look into objectclass for rules failed online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34230b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.objectclass_summarize_rule_failures(True, sdir=\"/tmp\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b701b",
   "metadata": {},
   "source": [
    "### Plotting sequence stats (e.g., % correct, for grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRINT useful things.\n",
    "from pythonlib.tools.pandastools import grouping_get_inner_items\n",
    "\n",
    "# list all task sets\n",
    "D.taskclass_extract_los_info_append_col()\n",
    "display(D.Dat[\"los_info\"].value_counts())\n",
    "\n",
    "print(D.Dat[\"task_stagecategory\"].value_counts())\n",
    "\n",
    "# Print summary out new taskgroups\n",
    "display(D.Dat[\"taskgroup\"].value_counts())\n",
    "display(grouping_get_inner_items(D.Dat, \"taskgroup\", \"block\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93500aca",
   "metadata": {},
   "source": [
    "##### [Grammar] plot timecourse (running avg of trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901113bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot binary score, rolling avg\n",
    "# [obsolete - moved to grammar.py] \n",
    "# [but is in progres...]\n",
    "\n",
    "list_sess = D.Dat[\"session\"].unique().tolist()\n",
    "for sess in list_sess:\n",
    "    dfthis = D.Dat[\n",
    "        (D.Dat[\"exclude_because_online_abort\"]==False) & \n",
    "        (D.Dat[\"session\"]==sess) \n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(4,1, figsize=(35,9))\n",
    "\n",
    "    ax = axes.flatten()[1]\n",
    "    ax.grid(True)\n",
    "    sns.scatterplot(data=dfthis, x=\"trial\", y=\"success_binary\", hue=\"epoch_superv\", ax=ax, \n",
    "                   alpha = 0.75)\n",
    "    smwin = 20\n",
    "    dfthis_rolling = dfthis.rolling(window=smwin, center=True).mean()\n",
    "    sns.lineplot(ax=ax, data=dfthis_rolling, x=\"trial\", y=\"success_binary\")\n",
    "    sns.scatterplot(ax=ax, data=dfthis_rolling, x=\"trial\", y=\"success_binary\")\n",
    "    blockver = \"block\"\n",
    "    idx_of_bloque_onsets = []\n",
    "    for i in np.argwhere(dfthis[blockver].diff().values):\n",
    "        idx_of_bloque_onsets.append(i[0])\n",
    "    bloque_onsets = dfthis[\"trial\"].values[idx_of_bloque_onsets]\n",
    "    # bloque_nums = df[\"bloque\"].values[idx_of_bloque_onsets]\n",
    "    # blokk_nums = dfthis[\"blokk\"].values[idx_of_bloque_onsets]\n",
    "    block_nums = dfthis[\"block\"].values[idx_of_bloque_onsets]\n",
    "\n",
    "    for b, x in zip(block_nums, bloque_onsets):\n",
    "        ax.axvline(x)\n",
    "        ax.text(x, ax.get_ylim()[1], f\"k{b}\\nt{x}\", size=10)\n",
    "    ax.grid(True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f921a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d23c5e5",
   "metadata": {},
   "source": [
    "##### [Grammar] plot timecourse, and by bloque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92786dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract blocques\n",
    "\n",
    "from pythonlib.tools.timeseriestools import getChangePoints\n",
    "getCh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc6268",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_analy.grammar import plot_performance_each_char\n",
    "\n",
    "plot_performance_each_char(dfGramScore, D, \"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ce30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [Grammar] separate score for each unique character\n",
    "list_taskgroups = sorted(dfthis[\"taskgroup\"].unique())\n",
    "list_epochsuperv = sorted(dfthis[\"epoch_superv\"].unique())\n",
    "list_textstrings = [] # for saving\n",
    "list_blocksetnum = dfGramScore[\"which_probe_blockset\"].unique().tolist()\n",
    "list_character = dfGramScore[\"character\"].unique().tolist()\n",
    "for i, blocksetnum in enumerate(list_blocksetnum):\n",
    "    print(\"blockset: \", blocksetnum)\n",
    "    for taskgroup in list_taskgroups:\n",
    "        print(\"taskgroup: \", taskgroup)\n",
    "        for epoch_superv in list_epochsuperv:\n",
    "            print(\"epoch_superv: \", epoch_superv)\n",
    "            for character in list_character:\n",
    "                print(\"character: \", character)\n",
    "                # get performance of tasks\n",
    "                inds = (dfthis[\"which_probe_blockset\"]==blocksetnum) & (dfthis[\"taskgroup\"]==taskgroup) & (dfthis[\"epoch_superv\"]==epoch_superv) & (dfthis[\"character\"]==character)\n",
    "                # Collect characters\n",
    "                dfthisthis = dfthis[inds]\n",
    "                if len(dfthisthis)>0:\n",
    "                    score = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28190ae8",
   "metadata": {},
   "source": [
    "##### [Grammar] trial by trial, showing (i) rule (ii) success/failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3517ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply supervision stage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f1538",
   "metadata": {},
   "source": [
    "##### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f49f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this to preprocess. clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "def F(x, abbrev = True):\n",
    "    S = x[\"supervision_params\"]\n",
    "\n",
    "    # sequence\n",
    "    if S[\"sequence_on\"]==False:\n",
    "        seq = \"off\"\n",
    "    else:\n",
    "        seq = S[\"sequence_ver\"]\n",
    "\n",
    "    # dynamic\n",
    "    dyna = S[\"guide_dynamic_strokes\"]\n",
    "    if dyna:\n",
    "        d = 1\n",
    "    else:\n",
    "        d=0\n",
    "\n",
    "    # color\n",
    "    colo = S[\"guide_colored_strokes\"]\n",
    "    if colo:\n",
    "        c=1\n",
    "    else:\n",
    "        c=0\n",
    "\n",
    "    # give a condensed name\n",
    "#     s = interpret_objectclass_sequence_module() # TODO\n",
    "    if seq==\"off\":\n",
    "        s = 0\n",
    "    elif seq==\"v3_remove_and_show\":\n",
    "        s = 3\n",
    "    elif seq==\"v3_remove_and_fadein\":\n",
    "        s = 4\n",
    "    elif seq==\"v3_noremove_and_show\":\n",
    "        s = 5\n",
    "    elif seq==\"v3_noremove_and_fadein\":\n",
    "        s = 6\n",
    "    elif seq==\"v4_fade_when_touch\":\n",
    "        s=1\n",
    "    elif seq==\"v4_remove_when_touch\":\n",
    "        s=2\n",
    "    elif seq==\"unknown\":\n",
    "        s=7\n",
    "    elif seq==\"objectclass_active_chunk\":\n",
    "        s=8\n",
    "    else:\n",
    "        print(seq)\n",
    "        print(\"what is this?\")\n",
    "        assert False\n",
    "\n",
    "    if abbrev:\n",
    "        return (s,d,c)\n",
    "    else:\n",
    "        return seq, dyna, colo\n",
    "if expt in [\"chunkbyshape1\"]:\n",
    "    # TODO: define supervision stage using ObjectCalss only\n",
    "    if False:\n",
    "        # Start from here\n",
    "        TT = T.Params[\"input_params\"]\n",
    "        Tnew = TT.get_tasknew()\n",
    "        Tnew[\"Objects\"][\"Params\"]\n",
    "    else:\n",
    "        # For now, just hack it \n",
    "        Fthis = lambda x: (0,0,0)\n",
    "else:\n",
    "    Fthis = F\n",
    "D.Dat = applyFunctionToAllRows(D.Dat, Fthis, \"supervision_stage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4001195",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve condensed name of supervision stage\n",
    "\n",
    "LIST_FIELDS = [\"SEQUENCE_SUP\", \"SEQUENCE_ALPHA\", \"COLOR_ON\", \"COLOR_METHOD\", \"SOUNDS_STROKES_DONE\", \"GUIDEDYN_ON\"]\n",
    "\n",
    "blocks = D.Dat[\"block\"].unique()\n",
    "for b in blocks:\n",
    "    ind = D.Dat[D.Dat[\"block\"]==b].index.tolist()[0]\n",
    "    prms = extract_supervision_params(D, ind)\n",
    "    epoch = D.Dat.iloc[ind][\"epoch\"]\n",
    "    sup = D.Dat.iloc[ind][\"supervision_stage\"]\n",
    "    print(\"--- BLOCK: \", b)\n",
    "#     for k, v in prms.items():\n",
    "#         print(k, ' -- ', v)\n",
    "#     for k in LIST_FIELDS:\n",
    "#         print(k, ' -- ', prms[k])\n",
    "    vals = [prms[k] for k in LIST_FIELDS] + [epoch, sup]\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b896d30",
   "metadata": {},
   "source": [
    "##### Better supervision tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_get_inner_items\n",
    "# grouping_get_inner_items(D.Dat, \"supervision_stage\", \"block\")\n",
    "# grouping_get_inner_items(D.Dat, \"supervision_stage_new\", \"block\")\n",
    "# grouping_get_inner_items(D.Dat, \"supervision_online\", \"block\")\n",
    "grouping_get_inner_items(D.Dat, \"supervision_online\", \"monkey_train_or_test\")\n",
    "# grouping_get_inner_items(D.Dat, \"monkey_train_or_test\", \"supervision_stage_new\")\n",
    "# grouping_get_inner_items(D.Dat, \"monkey_train_or_test\", \"block\")\n",
    "# grouping_get_inner_items(D.Dat, \"block\", \"index\")\n",
    "# grouping_get_inner_items(D.Dat, \"block\", \"index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf14645",
   "metadata": {},
   "source": [
    "##### [Hacky] Print \"simplified\" condition names (replacing epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Generate the appropriate names\n",
    "list_con = []\n",
    "for ind in range(len(D.Dat)):\n",
    "    supstage = D.Dat.iloc[ind][\"supervision_stage\"]\n",
    "    block = D.Dat.iloc[ind][\"block\"]\n",
    "    epoch = D.Dat.iloc[ind][\"epoch\"]\n",
    "    \n",
    "    if supstage==(0,0,1) and block in range(31, 37):\n",
    "#     if supstage==(0,0,1) and block in range(33, 37):\n",
    "        con = f\"colorsup_{epoch}\"\n",
    "    elif supstage==(0,0,0) and block in range(9, 15):\n",
    "#     elif supstage==(0,0,0) and block in range(11, 15):\n",
    "        con = epoch\n",
    "    elif supstage==(0,0,0) and block in range(20, 26):\n",
    "#     elif supstage==(0,0,0) and block in range(22, 26):\n",
    "        con = epoch\n",
    "    else:\n",
    "        con = \"train\"\n",
    "    \n",
    "    list_con.append(con)\n",
    "    \n",
    "D.Dat[\"epoch_new\"] = list_con\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46bf0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2) Print groupings, using the new epoch\n",
    "\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "\n",
    "# list_grouping_vars = [\"character\", \"block\", \"epoch\", \"supervision_stage\"]\n",
    "# list_grouping_vars = [\"character\", \"block\", \"epoch_new\", \"supervision_stage\"]\n",
    "# list_grouping_vars = [\"character\", \"block\", \"epoch_new\", \"supervision_stage\"]\n",
    "# list_grouping_vars = [\"character\", \"epoch\", \"epoch_new\", \"supervision_stage\"]\n",
    "list_grouping_vars = [\"character\", \"epoch_new\"]\n",
    "grouping_print_n_samples(D.Dat, list_grouping_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Plot drawings, using these new epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c0ea7",
   "metadata": {},
   "source": [
    "##### Given suffixes of unique task names, print out their LOS info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_suffixes = [\n",
    "    58220, 13670, 95515, 75390, 72070, 39522, # ss 14\n",
    "    51035, 75909, 24631, 13998, 89847, 61397, \"00316\", \"06845\", 69640, 69606, 60408, 48226, 60079, 57243, 69998\n",
    "]\n",
    "\n",
    "print(\"These are the saved sets for tasks whose unique names contain your inputed suffixes\")\n",
    "print(\"Total N:\", len(list_suffixes))\n",
    "\n",
    "for suff in list_suffixes:\n",
    "    inds = D.Dat[\"character\"].str.contains(str(suff))\n",
    "    df = D.Dat[inds]\n",
    "    idxs = df.index\n",
    "    assert len(df[\"character\"].unique())==1, \"mutlipel tasks with similar suffix...\"\n",
    "    \n",
    "    Task = D.Dat.iloc[idxs[0]][\"Task\"]\n",
    "    \n",
    "    print(Task.get_los_id())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0220ae9",
   "metadata": {},
   "source": [
    "##### investigating dataset for missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ebef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = D.Dat\n",
    "\n",
    "# slice out specific date\n",
    "date = df[df[\"datetime\"].str.contains(\"220308\")]\n",
    "\n",
    "# plot all trials in each session\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(1,3):\n",
    "    session = date[date[\"session\"].eq(i)]\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(session[\"trial\"],session[\"task_stagecategory\"], \"-o\")\n",
    "\n",
    "# slice out specific task\n",
    "date[date[\"unique_task_name\"].str.contains(\"51788\")]\n",
    "\n",
    "# examine all TEST tasks, see if they are displayed in both horiz/vert (for chunkbyshape2)\n",
    "test_data = df.loc[df[\"monkey_train_or_test\"]==\"test\"]\n",
    "test_task_names = test_data[\"unique_task_name\"].unique()\n",
    "\n",
    "print(\"TEST TASKS\")\n",
    "for t in test_task_names:\n",
    "    all_tasks_with_name_t = test_data.loc[test_data[\"unique_task_name\"]==t]\n",
    "    print(all_tasks_with_name_t[\"epoch\"].unique()) # should print ['vert', 'horiz'] for ALL tasks\n",
    "    \n",
    "# examine all TRAIN tasks, see if they are displayed in both horiz/vert (for chunkbyshape2)\n",
    "train_data = df.loc[df[\"monkey_train_or_test\"]==\"train\"]\n",
    "train_task_names = train_data[\"unique_task_name\"].unique()\n",
    "\n",
    "print(\"TRAIN TASKS\")\n",
    "for t in train_task_names:\n",
    "    all_tasks_with_name_t = train_data.loc[train_data[\"unique_task_name\"]==t]\n",
    "    print(all_tasks_with_name_t[\"epoch\"].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dbe0a",
   "metadata": {},
   "source": [
    "##### Get count of num trials for each test task, grouped by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = D.filterPandas({\"monkey_train_or_test\":[\"test\"]}, \"dataframe\")\n",
    "sns.catplot(data=dftest, x=\"character\", y=\"epoch\", hue=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "dftest = D.filterPandas({\"task_stagecategory\":[\"mixture2-ss-4\"]}, \"dataframe\")\n",
    "fig = sns.catplot(data=dftest, x=\"character\", y=\"epoch\", hue=\"date\", height=10, kind=\"swarm\")\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "rotateLabel(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcf169",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.groupby([\"character\", \"epoch\"]).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-manhattan",
   "metadata": {},
   "source": [
    "### [hand pick tasks to plot] [\"CRCNS\" plots] (also can choose whether to color by order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDIR_MAIN\n",
    "from pythonlib.tools.expttools import makeTimeStamp\n",
    "\n",
    "SDIR = f\"{SDIR_MAIN}/FIGS/drawfigs/handpicked-epoch_by_trial/{makeTimeStamp()}\"\n",
    "\n",
    "os.makedirs(SDIR, exist_ok=True)\n",
    "print(SDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.dataset.plots import plot_beh_grid_flexible_helper\n",
    "\n",
    "niters = 12\n",
    "\n",
    "if True:\n",
    "    # Enter partial names by hand, in order\n",
    "    \n",
    "    # gridlinecircle, Ilker Yildirim talk\n",
    "    list_tasks_partial = [\n",
    "        \"092894\",\n",
    "#         \"597648\", # missing baseline..\n",
    "        \"21199\",\n",
    "        \"02226\",\n",
    "        \"10208\",\n",
    "        \"85544\",\n",
    "        \"11763\",\n",
    "        \"42064\",\n",
    "        \"54929\",\n",
    "        \"95290\"\n",
    "    ]\n",
    "\n",
    "    # convert to real names\n",
    "    list_tasks = D.Dat[\"character\"].unique().tolist()\n",
    "\n",
    "    list_tasks_this = []\n",
    "    for name_partial in list_tasks_partial:\n",
    "        x = [t for t in list_tasks if name_partial in t]\n",
    "        if len(x)!=1:\n",
    "            print(x)\n",
    "            print(name_partial)\n",
    "        \n",
    "        assert len(x)==1\n",
    "        list_tasks_this.append(x[0])\n",
    "\n",
    "\n",
    "else:\n",
    "    # Pick random n tasks\n",
    "    n = 8\n",
    "    import random\n",
    "    list_tasks_this = random.sample(list_tasks, n)\n",
    "    \n",
    "print(list_tasks_this)\n",
    "\n",
    "\n",
    "for i in range(niters):\n",
    "    figb, figt = plot_beh_grid_flexible_helper(D, \"epoch\", col_group=\"character\", col_levels=list_tasks_this, max_cols=len(list_tasks_this), max_rows=5, plotkwargs={\"strokes_by_order\":True})\n",
    "    # figb, figt = plot_beh_grid_grouping_vs_task(dfdat, row_variable, tasklist, plotkwargs={\"strokes_by_order\":True})\n",
    "    figb.savefig(f\"{SDIR}/epoch_vs_character-color_by_order-iter_{i}-beh.pdf\")\n",
    "    figt.savefig(f\"{SDIR}/epoch_vs_character-color_by_order-iter_{i}-task.pdf\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = Dtrain.Dat[\"supervision_stage\"].unique()\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.expttools import makeTimeStamp\n",
    "\n",
    "SDIR = f\"{SDIR_MAIN}/FIGS/drawfigs/traintasks-epoch-color_by_order\"\n",
    "\n",
    "os.makedirs(SDIR, exist_ok=True)\n",
    "print(SDIR)\n",
    "\n",
    "Dtrain = D.filterPandas({\"monkey_train_or_test\":[\"train\"]}, \"dataset\")\n",
    "Dtrain = Dtrain.filterPandas({\n",
    "    \"supervision_stage\":[(0, 0, 0)]}, \"dataset\")\n",
    "\n",
    "for i in range(niters):\n",
    "    figb, figt = plot_beh_grid_flexible_helper(Dtrain, \"epoch\", col_group=\"trial_shuffled\", \n",
    "                                               max_cols=10, max_rows=5, plotkwargs={\"strokes_by_order\":True})\n",
    "    figb.savefig(f\"{SDIR}/iter_{i}-beh.pdf\")\n",
    "    figt.savefig(f\"{SDIR}/iter_{i}-task.pdf\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-madison",
   "metadata": {},
   "source": [
    "## Visual accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-business",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "animal = \"Red\"\n",
    "expt = \"lines5\"\n",
    "\n",
    "# --------------------------------\n",
    "D = Dataset([])\n",
    "D.load_dataset_helper(animal, expt)\n",
    "\n",
    "# SDIR_MAIN = f\"/data2/analyses/main/simple_summary/{animal}-{expt}\"\n",
    "# os.makedirs(SDIR_MAIN, exist_ok=True)\n",
    "\n",
    "# #### PLOT OVERVIEW OF EXPERIMENT\n",
    "# figlist = D.plotOverview()\n",
    "# for i, fig in enumerate(figlist):\n",
    "#     fig.savefig(f\"{SDIR_MAIN}/overview_{i}.pdf\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-bangkok",
   "metadata": {},
   "source": [
    "##### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) compute hd offline\n",
    "from pythonlib.tools.stroketools import strokesInterpolate2\n",
    "from pythonlib.drawmodel.strokedists import distscalarStrokes\n",
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "\n",
    "# Distance function\n",
    "DVER = \"position_hd_soft\"\n",
    "def dfunc(strokes_beh, strokes_task):\n",
    "    return distscalarStrokes(strokes_beh, strokes_task, DVER, \n",
    "                             do_spatial_interpolate=False, do_spatial_interpolate_interval = 10)\n",
    "\n",
    "D.Dat = applyFunctionToAllRows(D.Dat, F, \"hdoffline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Filter to only in learning endpoint\n",
    "F = {\"insummarydates\":[True]}\n",
    "print(len(D.Dat))\n",
    "D.filterPandas(F, \"modify\")\n",
    "print(len(D.Dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythonlib.tools.stroketools import standardizeStrokes\n",
    "# strokes_in = strokes_beh_list[100]\n",
    "# strokes_this = standardizeStrokes(strokes_in, ver=\"centerize\")\n",
    "\n",
    "# from pythonlib.drawmodel.strokePlots import plotDatStrokes\n",
    "\n",
    "# fig, axes = plt.subplots(1,2)\n",
    "# plotDatStrokes(ax=axes.flatten()[0], strokes=strokes_in, pcol=\"k\")\n",
    "# plotDatStrokes(ax=axes.flatten()[1], strokes=strokes_this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Compute lower-bound on visual accuracy, based on shuffling across trials\n",
    "# i.e., what if no relationship between beh and stim?\n",
    "\n",
    "# -- group\n",
    "F = {\"epoch\":[1], \"taskgroup\":[\"G3\"]}\n",
    "Dthis = D.filterPandas(F, \"dataset\")\n",
    "\n",
    "# -- preprocess strokes\n",
    "# ---- recenter\n",
    "Dthis.preprocessGood(ver=None, params=[\"recenter\"])\n",
    "\n",
    "# ---- rescale\n",
    "\n",
    "# --- interpolate\n",
    "\n",
    "\n",
    "# Pull out dataframe\n",
    "dfthis = D.Dat\n",
    "\n",
    "\n",
    "assert False, \"confirm that recentering doesnt affect score. otherwise somethign is wrogn\"\n",
    "\n",
    "\n",
    "# -- get strokes\n",
    "strokes_beh_list = dfthis[\"strokes_beh\"].tolist()\n",
    "strokes_task_list = dfthis[\"strokes_task\"].tolist()\n",
    "\n",
    "# ---- interpolate once\n",
    "def dfunc(strokes_beh, strokes_task):\n",
    "    return distscalarStrokes(strokes_beh, strokes_task, \"position_hd_soft\", \n",
    "                             do_spatial_interpolate=True, do_spatial_interpolate_interval = 10,\n",
    "                                return_strokes_only=True)\n",
    "S = [dfunc(sb, st) for sb, st in zip(strokes_beh_list, strokes_task_list)]\n",
    "# break out\n",
    "strokes_beh_list = [SS[0] for SS in S]\n",
    "strokes_task_list = [SS[1] for SS in S]\n",
    "\n",
    "# -- compute actual dstiances\n",
    "def dfunc(strokes_beh, strokes_task):\n",
    "    return distscalarStrokes(strokes_beh, strokes_task, \"position_hd_soft\", \n",
    "                             do_spatial_interpolate=False, do_spatial_interpolate_interval = 10)\n",
    "dists_actual = [dfunc(sb, st) for sb, st in zip(strokes_beh_list, strokes_task_list)]\n",
    "\n",
    "# -- SHUFFLE - shuffle relation between strokes\n",
    "niter = 100\n",
    "strokes_task_list_perm = [[s.copy() for s in strokes] for strokes in strokes_task_list]\n",
    "out = []\n",
    "for i in range(niter):\n",
    "    import random\n",
    "    random.shuffle(strokes_task_list_perm)\n",
    "\n",
    "    # --- pairwise distances\n",
    "    dists_perm = [dfunc(sb, st) for sb, st in zip(strokes_beh_list, strokes_task_list_perm)]\n",
    "    \n",
    "    out.append({\n",
    "        \"iter\":i,\n",
    "        \"dists\":dists_perm\n",
    "    })\n",
    "\n",
    "    if False:\n",
    "        plt.figure()\n",
    "        plt.hist(dists_actual)\n",
    "        plt.hist(dists_perm)\n",
    "        \n",
    "if niter<20:\n",
    "    plt.figure()\n",
    "    plt.hist(dists_actual)\n",
    "    for o in out:\n",
    "        plt.hist(o[\"dists\"], histtype=\"step\")\n",
    "    plt.title(\"actual + perms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(dists_actual)\n",
    "for o in out:\n",
    "    plt.hist(o[\"dists\"], histtype=\"step\")\n",
    "plt.title(\"actual + perms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shuffle(val_actual, vals_shuff, nbins=20):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.hist(vals_shuff, nbins)\n",
    "    ax.axvline(val_actual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == for each trial, convert to a percentile, reltaive to shuffle distribution.\n",
    "dp = np.c_[[o[\"dists\"] for o in out]]\n",
    "da = np.array(dists_actual)[None, :]\n",
    "\n",
    "nlist =[]\n",
    "for i in range(da.shape[1]):\n",
    "    nlist.append(np.sum(dp[:, i]<=da[:,i]))\n",
    "    \n",
    "# convert to percentile\n",
    "percentiles = np.array(nlist)/niter\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(percentiles)\n",
    "print(np.max(percentiles))\n",
    "plt.xlabel('percentile (beh vs shuffle dist)')\n",
    "plt.title('beh-task distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: wrap all of above into something like this\n",
    "preprocess(D.Dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUMMARY AGGREGATION\n",
    "from pythonlib.tools.pandastools import summarize_feature, summarize_featurediff\n",
    "\n",
    "GROUPING = [\"epoch\"]\n",
    "INDEX = [\"character\", \"monkey_train_or_test\",\"taskgroup\"]\n",
    "FEATURE_NAMES = [\"hdoffline\"]\n",
    "dfagg, dfaggflat = summarize_feature(D.Dat, GROUPING, FEATURE_NAMES, INDEX=INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT VISUAL SCORES\n",
    "tg = \"train_fixed\"\n",
    "dfthis = dfaggflat[dfaggflat[\"taskgroup\"]==tg]\n",
    "dfthis = dfaggflat\n",
    "# fig = sns.catplot(data=dfthis, x=\"character\", y=\"value\", col=\"taskgroup\", hue=\"epoch\")\n",
    "fig = sns.catplot(data=dfthis, x=\"taskgroup\", y=\"value\", hue=\"epoch\")\n",
    "fig = sns.catplot(data=dfthis, x=\"taskgroup\", y=\"value\", hue=\"epoch\", kind=\"boxen\")\n",
    "fig = sns.catplot(data=dfthis, x=\"taskgroup\", y=\"value\", hue=\"epoch\", kind=\"point\", ci=68)\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-leadership",
   "metadata": {},
   "source": [
    "##### Lower bound --> take the most similar behavior during training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsub = D.copy()\n",
    "ind = 120\n",
    "Dsub.plotSingleTrial(ind, sharex=True, sharey=True);\n",
    "Dsub.preprocessGood(params=[\"interp_spatial_int\"])\n",
    "Dsub.plotSingleTrial(ind, sharex=True, sharey=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"TODO confirm that recentering doesnt affect score. otherwise somethign is wrogn\")\n",
    "\n",
    "F = {\"epoch\":[1], \"taskgroup\":[\"G3\"]}\n",
    "strokes_beh_list, strokes_task_list, Dsub = D.extractStrokeLists(F, recenter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance function\n",
    "DVER = \"position_hd_soft\"\n",
    "def dfunc(strokes_beh, strokes_task):\n",
    "    return distscalarStrokes(strokes_beh, strokes_task, DVER, \n",
    "                             do_spatial_interpolate=False, do_spatial_interpolate_interval = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_visual(datasets, constant_dset, constant_kind, shuffle_dset, shuffle_kind, \n",
    "                niter=100, post_process=\"keep_all\"):\n",
    "    \"\"\" wrapper to score and shuffle, based on visual distances\n",
    "    INPUTS:\n",
    "    - datasets, list of Dataset, [D1, D2], ... can be any length. but \n",
    "    the indices in constant_dset and shuffle_dset will index into this...\n",
    "    - constant_dset, which dset (0, 1, 2... indexing into datasets) to hold \n",
    "    constant for shuffle analysis.\n",
    "    - constant_kind, which kind (\"task\", \"beh\") to hold constant. \n",
    "    - post_process, what to do will all distances. \n",
    "    --- keep_all, does nothing, returns all distances\n",
    "    --- smallest, takes the best distance [assumes smaller is better]\n",
    "    NOTE: in combination, constant_dset and constant_kind determine which strokes \n",
    "    (i.e., strokes_beh or strokes_task) to hold constant.\n",
    "    - shuffle_dset, shuffle_kind, similar to constant.. except this says which strokes\n",
    "    to shuffle \n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    # Extract strokes_lists.\n",
    "    def _extract(dsetnum, kind):\n",
    "        D = datasets[dsetnum]\n",
    "        print(D)\n",
    "        strokes_list_beh, strokes_list_task, D = extractStrokeLists(D, None, recenter=False, rescale=False)\n",
    "        if kind==\"beh\":\n",
    "            return strokes_list_beh\n",
    "        elif kind==\"task\":\n",
    "            return strokes_list_task\n",
    "        else:\n",
    "            assert False\n",
    "    \n",
    "    strokes_list_constant = _extract(constant_dset, constant_kind)\n",
    "    strokes_list_shuffle = _extract(shuffle_dset, shuffle_kind)\n",
    "    \n",
    "    out = []\n",
    "    for i, strokes_constant in enumerate(strokes_list_constant):\n",
    "        dists = [dfunc(strokes_constant, s) for s in strokes_list_shuffle]\n",
    "        out.append({\n",
    "            \"index\":i,\n",
    "            \"dists\":dists\n",
    "        })\n",
    "        \n",
    "    if post_process==\"keep_all\":\n",
    "        pass\n",
    "    elif post_process==\"sorted\":\n",
    "        for o in out:\n",
    "            dists = o[\"dists\"]\n",
    "            tmp = [(i, d) for i,d in enumerate(dists)]\n",
    "            tmp = sorted(tmp, key=lambda x:x[1])\n",
    "            o[\"dists_sorted_index\"] = [t[0] for t in tmp]\n",
    "            o[\"dists_sorted\"] = [t[1] for t in tmp]\n",
    "    elif post_process==\"smallest\":\n",
    "        for o in out:\n",
    "            o[\"dist_best\"] = min(o[\"dists\"])\n",
    "            o[\"dist_best_index\"] = o[\"dists\"].index(min(o[\"dists\"]))\n",
    "    else:\n",
    "        assert False\n",
    "        \n",
    "    return out\n",
    "    \n",
    "#     # Go thru each item in \"constant\" and for each, get score against all items in shuffle.\n",
    "#     strokes_list_shuffle_perm = [[s.copy() for s in strokes] for strokes in strokes_list_shuffle]\n",
    "#     out = []\n",
    "#     for i in range(niter):\n",
    "#         random.shuffle(strokes_list_shuffle_perm)\n",
    "\n",
    "#         # --- pairwise distances\n",
    "#         dists_perm = [dfunc(sb, st) for sb, st in zip(strokes_list_constant, strokes_list_shuffle_perm)]\n",
    "\n",
    "#         out.append({\n",
    "#             \"iter\":i,\n",
    "#             \"dists\":dists_perm\n",
    "#         })\n",
    "\n",
    "#         if False:\n",
    "#             plt.figure()\n",
    "#             plt.hist(dists_actual)\n",
    "#             plt.hist(dists_perm)\n",
    "\n",
    "    \n",
    "\n",
    "# Extract datasets\n",
    "epoch = 1\n",
    "F = {\"epoch\":[epoch], \"taskgroup\":[\"G3\"]}\n",
    "Dtest = D.filterPandas(F, \"dataset\")\n",
    "Dtest.preprocessGood(params=[\"recenter\", \"interp_spatial_int\"])\n",
    "F = {\"epoch\":[epoch], \"taskgroup\":[\"train_fixed\", \"train_random\"]}\n",
    "Dtrain = D.filterPandas(F, \"dataset\")\n",
    "Dtrain.preprocessGood(params=[\"recenter\", \"interp_spatial_int\"])\n",
    "\n",
    "# Preprocess both datasets\n",
    "\n",
    "\n",
    "# score\n",
    "# - actual distance (test tasks)\n",
    "strokes_list_beh, strokes_list_task = extractStrokeLists(Dtest, None, recenter=True)[:2]\n",
    "dists_actual_test = [dfunc(sb, st) for sb, st in zip(strokes_list_beh, strokes_list_task)]\n",
    "\n",
    "strokes_list_beh, strokes_list_task = extractStrokeLists(Dtrain, None, recenter=True)[:2]\n",
    "dists_actual_train = [dfunc(sb, st) for sb, st in zip(strokes_list_beh, strokes_list_task)]\n",
    "# out = score_visual([Dtest], 0, \"task\", 0, \"beh\") # to shuffle task-beh\n",
    "\n",
    "# score to find \"best train beh\"\n",
    "out = score_visual([Dtrain, Dtest], 1, \"task\", 0, \"beh\", post_process=\"sorted\") # to find \"best train beh\"\n",
    "\n",
    "# -- sanity check, compare datset to itself\n",
    "# out, Dtest, Dtrain = score_visual([Dtest, Dtest], 1, \"task\", 0, \"beh\", post_process=\"sorted\") # to find \"best train beh\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_negcontrol = score_visual([Dtest], 0, \"task\", 0, \"beh\") # to shuffle task-beh\n",
    "out_negcontrol_train = score_visual([Dtrain], 0, \"task\", 0, \"beh\") # to shuffle task-beh\n",
    "\n",
    "dists_negcontrol = [np.median(o[\"dists\"]) for o in out_negcontrol]\n",
    "dists_negcontrol_train = [np.median(o[\"dists\"]) for o in out_negcontrol_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_bestfromtrain = [o[\"dists_sorted\"][0] for o in out]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT\n",
    "ind = 127\n",
    "nplot = 5\n",
    "\n",
    "# plot actual\n",
    "Dtest.plotSingleTrial(ind);\n",
    "print(dists_actual_test[ind])\n",
    "\n",
    "# plot the top 5 closest from the other dataset\n",
    "dists_sorted = out[ind][\"dists_sorted\"][:nplot]\n",
    "dists_sorted_index = out[ind][\"dists_sorted_index\"][:nplot]\n",
    "Dtrain.plotMultTrials(dists_sorted_index, which_strokes=\"strokes_task\");\n",
    "Dtrain.plotMultTrials(dists_sorted_index, titles=dists_sorted);\n",
    "# print(index_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT\n",
    "ind = 127\n",
    "nplot = 5\n",
    "\n",
    "# plot actual\n",
    "Dtest.plotSingleTrial(ind);\n",
    "print(dists_actual_test[ind])\n",
    "\n",
    "# plot the top 5 closest from the other dataset\n",
    "dists_sorted = out[ind][\"dists_sorted\"][:nplot]\n",
    "dists_sorted_index = out[ind][\"dists_sorted_index\"][:nplot]\n",
    "Dtrain.plotMultTrials(dists_sorted_index, which_strokes=\"strokes_task\");\n",
    "Dtrain.plotMultTrials(dists_sorted_index, titles=dists_sorted);\n",
    "# print(index_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot statistics\n",
    "# for each trial, take the best matching from training\n",
    "plt.figure()\n",
    "plt.hist(dists_actual_train)\n",
    "plt.hist(dists_actual_test)\n",
    "plt.hist(dists_bestfromtrain)\n",
    "plt.hist(dists_negcontrol)\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(dists_actual_train)\n",
    "plt.boxplot(dists_actual_test)\n",
    "plt.boxplot(dists_bestfromtrain)\n",
    "plt.boxplot(dists_negcontrol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot statistics\n",
    "# for each trial, take the best matching from training\n",
    "plt.figure()\n",
    "plt.hist(dists_actual_train)\n",
    "plt.hist(dists_actual_test)\n",
    "plt.hist(dists_bestfromtrain)\n",
    "plt.hist(dists_negcontrol)\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(dists_actual_train)\n",
    "plt.boxplot(dists_actual_test)\n",
    "plt.boxplot(dists_bestfromtrain)\n",
    "plt.boxplot(dists_negcontrol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = []\n",
    "def _append(dists, kind):\n",
    "    for d in dists:\n",
    "        dat.append(\n",
    "            {\"kind\":kind,\n",
    "             \"dist\":d}\n",
    "        )\n",
    "_append(dists_actual_train, \"actual_train\")\n",
    "_append(dists_actual_test, \"actual_test\")\n",
    "_append(dists_bestfromtrain, \"best_from_train\")\n",
    "_append(dists_negcontrol, \"shuffle_test\")\n",
    "dat = pd.DataFrame(dat)\n",
    "\n",
    "# normalize, so is positive, deviation from shuffle\n",
    "if False:\n",
    "    lower_bound = dat[dat[\"kind\"]==\"shuffle_test\"][\"dist\"].mean()\n",
    "#     lower_bound = 0\n",
    "    dat[\"dist\"] = -(dat[\"dist\"]-lower_bound)\n",
    "\n",
    "sns.catplot(data=dat, x=\"kind\", hue=\"kind\", y=\"dist\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = []\n",
    "def _append(dists, kind):\n",
    "    for d in dists:\n",
    "        dat.append(\n",
    "            {\"kind\":kind,\n",
    "             \"dist\":d}\n",
    "        )\n",
    "_append(dists_actual_train, \"actual_train\")\n",
    "_append(dists_actual_test, \"actual_test\")\n",
    "_append(dists_bestfromtrain, \"best_from_train\")\n",
    "_append(dists_negcontrol, \"shuffle_test\")\n",
    "dat = pd.DataFrame(dat)\n",
    "\n",
    "# normalize, so is positive, deviation from shuffle\n",
    "if False:\n",
    "    lower_bound = dat[dat[\"kind\"]==\"shuffle_test\"][\"dist\"].mean()\n",
    "#     lower_bound = 0\n",
    "    dat[\"dist\"] = -(dat[\"dist\"]-lower_bound)\n",
    "\n",
    "sns.catplot(data=dat, x=\"kind\", hue=\"kind\", y=\"dist\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 100\n",
    "sb = strokes_beh_list[ind]\n",
    "st = strokes_task_list[ind]\n",
    "\n",
    "# actual distance (beh-task)\n",
    "d_actual = dfunc(sb, st)\n",
    "\n",
    "# list of distances between (task) and (all beh from training)\n",
    "d_shuff_list = [dfunc(x, st) for x in strokes_beh_list_train] \n",
    "\n",
    "# pull out index for the closest match\n",
    "tmp = [(i, d) for i,d in enumerate(d_shuff_list)]\n",
    "tmp = sorted(tmp, key=lambda x:x[1])\n",
    "index_sorted = [t[0] for t in tmp]\n",
    "dist_sorted = [t[1] for t in tmp]\n",
    "\n",
    "# plot top N indices\n",
    "Dsub.plotSingleTrial(ind);\n",
    "Dsub_train.plotMultTrials(index_sorted[:5], which_strokes=\"strokes_task\");\n",
    "Dsub_train.plotMultTrials(index_sorted[:5]);\n",
    "# print(index_sorted)\n",
    "\n",
    "# Take score for the top matching from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shuffle(d_actual, d_shuff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUMMARIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.distfunctools import modHausdorffDistance\n",
    "S1 = np.random.rand(10,2)\n",
    "S2 = np.random.rand(20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1+np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modHausdorffDistance(S1,S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array([0.1, 0.1])\n",
    "modHausdorffDistance(S1+tmp,S2+tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsub.plotSingleTrial(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsub_c.plotSingleTrial(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a single distance\n",
    "def dfunc(strokes_beh, strokes_task):\n",
    "    return distscalarStrokes(strokes_beh, strokes_task, \"position_hd_soft\", \n",
    "                             do_spatial_interpolate=False, do_spatial_interpolate_interval = 10)\n",
    "dfunc(strokes_beh_list[0], strokes_task_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compute actual dstiances\n",
    "def dfunc(strokes_beh, strokes_task):\n",
    "    return distscalarStrokes(strokes_beh, strokes_task, \"position_hd_soft\", \n",
    "                             do_spatial_interpolate=False, do_spatial_interpolate_interval = 10)\n",
    "dists_actual = [dfunc(sb, st) for sb, st in zip(strokes_beh_list, strokes_task_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that not just reproducing memorized sequences from train\n",
    "# --- basic stats are different (num strokes)\n",
    "# --- plot a grid to show difference\n",
    "# --- find closest \"pair\" across groups, show there is no close (do this for both task and beh)\n",
    "# --- show that diff trials for same task have more similar beh than across tasks.\n",
    "\n",
    "# --- Show variability in motor stats --> onset location, direciotn, etc.\n",
    "# ----- variable across tasks, but consistency within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by variables:\n",
    "# --- epoch, character,\n",
    "# --- split into random and fixed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-growth",
   "metadata": {},
   "source": [
    "##### Summarize score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-aside",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- For a given task, plot over time\n",
    "\n",
    "# --- Group tasks into: train_fixed, train_random, test_G2, test_G3, test_G4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-oriental",
   "metadata": {},
   "source": [
    "### Rule-based score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each rule, do the folliwng:\n",
    "# 1) Not model based. predictions about some kind of motor statistic\n",
    "# 2) Model based --> predict motor behavior ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-fifteen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-conversation",
   "metadata": {},
   "source": [
    "### Motor biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly descriptive\n",
    "# --- Overall direction bias\n",
    "# --- Within stroke direction bias.\n",
    "# ------ No correlation between these.\n",
    "# --- If don't think of this as strokes, then how many different trajectories have to do?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-court",
   "metadata": {},
   "source": [
    "### Action categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate with strok manifold analysis.\n",
    "# -- categorize each stroke.\n",
    "\n",
    "# Stereotyped ordering of shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-rugby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d39168",
   "metadata": {},
   "source": [
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba08fc0",
   "metadata": {},
   "source": [
    "##### Renaming tasks using new los info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(D.Dat.iloc[501])\n",
    "pd.set_option('display.max_rows', 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task = D.Dat.iloc[500][\"Task\"]\n",
    "print(Task.get_task_id())\n",
    "print(Task.get_category_setnum())\n",
    "print(Task.get_los_id())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task.get_number_hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808f9fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.Dat[\"monkey_train_or_test\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76da7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f15dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394c67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
