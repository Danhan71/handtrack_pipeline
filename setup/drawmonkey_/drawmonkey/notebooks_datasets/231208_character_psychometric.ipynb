{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Psychometric stuff.\n",
    "\n",
    "# See notes here:\n",
    "# - Evernote: https://www.evernote.com/shard/s101/nl/11215139/42869e39-d0af-4935-a285-46236ef79adc?title=Psychometric\n",
    "(hav elooked thru, nothing missing that should be here).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.dataset.dataset_analy.primitives import *\n",
    "from pythonlib.dataset.dataset_preprocess.primitives import *\n",
    "from pythonlib.dataset.dataset import Dataset, load_dataset, load_dataset_daily_helper\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "749139b24e5ed65e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Chars\n",
    "# animal = \"Pancho\"\n",
    "# date = \"230127\"\n",
    "\n",
    "animal = \"Diego\"\n",
    "date = \"231211\"\n",
    "\n",
    "D = load_dataset_daily_helper(animal, date)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33cf1e98be74a03f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How to represent task so that can easily cluster into psychometric groups"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0255a1766a01b41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T.PlanDat.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1b3ebf39b45cdee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set of base-level prims and their locations\n",
    "T.PlanDat[\"Plan\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8e0c15d0b68d931"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "T.get_shapes_hash()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2defdc515c1acef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Distance metric for comparing characters\n",
    "# - first, between prims (score for locaiton and shape distnace\n",
    "\n",
    "# Or simply use pixel distance, after transforming one to maximally algin with the other. \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bc46d295f2661fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.strokes2image(\"strokes_task\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "897bd21a27bd8458"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### old code From analy_psychometric notebook"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0f500a2f1d0aee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sdir = f\"/data2/analyses/main/psychometric/monkey/{animal}-{expt}/plots\"\n",
    "os.makedirs(sdir, exist_ok=True)\n",
    "from pythonlib.dataset.psychometric import plotMultTaskcategories\n",
    "for max_n_per_grid in [None] + list(range(5)):\n",
    "    sdirthis = f\"{sdir}/npergrid_{max_n_per_grid}\"\n",
    "    os.makedirs(sdirthis, exist_ok=True)\n",
    "    plotMultTaskcategories(D, sdir=sdirthis, max_n_per_grid=max_n_per_grid)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31c953793e715c4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# each task extract its number\n",
    "\n",
    "\n",
    "# update grid plot code to work with strokes list\n",
    "\n",
    "#### 2) compute some scalar score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d8abd9ec30629fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NEW METHOD - using shapes and their locations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67e8dd19350b1a8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) Get graph represnetation of each char\n",
    "\n",
    "# Extract base prims for each char\n",
    "ind = 403\n",
    "ind2 = 404\n",
    "# D.Dat[\"\"]\n",
    "list_shloc1 = D.taskclass_shapes_loc_configuration_extract(ind, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "list_shloc2 = D.taskclass_shapes_loc_configuration_extract(ind2, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "\n",
    "D.plotMultTrials2([ind, ind2])\n",
    "D.plotMultTrials2([ind, ind2], \"strokes_task\")\n",
    "\n",
    "\n",
    "print(list_shloc1)\n",
    "print(list_shloc2)\n",
    "# 2) Find related chars"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc1b3b1fce3eda5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _dist_sh(sh1, sh2):\n",
    "    \"\"\"\n",
    "    Dist (from 0 to 1) between these shape strings. counts up how many\n",
    "    mathces out fo the 4 substrings, and then norms to 0 and 1.\n",
    "    sh = 'line-11-1-0'\n",
    "    \"\"\"\n",
    "    from pythonlib.tools.stringtools import decompose_string\n",
    "    \n",
    "    NTOT = 4\n",
    "    \n",
    "    sh1_list = decompose_string(sh1, \"-\")\n",
    "    sh2_list = decompose_string(sh2, \"-\")\n",
    "    # print(sh1)\n",
    "    # print(sh1_list)\n",
    "    # assert False\n",
    "    assert len(sh1_list)==NTOT\n",
    "    assert len(sh2_list)==NTOT\n",
    "    \n",
    "    nmatch = sum([x==y for x,y in zip(sh1_list, sh2_list)])\n",
    "    \n",
    "    # normalize \n",
    "    dist = 1 - nmatch/NTOT\n",
    "    \n",
    "    return dist\n",
    "    \n",
    "# _dist_sh(shloc1[0][0], shloc1[6][0])\n",
    "\n",
    "\n",
    "DIAG = D.sketchpad_compute_diagonal_using_all_strokes()\n",
    "\n",
    "def _dist_loc(loc1, loc2):\n",
    "    \"\"\" Eucl dist between two locations, normalized to 0 and 1\n",
    "    - loc, (2,) array.\n",
    "    RETURNS:\n",
    "    - dist, scalar, normalized between 0 (same) and 1 (sketchpad diag).\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(loc1, list):\n",
    "        loc1 = np.array(loc1)\n",
    "        loc2 = np.array(loc2)\n",
    "        \n",
    "    d_eucl = np.linalg.norm(loc1 - loc2)\n",
    "    \n",
    "    # normalize to max.\n",
    "    dist = d_eucl/DIAG\n",
    "    \n",
    "    return dist\n",
    "\n",
    "def _dist_shloc(shloc1, shloc2):\n",
    "    \"\"\"\n",
    "    - shloc, (sh string, loc xy)\n",
    "    \"\"\"\n",
    "    d1 = _dist_sh(shloc1[0], shloc2[0])\n",
    "    d2 = _dist_loc(shloc1[1], shloc2[1])\n",
    "    return np.mean([d1, d2])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5746c8ddc0b3c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Given two shape_loc configs, compute their distance\n",
    "# for each (shape,loc) object in one task, get its min distance to all in other task.\n",
    "\n",
    "def _dist(list_shloc1, list_shloc2):\n",
    "    \"\"\" Distance between two shape/loc objects\n",
    "    - shloc = (shape string, loc num(2,1))\n",
    "    \"\"\"\n",
    "            \n",
    "    distmat = np.asarray([[_dist_shloc(shloc1, shloc2) for shloc2 in list_shloc2] for shloc1 in list_shloc1]) # (len1, len2)\n",
    "\n",
    "    # get mean across both dimensions\n",
    "    d1 = np.mean(np.min(distmat, axis=0))\n",
    "    d2 = np.mean(np.min(distmat, axis=1))\n",
    "    dall = np.mean([d1, d2])\n",
    "    \n",
    "    return dall\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d8e2c19c6e48779"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SDIR = D.make_savedir_for_analysis_figures_BETTER(\"char_psycho\")\n",
    "sdir = f\"{SDIR}/best_matches_for_each_char\"\n",
    "import os\n",
    "os.makedirs(sdir, exist_ok=True)\n",
    "print(sdir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1480aebc39ff1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# include only chars\n",
    "Dc = D.copy()\n",
    "Dc.Dat = Dc.Dat[Dc.Dat[\"task_kind\"]==\"character\"].reset_index(drop=True)\n",
    "Dc.preprocessGood(params=[\"no_supervision\", \"remove_online_abort\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "758ead229625b272"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_char = Dc.Dat[\"character\"].unique().tolist()\n",
    "inds, list_char = Dc.taskcharacter_extract_examples(list_char)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e65a44c7c299a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first collect pairwise between all chars.\n",
    "# Then make plots using that info.\n",
    "\n",
    "# get map from ind to score\n",
    "map_char_listshloc = {}\n",
    "\n",
    "for ind, char in zip(inds, list_char):\n",
    "    list_shloc = Dc.taskclass_shapes_loc_configuration_extract(ind, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "    map_char_listshloc[char] = list_shloc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd46cb3955252dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "distances = {}\n",
    "for i in range(len(inds)):\n",
    "    print(i)\n",
    "    for j in range(i+1, len(inds)):\n",
    "        ind1 = inds[i]\n",
    "        char1 = list_char[i]\n",
    "        \n",
    "        ind2 = inds[j]\n",
    "        char2 = list_char[j]\n",
    "        \n",
    "        list_shloc1 = map_char_listshloc[char1]\n",
    "        list_shloc2 = map_char_listshloc[char2]\n",
    "        \n",
    "        distances[(i, j)] = _dist(list_shloc1, list_shloc2)\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "821890bdcbf37515"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ni = np.max(np.asarray(list(distances.keys())), axis=0)[0]\n",
    "# nj = np.max(np.asarray(list(distances.keys())), axis=0)[1]\n",
    "\n",
    "ni = len(list_char)\n",
    "nj = len(list_char)\n",
    "\n",
    "# plot in heatmap\n",
    "distances_mat = np.zeros((ni, nj))\n",
    "for i in range(ni):\n",
    "    \n",
    "    # Assymetric\n",
    "    # for j in range(i+1, nj):\n",
    "    #     distances_mat[i, j] = distances[(i, j)]\n",
    "    \n",
    "    # Symmetric\n",
    "    for j in range(nj):\n",
    "        if j==i:\n",
    "            distances_mat[i, j] = 0.0001\n",
    "        elif j>i:\n",
    "            distances_mat[i, j] = distances[(i, j)]\n",
    "        elif j<i:\n",
    "            distances_mat[i, j] = distances[(j,i)]\n",
    "        else:\n",
    "            assert False\n",
    "assert np.any(distances_mat==0.)==False, \"sanity check that modified all slots\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(distances_mat)\n",
    "plt.colorbar(im)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d49ae7cc9595a9d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Given a single char, get its score against all other char\n",
    "i=103\n",
    "list_score = distances_mat[i,:]\n",
    "charthis = list_char[i]\n",
    "print(charthis)\n",
    "Dc._taskcharacter_find_plot_sorted_by_score(list_char, list_score, True, \"/tmp\", 1, 20, \"test\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b03a9a497dd07a69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dc.Dat[\"task_stagecategory\"].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96a95c9e7997f257"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# list_task_stagecategory = [\"charstrokeseq-ss-49\"]\n",
    "list_task_stagecategory = [\"charstrokeseq-ss-65\", \"charstrokeseq-ss-64\", \"charstrokeseq-ss-63\", \"charstrokeseq-ss-66\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbffca0edc793794"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Go thru all chars\n",
    "nsubplots = 20\n",
    "\n",
    "for i, charthis in enumerate(list_char):\n",
    "    list_score = distances_mat[i,:]\n",
    "    print(charthis)\n",
    "    \n",
    "    # Check if char is in desired list of cats\n",
    "    catthis = Dc.Dat[Dc.Dat[\"character\"]==charthis][\"task_stagecategory\"].tolist()[0]\n",
    "    \n",
    "    if catthis in list_task_stagecategory:\n",
    "        \n",
    "        Dc._taskcharacter_find_plot_sorted_by_score(list_char, list_score, True, sdir, 1, nsubplots, charthis,\n",
    "                                                    plot_which=\"worst\")\n",
    "        plt.close(\"all\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4652e164a4f26bfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Check that the prims extracted across the dataset are reasonable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "269dd8e5f86082d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.taskclass_shapes_extract_unique_alltrials()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81d1bb55d190fce5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Account for the centering, this leads to incorrect location scores.\n",
    "# Should use relational coords?\n",
    "# Or graph representation?\n",
    "# ---> Best: do realignement of some sort... using image?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c037b12db3625f6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.plotSingleTrial(ind1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17b1761162be38f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Represent prim using the (shape, scale, location of onset relative to center).\n",
    "\n",
    "Prim = tokens[0][\"Prim\"]\n",
    "Prim.extract_as()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d60df7652b7a34b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Prim.label_classify_prim()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "978ceb8ce44b8ede"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Tt = T.extract_monkeylogic_ml2_task()\n",
    "Tt.get_tasknew()[\"Plan\"].keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104255cbe1e51666"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Tt.get_tasknew()[\"Plan\"][\"PrimsExtraParams\"]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3e2cc0480d71b69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) check all tasks to see if abstract transforms are occuring.\n",
    "# 2) in computing angle, also compute to offset. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b7c0f09c2c7b3c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Prim.ParamsAbstract"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "794b8f5e495a734e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Prim.ParamsConcrete"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d2b9f6bb56f9563"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# example cahracters to compare, same psycho\n",
    "task = \"charstrokeseq-62-28-948510\"\n",
    "task = \"charstrokeseq-62-7-372727\"\n",
    "D.Dat[D.Dat[\"character\"]==task].index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c84adb154df2a61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "665"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78c77c9cb0ce0b93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind = 405\n",
    "T = D.Dat.iloc[ind][\"Task\"]\n",
    "T.PlanDat[\"RelsAttachIndicesAlongStrok_RelInd\"]\n",
    "T.PlanDat[\"PrimsAsStrings\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6336df2a427e5ed3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11a3623dc9d1e693"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f8d278460c7560c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### snaity check, plot tasks and overlay sh_loc on image\n",
    "\n",
    "import random\n",
    "inds = random.sample(range(len(D.Dat)), 20)\n",
    "\n",
    "D.plotMultTrials2(inds)\n",
    "fig, axes, idxs = D.plotMultTrials2(inds, \"strokes_task\")\n",
    "\n",
    "for ax, ind in zip(axes.flatten(), inds):\n",
    "    print(\"---------\", ind)\n",
    "    # T = D.Dat.iloc[ind][\"Task\"]\n",
    "    # T.PlanDat[\"RelsAttachIndicesAlongStrok_RelInd\"]\n",
    "    print(T.PlanDat[\"CentersActual\"])\n",
    "    list_shloc = D.taskclass_shapes_loc_configuration_extract(ind, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "    print(list_shloc)\n",
    "    \n",
    "    for i, shloc in enumerate(list_shloc):\n",
    "        sh = shloc[0]\n",
    "        loc = shloc[1]\n",
    "        ax.plot(loc[0], loc[1], \"or\")\n",
    "        t = f\"{i}_{sh}\"\n",
    "        ax.text(loc[0], loc[1], t, fontsize=6, color=\"b\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4125ef41a6ffab5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "inds = [665, 709]\n",
    "\n",
    "D.plotMultTrials2(inds)\n",
    "fig, axes, idxs = D.plotMultTrials2(inds, \"strokes_task\")\n",
    "\n",
    "for ax, ind in zip(axes.flatten(), inds):\n",
    "    print(\"---------\", ind)\n",
    "    # T = D.Dat.iloc[ind][\"Task\"]\n",
    "    # T.PlanDat[\"RelsAttachIndicesAlongStrok_RelInd\"]\n",
    "    print(T.PlanDat[\"CentersActual\"])\n",
    "    list_shloc = D.taskclass_shapes_loc_configuration_extract(ind, loc_version=\"pixel\")[\"shape_loc\"]\n",
    "    print(list_shloc)\n",
    "    \n",
    "    for i, shloc in enumerate(list_shloc):\n",
    "        sh = shloc[0]\n",
    "        loc = shloc[1]\n",
    "        ax.plot(loc[0], loc[1], \"or\")\n",
    "        t = f\"{i}_{sh}\"\n",
    "        ax.text(loc[0], loc[1], t, fontsize=6, color=\"b\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dfe378827d663d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.sequence_tokens_clear_behclass_and_taskclass()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "285dad3ce78f0bf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.behclass_preprocess_wrapper(True, False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6849fde749fdf767"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Get a trial's tokens and compare to plot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74585eb7de6e2fbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [GOOD] Delete all tokens for this trial\n",
    "if False:\n",
    "    T = D.Dat.iloc[ind][\"Task\"]\n",
    "    T._tokens_delete()\n",
    "    \n",
    "    Beh = D.Dat.iloc[ind][\"BehClass\"]\n",
    "    Beh.Alignsim_Datsegs = None\n",
    "    Beh.Alignsim_Datsegs_BehLength = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d91acebd22dd27ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind = 403\n",
    "T = D.Dat.iloc[ind][\"Task\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48de2e9863a132d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens = D.taskclass_tokens_extract_wrapper(ind, \"task\")\n",
    "D.plotSingleTrial(ind, task_add_num=True);\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "347eda1e3c64aaaf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T.plotStrokes(ordinal=True)\n",
    "for i, t in enumerate(tokens):\n",
    "    print(i, t[\"shape\"], t[\"center\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70088326693180e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.behclass_preprocess_wrapper(reset_tokens=True, skip_if_exists=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b20a1c38076a3a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T.primitives_extract_final()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "148b6957fef119f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.taskclass_shapes_loc_configuration_extract(ind, loc_version=\"pixel\")[\"shape_loc\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e193c74acfa82f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = D."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ab020ea3255e12a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T.PlanDat.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8ac8d3324b39707"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [BELOW IS OLD] Psychometric, taken from analy_dataset_summarize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cab29ac9bc392f06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9f6f8345b9690077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Rename tasks based on Plan. \n",
    "\n",
    "This allows matching tasks that have same abstract plan but different size, for eg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf696d22094166fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate all beh class\n",
    "D.behclass_generate_alltrials()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ff639bfab705594"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try a single trial\n",
    "ind = 100\n",
    "Beh = D.Dat.iloc[ind][\"BehClass\"]\n",
    "Task = D.Dat.iloc[ind][\"Task\"]\n",
    "Task.PlanDat[\"Plan\"]\n",
    "plan = Task.PlanDat[\"Plan\"]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed58e7416f13003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# convert plan to a hashable\n",
    "\n",
    "def _list_to_hashable(inlist):\n",
    "    \n",
    "    outlist = []\n",
    "    for i, this in enumerate(inlist):\n",
    "        if isinstance(this, list):\n",
    "            outlist.append(_list_to_hashable(this))\n",
    "#             inlist[i] = _list_to_hashable(this)\n",
    "        else:\n",
    "            outlist.append(str(this))\n",
    "#             inlist[i] = str(this)\n",
    "    return tuple(outlist)\n",
    "\n",
    "_list_to_hashable(plan)\n",
    "\n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57393a412a3e2437"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change all character names to \n",
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "def F(x):\n",
    "    Task = x[\"Task\"]\n",
    "    plan = Task.PlanDat[\"Plan\"]\n",
    "    return hash(_list_to_hashable(plan))\n",
    "\n",
    "D.Dat = applyFunctionToAllRows(D.Dat, F, \"planhash\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff1431b794091980"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract a single plan based on hash\n",
    "print(D.Dat[\"planhash\"].value_counts())\n",
    "\n",
    "inds = D.Dat[D.Dat[\"planhash\"]==4457446285971416165].index.tolist()\n",
    "D.plotMultTrials2(inds)\n",
    "D.plotMultTrials2(inds, \"strokes_task\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e280cfde6b092ec7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sdir = f\"{SAVEDIR_FIGS}/using_planhash/quick\"\n",
    "os.makedirs(sdir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfebdeb39469427b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort trials by size of grid\n",
    "def _get_grid_spacing(ind):\n",
    "    \"\"\" Get scalar spacing for grids, for this trial of D.Dat\n",
    "    NOTE: is quick and dirty, just gets the diff of centers,looking at x.\n",
    "    doesnt work if tasks have diff size due to cell size (not due to centers).\n",
    "    \"\"\"\n",
    "    Task = D.Dat.iloc[ind][\"Task\"]\n",
    "    par = Task.get_grid_params()\n",
    "    return par[\"grid_diff_x\"]\n",
    "\n",
    "_get_grid_spacing(100)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c707d2c1969dc711"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each planhash with > N trials, plot all the trials, sorted by something\n",
    "\n",
    "# 1. get all planhash with > N trials\n",
    "N = 5\n",
    "x = D.Dat[\"planhash\"].value_counts()\n",
    "list_planhash = [ph for ph, counts in zip(x.index, x.values) if counts > N]\n",
    "\n",
    "print(\"This many tasks :\", len(list_planhash))\n",
    "\n",
    "for planhash in list_planhash:\n",
    "    # get all trials for this ph\n",
    "    inds = D.Dat[D.Dat[\"planhash\"]==planhash].index.tolist()\n",
    "    \n",
    "    # sort by grid spacing size\n",
    "    x = [(i, _get_grid_spacing(i)) for i in inds]\n",
    "    x = sorted(x, key=lambda x: x[1])\n",
    "    inds = [xx[0] for xx in x]\n",
    "    sizes = [xx[1] for xx in x]\n",
    "    \n",
    "    # Plot\n",
    "    fig1, _, _ = D.plotMultTrials(inds, \"strokes_beh\", color_by=\"order\")\n",
    "    fig2 = D.plotMultTrials(inds, \"strokes_task\", titles=sizes)\n",
    "    \n",
    "    # save\n",
    "    fig1.savefig(f\"{sdir}/alltrials-chron-{planhash}-beh.pdf\")\n",
    "    fig2.savefig(f\"{sdir}/alltrials-chron-{planhash}-task.pdf\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea183125604e031a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### [Psychometric] Categorize tasks based on their psychonmetric groupings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc9e2cf7533415c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get a task for testing\n",
    "Task = D.Dat.iloc[0][\"Task\"]\n",
    "taskthis = Task.PlanDat[\"Plan\"] # look for tasks similar to this one"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b7dca2590245cd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HACK - reassing train test for motifchar3 based on fixed tasks\n",
    "\n",
    "def F(x):\n",
    "    if x[\"random_task\"]:\n",
    "        return \"train\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "    \n",
    "D.Dat = applyFunctionToAllRows(D.Dat, F, \"monkey_train_or_test\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51a8662fa8426c3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find task groupgings\n",
    "\n",
    "\n",
    "def check_tasks_same_psychometric_group(task, taskother, row_diff=3):\n",
    "    \"\"\" if taskother is in same psychometric group as task, then\n",
    "    returns True.\n",
    "    Detects bsaed on all plan being identical except a speciifc relatin\n",
    "    (curerntl yhard coded for motifchar3\n",
    "    PARAMS:\n",
    "    - task, taskother, TaskGeneral instances\n",
    "    \"\"\"\n",
    "    \n",
    "    def _check_row_same(row1, row2):\n",
    "        \"\"\" recusrsive, check tuples are same\n",
    "        \"\"\"\n",
    "        return row1==row2\n",
    "#         if isinstance(row1, tuple):\n",
    "#             if not isinstance(row2, tuple):\n",
    "#                 return False\n",
    "#             for r1, r2 in zip(row1, row2):\n",
    "#                 return _check_row_same(r1, r2)\n",
    "#         else:\n",
    "#             return row1==row2\n",
    "            \n",
    "    \n",
    "    # 1) convert tasks to hashable plans\n",
    "    plan1 = _list_to_hashable(task.PlanDat[\"Plan\"])\n",
    "    plan2 = _list_to_hashable(taskother.PlanDat[\"Plan\"])\n",
    "\n",
    "    # 2) check item by item\n",
    "    list_plan_common_rows = []\n",
    "    for i, (row1, row2) in enumerate(zip(plan1, plan2)):\n",
    "        if i==row_diff:\n",
    "            # then allow to be diff\n",
    "            # row1 =  ['translate_xy',\n",
    "#                   array(-1.),\n",
    "#                   ['interp_end1_end2_99', 'end2', array([0., 0.])]],\n",
    "            tmp = [] # to collect this row elements ignoring the psycho thing\n",
    "            for ii, (rowrow1, rowrow2) in enumerate(zip(row1, row2)):\n",
    "                if ii==2:\n",
    "                    # rowrow1 = ['interp_end1_end2_99', 'end2', array([0., 0.])]\n",
    "                    # ignore the first item, interp_end1_end2_99\n",
    "                    x1 = rowrow1[1:]\n",
    "                    x2 = rowrow2[1:]\n",
    "                else:\n",
    "                    x1 = rowrow1\n",
    "                    x2 = rowrow2\n",
    "                same = _check_row_same(x1, x2)\n",
    "                if not same:\n",
    "                    return False, None\n",
    "                tmp.append(x1)\n",
    "            list_plan_common_rows.append(tuple(tmp))\n",
    "        else:\n",
    "            # check if same\n",
    "            same = _check_row_same(row1, row2)\n",
    "            if not same:\n",
    "                return False, None\n",
    "            list_plan_common_rows.append(row1)\n",
    "    return True, tuple(list_plan_common_rows)\n",
    "\n",
    "def get_tasks_psycho_group(Task):\n",
    "    \"\"\" Get this tasks group. \n",
    "    Assumes a specific kind of manipualtion of plan..\n",
    "    PARAMS;\n",
    "    - Task, TaskClassGeneral\n",
    "    RETURNS:\n",
    "    - list_tasks, list_inds, list_interps, list_plancommon, all same length.\n",
    "    \"\"\"\n",
    "    row_diff = 3\n",
    "    list_tasks = []\n",
    "    list_inds = []\n",
    "    list_interpstrings = []\n",
    "    list_plancommon = []\n",
    "    for i in range(len(D.Dat)):\n",
    "        if D.Dat.iloc[i][\"monkey_train_or_test\"]==\"train\":\n",
    "            continue\n",
    "        TaskOther = D.Dat.iloc[i][\"Task\"]    \n",
    "        same, list_plan_common_rows = check_tasks_same_psychometric_group(Task, TaskOther, row_diff)\n",
    "        if same:\n",
    "#             print(\"Found same task, row: \", i)\n",
    "            list_tasks.append(TaskOther)\n",
    "            list_inds.append(i)\n",
    "            list_plancommon.append(list_plan_common_rows)\n",
    "\n",
    "            # Pull out its relation value\n",
    "            interp_string = TaskOther.PlanDat[\"Plan\"][row_diff][2][0] # interp_end1_end2_99\n",
    "            list_interpstrings.append(interp_string)\n",
    "\n",
    "    print(list_interpstrings)\n",
    "    list_interps = [int(x[-2:]) for x in list_interpstrings]\n",
    "    list_plancommon_hash = [hash(x) for x in list_plancommon]\n",
    "    assert len(set(list_plancommon_hash))==1, \"shuld all be same psycho group...\"\n",
    "    \n",
    "    return list_tasks, list_inds, list_interps, list_plancommon"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9587c51df932f576"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get psychometric groyup for all tasks\n",
    "\n",
    "out = [] # list of dict, index: group\n",
    "dftest = D.Dat[D.Dat[\"monkey_train_or_test\"]==\"test\"]\n",
    "\n",
    "def _exists(ind, out):\n",
    "    \"\"\" Check if this trial ind is present alreadry in out\"\"\"\n",
    "    for x in out:\n",
    "        if x[\"ind\"]==ind:\n",
    "            return x, True\n",
    "    return None, False\n",
    "\n",
    "for i in dftest.index.tolist():\n",
    "    print(i)\n",
    "    Task = D.Dat.iloc[i][\"Task\"]\n",
    "    list_tasks, list_inds, list_interps, list_plancommon = get_tasks_psycho_group(Task)\n",
    "    \n",
    "    # assign groups to tasks. if already assigned, confirm that is same as before\n",
    "    for ind, interp, plan in zip(list_inds, list_interps, list_plancommon):\n",
    "        # Check if exists\n",
    "        x, exists = _exists(ind, out)\n",
    "        if exists:\n",
    "#             print(\"Exists...\")\n",
    "            assert x[\"interp\"]==interp\n",
    "            assert x[\"plan_hash\"]==hash(plan)\n",
    "        else:\n",
    "#             print(\"Doesnt exist, adding this task\")\n",
    "            # append\n",
    "            out.append({\n",
    "                \"ind\":ind,\n",
    "                \"interp\":interp,\n",
    "                \"plan_hash\":hash(plan),\n",
    "                \"plan_common\":plan\n",
    "            })\n",
    "            \n",
    "# TODO: to speed up, dont only look for a tasks group if it is not already in out. Only\n",
    "# do this if sure that this code doesnt mistakenly assign assign a task to multiple groups."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7be7f9bc15d6ee5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check that all test tasks have been assigned. If so, then confident that each task is assigned to one and only one.\n",
    "for i in dftest.index.tolist():\n",
    "    assert _exists(i, out)[1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fbe00c680e72975"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort out\n",
    "out = sorted(out, key=lambda x: x[\"ind\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9785bba08fd3cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfpsycho = pd.DataFrame(out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb688012a7d8e796"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print some stats about psycho groups\n",
    "list_groups = dfpsycho[\"plan_hash\"].unique().tolist()\n",
    "print(\"-- found this many psycho groups: \", len(list_groups))\n",
    "\n",
    "for grp in list_groups:\n",
    "    dfthis = dfpsycho[dfpsycho[\"plan_hash\"]==grp]\n",
    "    print(grp, \" : \", len(dfthis))\n",
    "    \n",
    "print(\"-- With these num samples per interp\")\n",
    "for grp in list_groups:\n",
    "    dfthis = dfpsycho[dfpsycho[\"plan_hash\"]==grp]\n",
    "    print(grp)\n",
    "    print(dfthis[\"interp\"].value_counts())\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faa00b8282ce163"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfthis.sort_values(\"interp\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f06e21168b27296a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "sdir = f\"{SAVEDIR_FIGS}/using_planhash/psycho_quick\"\n",
    "os.makedirs(sdir)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8d24198d8cec03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot each group\n",
    "for grp in list_groups:\n",
    "    dfthis = dfpsycho[dfpsycho[\"plan_hash\"]==grp]\n",
    "    # sort by psychometric\n",
    "    dfthis = dfthis.sort_values(\"interp\")\n",
    "#     print(dfthis)\n",
    "    inds = dfthis[\"ind\"].tolist()\n",
    "    interps = dfthis[\"interp\"].tolist()\n",
    "#     print(inds)\n",
    "    fig1 = D.plotMultTrials(inds, \"strokes_task\", titles=interps);\n",
    "    fig2, _, _ = D.plotMultTrials(inds, color_by=\"order\");\n",
    "    \n",
    "    fig1.savefig(f\"{sdir}/alltrials-group_{grp}-task.pdf\")\n",
    "    try:\n",
    "        fig2.savefig(f\"{sdir}/alltrials-group_{grp}-beh.pdf\")\n",
    "    except:\n",
    "        fig2.savefig(f\"{sdir}/alltrials-group_{grp}-beh.png\")\n",
    "    \n",
    "    plt.close(\"all\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d966b39790c5e1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2, _, _ = D.plotMultTrials(inds, color_by=\"order\");\n",
    "fig2.savefig(f\"{sdir}/alltrials-group_{grp}-beh.jpg\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b3f862a235b2d67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Give this group a name, based on the common plan elements\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dbd8049236b3bb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "D.plotMultTrials(list_inds, \"strokes_task\", titles=list_interps);\n",
    "D.plotMultTrials(list_inds, color_by=\"order\");\n",
    "                                  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddcc327d5438f004"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
