{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621fb279-1a87-4ba9-817a-335fe1c516c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pythonlib.tools.stroketools import *\n",
    "from tools.preprocess import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pyvm.classes.videoclass import Videos\n",
    "from tools.handtrack import HandTrack, getTrialsCameraFrametimes\n",
    "from pyvm.utils.directories import get_metadata\n",
    "from pythonlib.tools.expttools import load_yaml_config\n",
    "from pyvm.globals import BASEDIR\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b41b8d4-8cf2-4fdd-81c3-f1c2857a8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regression_cam(HT, trange):\n",
    "\t\"\"\"\n",
    "\tFits linear regression for this HT object and trial list\n",
    "\tPARAMS:\n",
    "\tHT, hand track object\n",
    "\ttrange, range of trials\n",
    "\tRETURNS: \n",
    "\tscikit linear regression object\n",
    "\t\"\"\"\n",
    "\n",
    "\tfor trial in trange:\n",
    "\n",
    "\t\tdat, _ = HT.process_data_singletrial(trial, ploton=False, finger_raise_time = 0.0)\n",
    "\n",
    "\t\tif dat == {}:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\tstrokes_cam_all = []\n",
    "\tstrokes_touch_all = []\n",
    "\tfor strok_cam, strok_touch in zip(dat[\"strokes_cam\"], dat[\"strokes_touch\"]):\n",
    "\t\tstrokes_cam_all.append(np.array(strok_cam))\n",
    "\t\tstrokes_touch_all.append(np.array(strok_touch))\n",
    "\n",
    "\tassert (strokes_touch_all != {}), \"No data for this expt\"\n",
    "\n",
    "\tN = [\"input_times\"]\n",
    "\tfor strok in strokes_cam_all:\n",
    "\t\tN.append(np.array([p[3] for p in strok]))\n",
    "\n",
    "\ttouch_interp = strokesInterpolate2(strokes_touch_all, N)\n",
    "\n",
    "\ttouch_interpz = []\n",
    "\tfor strok in touch_interp:\n",
    "\t\tadd_z = [[p[0],p[1],0,p[2]] for p in strok]\n",
    "\t\ttouch_interpz.append(np.array(add_z))\n",
    "\n",
    "\tcam_one_list = np.array([])\n",
    "\ttouch_one_list = np.array([])\n",
    "\tfor strok_cam, strok_touch in zip(strokes_cam_all, touch_interpz):\n",
    "\t\tif len(cam_one_list) == 0 and len(touch_one_list) == 0:\n",
    "\t\t\tcam_one_list = np.array(strok_cam)\n",
    "\t\t\ttouch_one_list = np.array(strok_touch)\n",
    "\t\telse:\n",
    "\t\t\tcam_one_list = np.concatenate((cam_one_list,strok_cam))\n",
    "\t\t\ttouch_one_list = np.concatenate((touch_one_list,strok_touch))\n",
    "\t\t\treg = LinearRegression().fit(cam_one_list, touch_one_list)\n",
    "\treturn reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adb4b453-2410-4039-bcd9-c2ca32ffce21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vid range(2, 249)\n",
      "/home/danhan/freiwaldDrive/ltian/backup/gorilla/gorilla1/animals/Pancho/221101/221101_*_dirshapecolor3_Pancho_1.pkl\n",
      "/home/danhan/freiwaldDrive/ltian/backup/gorilla/gorilla1/animals/Pancho/221101/221101_*_dirshapecolor3_Pancho_1.pkl\n",
      "-- loaded presaved data: /home/danhan/freiwaldDrive/ltian/backup/gorilla/gorilla1/animals/Pancho/221101/221101_151509_dirshapecolor3_Pancho_1.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_4-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_4-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_4-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_4-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_4-dat.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_5-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_5-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_5-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_5-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_5-dat.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_6-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_6-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_6-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_6-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_6-dat.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_7-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_7-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_7-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_7-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_7-dat.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_8-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_8-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_8-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_8-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_8-dat.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_9-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_9-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_9-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_9-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_9-dat.pkl\n",
      "TODO: Get accurate frametime after pass in frame extraction to Buttons\n",
      "Searching using this string:\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/*camera*trial_10-*dat**\n",
      "Found this many paths:\n",
      "4\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_bfs1_-trial_10-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_flea_-trial_10-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly1_-trial_10-dat.pkl\n",
      "---\n",
      "/data3/hand_track/Pancho/221101_dirshapecolor3/behavior/extracted_dlc_data/camera_fly2_-trial_10-dat.pkl\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "op1=635, op2=708",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m HT\u001b[38;5;241m.\u001b[39mload_campy_data(\u001b[38;5;241m1\u001b[39m, sess\u001b[38;5;241m=\u001b[39msess_print)\n\u001b[1;32m     19\u001b[0m trials_no_ts_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 23\u001b[0m regression \u001b[38;5;241m=\u001b[39m \u001b[43mfit_regression_cam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrange\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m HT\u001b[38;5;241m.\u001b[39mregressor \u001b[38;5;241m=\u001b[39m regression\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# fd = loadSingleDataQuick(\"Pancho\", \"220317\", \"chunkbyshape4\", 1)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# HT = HandTrack(4, 1, fd, 220317, \"chunkbyshape4\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m, in \u001b[0;36mfit_regression_cam\u001b[0;34m(HT, trange)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mFits linear regression for this HT object and trial list\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mPARAMS:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mscikit linear regression object\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trange:\n\u001b[0;32m---> 13\u001b[0m \tdat, _ \u001b[38;5;241m=\u001b[39m \u001b[43mHT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_data_singletrial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mploton\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinger_raise_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m dat \u001b[38;5;241m==\u001b[39m {}:\n\u001b[1;32m     16\u001b[0m \t\t\u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/pipeline/setup/drawmonkey/tools/handtrack.py:170\u001b[0m, in \u001b[0;36mHandTrack.process_data_singletrial\u001b[0;34m(self, trial_ml2, ploton, filter_by_likeli_thresh, return_in_meters, finger_raise_time)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pts\u001b[38;5;241m/\u001b[39mconv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpix_over_m\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# 1) Extract cam and coinvert coords.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m dfall, t, pts, camdict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trials_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_ml2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_by_likeli_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_by_likeli_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dfall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:   \n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# failed becuase no campy data\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, []\n",
      "File \u001b[0;32m~/Documents/pipeline/setup/drawmonkey/tools/handtrack.py:559\u001b[0m, in \u001b[0;36mHandTrack.get_trials_all_data\u001b[0;34m(self, trial_ml2, bodypart, filter_by_likeli_thresh, thresh_likeli, return_empty_if_skip)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# 3b) Get frametimes relative to trial\u001b[39;00m\n\u001b[1;32m    558\u001b[0m t_intrial \u001b[38;5;241m=\u001b[39m getTrialsCameraFrametimes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFd, trial_ml2)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t_intrial)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(frametimes_mean), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(t_intrial)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, op2=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(frametimes_mean)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# 4) Sanity checks - confirm that campy and dlc are aligned\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frametimes_mean)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(pts)\n",
      "\u001b[0;31mAssertionError\u001b[0m: op1=635, op2=708"
     ]
    }
   ],
   "source": [
    "#Get range of trials to analyze data from\n",
    "\n",
    "ind1_ml2 = 1\n",
    "config = load_yaml_config(f\"/home/danhan/Documents/pipeline/metadata/221101_dirshapecolor3.yaml\")\n",
    "vid_inds = config[\"list_vidnums\"][0]\n",
    "trange = range(vid_inds[0],vid_inds[1])\n",
    "ind1_vid = vid_inds[0]\n",
    "print(\"Vid\", trange)\n",
    "\n",
    "animal = \"Pancho\"\n",
    "date = \"221101\"\n",
    "expt = \"dirshapecolor3\"\n",
    "sess = \"1\"\n",
    "sess_print = \"\"\n",
    "\n",
    "fd = loadSingleDataQuick(animal, date, expt, sess)\n",
    "HT = HandTrack(ind1_vid, ind1_ml2, fd, date=date, expt=expt)\n",
    "HT.load_campy_data(1, sess=sess_print)\n",
    "trials_no_ts_data = []\n",
    "\n",
    "\n",
    "\n",
    "regression = fit_regression_cam(HT, trange)\n",
    "HT.regressor = regression\n",
    "\n",
    "# fd = loadSingleDataQuick(\"Pancho\", \"220317\", \"chunkbyshape4\", 1)\n",
    "# HT = HandTrack(4, 1, fd, 220317, \"chunkbyshape4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
